["```py\n%matplotlib inline \nimport numpy as np \nfrom pylab import * \n\nnp.random.seed(2) \n\npageSpeeds = np.random.normal(3.0, 1.0, 100) \npurchaseAmount = np.random.normal(50.0, 30.0, 100) / pageSpeeds \n\nscatter(pageSpeeds, purchaseAmount) \n\n```", "```py\ntrainX = pageSpeeds[:80] \ntestX = pageSpeeds[80:] \n\ntrainY = purchaseAmount[:80] \ntestY = purchaseAmount[80:] \n\n```", "```py\nscatter(trainX, trainY) \n\n```", "```py\nscatter(testX, testY) \n\n```", "```py\nx = np.array(trainX) \ny = np.array(trainY) \n\np4 = np.poly1d(np.polyfit(x, y, 8)) \n\n```", "```py\nimport matplotlib.pyplot as plt \n\nxp = np.linspace(0, 7, 100) \naxes = plt.axes() \naxes.set_xlim([0,7]) \naxes.set_ylim([0, 200]) \nplt.scatter(x, y) \nplt.plot(xp, p4(xp), c='r') \nplt.show() \n\n```", "```py\ntestx = np.array(testX) \ntesty = np.array(testY) \n\naxes = plt.axes() \naxes.set_xlim([0,7]) \naxes.set_ylim([0, 200]) \nplt.scatter(testx, testy) \nplt.plot(xp, p4(xp), c='r') \nplt.show() \n\n```", "```py\nfrom sklearn.metrics import r2_score  \nr2 = r2_score(testy, p4(testx))  \nprint r2 \n\n```", "```py\nfrom sklearn.metrics import r2_score  \nr2 = r2_score(np.array(trainY), p4(np.array(trainX))) \nprint r2 \n\n```", "```py\nimport os \nimport io \nimport numpy \nfrom pandas import DataFrame \nfrom sklearn.feature_extraction.text import CountVectorizer \nfrom sklearn.naive_bayes import MultinomialNB \n\ndef readFiles(path): \n    for root, dirnames, filenames in os.walk(path): \n        for filename in filenames: \n            path = os.path.join(root, filename) \n\n            inBody = False \n            lines = [] \n            f = io.open(path, 'r', encoding='latin1') \n            for line in f: \n                if inBody: \n                    lines.append(line) \n                elif line == '\\n': \n                    inBody = True \n            f.close() \n            message = '\\n'.join(lines) \n            yield path, message \n\ndef dataFrameFromDirectory(path, classification): \n    rows = [] \n    index = [] \n    for filename, message in readFiles(path): \n        rows.append({'message': message, 'class': classification}) \n        index.append(filename) \n\n    return DataFrame(rows, index=index) \n\ndata = DataFrame({'message': [], 'class': []}) \n\ndata = data.append(dataFrameFromDirectory(\n                   'e:/sundog-consult/Udemy/DataScience/emails/spam',\n                   'spam')) \ndata = data.append(dataFrameFromDirectory(\n                   'e:/sundog-consult/Udemy/DataScience/emails/ham',\n                   'ham')) \n\n```", "```py\ndata.head() \n\n```", "```py\nvectorizer = CountVectorizer() \ncounts = vectorizer.fit_transform(data['message'].values) \n\nclassifier = MultinomialNB() \ntargets = data['class'].values \nclassifier.fit(counts, targets) \n\n```", "```py\nexamples = ['Free Money now!!!', \"Hi Bob, how about a game of golf tomorrow?\"] \nexample_counts = vectorizer.transform(examples) \npredictions = classifier.predict(example_counts) \npredictions \n\n```", "```py\narray(['spam', 'ham'], dtype='|S4') \n\n```", "```py\nfrom numpy import random, array \n\n#Create fake income/age clusters for N people in k clusters \ndef createClusteredData(N, k): \n    random.seed(10) \n    pointsPerCluster = float(N)/k \n    X = [] \n    for i in range (k): \n        incomeCentroid = random.uniform(20000.0, 200000.0) \n        ageCentroid = random.uniform(20.0, 70.0) \n        for j in range(int(pointsPerCluster)): \n            X.append([random.normal(incomeCentroid, 10000.0), \n            random.normal(ageCentroid, 2.0)]) \n    X = array(X) \n    return X \n\n```", "```py\nfrom sklearn.cluster import KMeans \nimport matplotlib.pyplot as plt \nfrom sklearn.preprocessing import scale \nfrom numpy import random, float \n\ndata = createClusteredData(100, 5) \n\nmodel = KMeans(n_clusters=5) \n\n# Note I'm scaling the data to normalize it! Important for good results. \nmodel = model.fit(scale(data)) \n\n# We can look at the clusters each data point was assigned to \nprint model.labels_  \n\n# And we'll visualize it: \nplt.figure(figsize=(8, 6)) \nplt.scatter(data[:,0], data[:,1], c=model.labels_.astype(float)) \nplt.show() \n\n```", "```py\nimport numpy as np \nimport pandas as pd \nfrom sklearn import tree \n\ninput_file = \"c:/spark/DataScience/PastHires.csv\" \ndf = pd.read_csv(input_file, header = 0) \n\n```", "```py\ndf.head() \n\n```", "```py\nd = {'Y': 1, 'N': 0} \ndf['Hired'] = df['Hired'].map(d) \ndf['Employed?'] = df['Employed?'].map(d) \ndf['Top-tier school'] = df['Top-tier school'].map(d) \ndf['Interned'] = df['Interned'].map(d) \nd = {'BS': 0, 'MS': 1, 'PhD': 2} \ndf['Level of Education'] = df['Level of Education'].map(d) \ndf.head() \n\n```", "```py\nfeatures = list(df.columns[:6]) \nfeatures \n\n```", "```py\ny = df[\"Hired\"] \nX = df[features] \nclf = tree.DecisionTreeClassifier() \nclf = clf.fit(X,y) \n\n```", "```py\nfrom IPython.display import Image   \nfrom sklearn.externals.six import StringIO   \nimport pydot  \n\ndot_data = StringIO()   \ntree.export_graphviz(clf, out_file=dot_data,   \n                         feature_names=features)   \ngraph = pydot.graph_from_dot_data(dot_data.getvalue())   \nImage(graph.create_png()) \n\n```", "```py\nfrom sklearn.ensemble import RandomForestClassifier \n\nclf = RandomForestClassifier(n_estimators=10) \nclf = clf.fit(X, y) \n\n#Predict employment of an employed 10-year veteran \nprint clf.predict([[10, 1, 4, 0, 0, 0]]) \n#...and an unemployed 10-year veteran \nprint clf.predict([[10, 0, 4, 0, 0, 0]]) \n\n```", "```py\nimport numpy as np \n\n#Create fake income/age clusters for N people in k clusters \ndef createClusteredData(N, k): \n    pointsPerCluster = float(N)/k \n    X = [] \n    y = [] \n    for i in range (k): \n        incomeCentroid = np.random.uniform(20000.0, 200000.0) \n        ageCentroid = np.random.uniform(20.0, 70.0) \n        for j in range(int(pointsPerCluster)): \n            X.append([np.random.normal(incomeCentroid, 10000.0),  \n            np.random.normal(ageCentroid, 2.0)]) \n            y.append(i) \n    X = np.array(X) \n    y = np.array(y) \n    return X, y \n\n```", "```py\n%matplotlib inline \nfrom pylab import * \n\n(X, y) = createClusteredData(100, 5) \n\nplt.figure(figsize=(8, 6)) \nplt.scatter(X[:,0], X[:,1], c=y.astype(np.float)) \nplt.show() \n\n```", "```py\nfrom sklearn import svm, datasets \n\nC = 1.0 \nsvc = svm.SVC(kernel='linear', C=C).fit(X, y) \n\n```", "```py\ndef plotPredictions(clf): \n    xx, yy = np.meshgrid(np.arange(0, 250000, 10), \n                     np.arange(10, 70, 0.5)) \n    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()]) \n\n    plt.figure(figsize=(8, 6)) \n    Z = Z.reshape(xx.shape) \n    plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8) \n    plt.scatter(X[:,0], X[:,1], c=y.astype(np.float)) \n    plt.show() \n\nplotPredictions(svc) \n\n```", "```py\nsvc.predict([[200000, 40]])\n\n```", "```py\nsvc.predict([[50000, 65]])\n\n```"]