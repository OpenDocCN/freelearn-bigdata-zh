["```scala\nexport SPARKLING_WATER_VERSION=\"2.1.12\" \nexport SPARK_PACKAGES=\\ \n\"ai.h2o:sparkling-water-core_2.11:${SPARKLING_WATER_VERSION},\\ \nai.h2o:sparkling-water-repl_2.11:${SPARKLING_WATER_VERSION},\\ \nai.h2o:sparkling-water-ml_2.11:${SPARKLING_WATER_VERSION},\\ \ncom.packtpub:mastering-ml-w-spark-utils:1.0.0\" \n\n$SPARK_HOME/bin/spark-shell \\ \n        --master 'local[*]' \\ \n        --driver-memory 8g \\ \n        --executor-memory 8g \\ \n        --conf spark.executor.extraJavaOptions=-XX:MaxPermSize=384M \\ \n        --conf spark.driver.extraJavaOptions=-XX:MaxPermSize=384M \\ \n        --packages \"$SPARK_PACKAGES\" \"$@\"\n```", "```scala\nval DATASET_DIR = s\"${sys.env.get(\"DATADIR\").getOrElse(\"data\")}/aclImdb/train\"\n val FILE_SELECTOR = \"*.txt\" \n\ncase class Review(label: Int, reviewText: String) \n\n val positiveReviews = spark.read.textFile(s\"$DATASET_DIR/pos/$FILE_SELECTOR\")\n     .map(line => Review(1, line)).toDF\n val negativeReviews = spark.read.textFile(s\"$DATASET_DIR/neg/$FILE_SELECTOR\")\n   .map(line => Review(0, line)).toDF\n var movieReviews = positiveReviews.union(negativeReviews)\n```", "```scala\nimport org.apache.spark.ml.feature.StopWordsRemover\n val stopWords = StopWordsRemover.loadDefaultStopWords(\"english\") ++ Array(\"ax\", \"arent\", \"re\")\n\n val MIN_TOKEN_LENGTH = 3\n val toTokens = (minTokenLen: Int, stopWords: Array[String], review: String) =>\n   review.split(\"\"\"\\W+\"\"\")\n     .map(_.toLowerCase.replaceAll(\"[^\\\\p{IsAlphabetic}]\", \"\"))\n     .filter(w => w.length > minTokenLen)\n     .filter(w => !stopWords.contains(w))\n```", "```scala\n\n val toTokensUDF = udf(toTokens.curried(MIN_TOKEN_LENGTH)(stopWords))\n movieReviews = movieReviews.withColumn(\"reviewTokens\", toTokensUDF('reviewText))\n```", "```scala\nval word2vec = new Word2Vec()\n   .setInputCol(\"reviewTokens\")\n   .setOutputCol(\"reviewVector\")\n   .setMinCount(1)\nval w2vModel = word2vec.fit(movieReviews)\n```", "```scala\nw2vModel.findSynonyms(\"funny\", 5).show()\n\n```", "```scala\nw2vModel.getVectors.where(\"word = 'funny'\").show(truncate = false)\n```", "```scala\nval testDf = Seq(Seq(\"funny\"), Seq(\"movie\"), Seq(\"funny\", \"movie\")).toDF(\"reviewTokens\")\n w2vModel.transform(testDf).show(truncate=false)\n```", "```scala\nval inputData = w2vModel.transform(movieReviews)\n```", "```scala\nval trainValidSplits = inputData.randomSplit(Array(0.8, 0.2))\nval (trainData, validData) = (trainValidSplits(0), trainValidSplits(1))\n```", "```scala\nval gridSearch =\nfor (\n     hpImpurity <- Array(\"entropy\", \"gini\");\n     hpDepth <- Array(5, 20);\n     hpBins <- Array(10, 50))\nyield {\nprintln(s\"Building model with: impurity=${hpImpurity}, depth=${hpDepth}, bins=${hpBins}\")\nval model = new DecisionTreeClassifier()\n         .setFeaturesCol(\"reviewVector\")\n         .setLabelCol(\"label\")\n         .setImpurity(hpImpurity)\n         .setMaxDepth(hpDepth)\n         .setMaxBins(hpBins)\n         .fit(trainData)\n\nval preds = model.transform(validData)\nval auc = new BinaryClassificationEvaluator().setLabelCol(\"label\")\n         .evaluate(preds)\n       (hpImpurity, hpDepth, hpBins, auc)\n     }\n```", "```scala\nimport com.packtpub.mmlwspark.utils.Tabulizer.table\nprintln(table(Seq(\"Impurity\", \"Depth\", \"Bins\", \"AUC\"),\n               gridSearch.sortBy(_._4).reverse,\nMap.empty[Int,String]))\n```", "```scala\nimport org.apache.spark.h2o._\nval hc = H2OContext.getOrCreate(sc)\nval trainHf = hc.asH2OFrame(trainData, \"trainData\")\nval validHf = hc.asH2OFrame(validData, \"validData\")\n```", "```scala\nhc.openFlow()\n```", "```scala\nw2vModel.findSynonyms(\"drama\", 5).show()\n```", "```scala\nval newW2VModel = new Word2Vec()\n   .setInputCol(\"reviewTokens\")\n   .setOutputCol(\"reviewVector\")\n   .setMinCount(3)\n   .setMaxIter(250)\n   .setStepSize(0.02)\n   .fit(movieReviews)\n    newW2VModel.findSynonyms(\"drama\", 5).show()\n```"]