["```scala\nwget http://files.grouplens.org/datasets/movielens/ml-1m.zip\n```", "```scala\ncurl http://files.grouplens.org/datasets/movielens/ml-1m.zip -o ml-1m.zip\n```", "```scala\nunzip ml-1m.zip\ncreating: ml-1m/\ninflating: ml-1m/movies.dat\ninflating: ml-1m/ratings.dat\ninflating: ml-1m/README\ninflating: ml-1m/users.dat\n```", "```scala\ncd m1-1m\n```", "```scala\nhead -5 movies.dat\n1::Toy Story (1995)::Animation|Children's|Comedy\n2::Jumanji (1995)::Adventure|Children's|Fantasy\n3::Grumpier Old Men (1995)::Comedy|Romance\n4::Waiting to Exhale (1995)::Comedy|Drama\n5::Father of the Bride Part II (1995)::Comedy\n```", "```scala\nhead -5 ratings.dat\n1::1193::5::978300760\n1::661::3::978302109\n1::914::3::978301968\n1::3408::4::978300275\n1::2355::5::978824291\n```", "```scala\npackage spark.ml.cookbook.chapter7\n```", "```scala\nimport java.text.DecimalFormat\n import org.apache.log4j.{Level, Logger}\n import org.apache.spark.sql.SparkSession\n import org.jfree.chart.{ChartFactory, ChartFrame, JFreeChart}\n import org.jfree.chart.axis.NumberAxis\n import org.jfree.chart.plot.PlotOrientation\n import org.jfree.data.xy.{XYSeries, XYSeriesCollection}\n```", "```scala\ncase class MovieData(movieId: Int, title: String, year: Int, genre: Seq[String])\n```", "```scala\ndef show(chart: JFreeChart) {\n val frame = new ChartFrame(\"plot\", chart)\n frame.pack()\n frame.setVisible(true)\n }\n```", "```scala\ndef parseMovie(str: String): MovieData = {\n val columns = str.split(\"::\")\n *assert*(columns.size == 3)\n\n val titleYearStriped = \"\"\"\\(|\\)\"\"\".r.replaceAllIn(columns(1), \" \")\n val titleYearData = titleYearStriped.split(\" \")\n\n *MovieData*(columns(0).toInt,\n titleYearData.take(titleYearData.size - 1).mkString(\" \"),\n titleYearData.last.toInt,\n columns(2).split(\"|\"))\n }\n```", "```scala\n val movieFile = \"../data/sparkml2/chapter7/movies.dat\"\n```", "```scala\nval spark = SparkSession\n .*builder* .master(\"local[*]\")\n .appName(\"MovieData App\")\n .config(\"spark.sql.warehouse.dir\", \".\")\n .config(\"spark.executor.memory\", \"2g\")\n .getOrCreate()\n```", "```scala\nLogger.getLogger(\"org\").setLevel(Level.ERROR)\n```", "```scala\nimport spark.implicits._\nval movies = spark.read.textFile(movieFile).map(parseMovie)  \n```", "```scala\nmovies.createOrReplaceTempView(\"movies\")\nval moviesByYear = spark.sql(\"select year, count(year) as count from movies group by year order by year\")\n```", "```scala\nval histogramDataset = new XYSeriesCollection()\n val xy = new XYSeries(\"\")\n moviesByYear.collect().foreach({\n row => xy.add(row.getAs[Int](\"year\"), row.getAs[Long](\"count\"))\n })\n\n histogramDataset.addSeries(xy)\n\n val chart = ChartFactory.createHistogram(\n \"\", \"Year\", \"Movies Per Year\", histogramDataset, PlotOrientation.VERTICAL, false, false, false)\n val chartPlot = chart.getXYPlot()\n\n val xAxis = chartPlot.getDomainAxis().asInstanceOf[NumberAxis]\n xAxis.setNumberFormatOverride(new DecimalFormat(\"####\"))\n\n show(chart)\n```", "```scala\nspark.stop()  \n```", "```scala\npackage spark.ml.cookbook.chapter7\n```", "```scala\nimport java.text.DecimalFormat\n import org.apache.log4j.{Level, Logger}\n import org.apache.spark.sql.SparkSession\n import org.jfree.chart.{ChartFactory, ChartFrame, JFreeChart}\n import org.jfree.chart.axis.NumberAxis\n import org.jfree.chart.plot.PlotOrientation\n import org.jfree.data.xy.{XYSeries, XYSeriesCollection}\n```", "```scala\ncase class Rating(userId: Int, movieId: Int, rating: Float, timestamp: Long)\n```", "```scala\ndef show(chart: JFreeChart) {\n val frame = new ChartFrame(\"plot\", chart)\n frame.pack()\n frame.setVisible(true)\n }\n```", "```scala\ndef parseRating(str: String): Rating = {\n val columns = str.split(\"::\")\n assert(columns.size == 4)\n Rating(columns(0).toInt, columns(1).toInt, columns(2).toFloat, columns(3).toLong)\n }\n```", "```scala\nval ratingsFile = \"../data/sparkml2/chapter7/ratings.dat\"\n```", "```scala\nval spark = SparkSession\n .*builder* .master(\"local[*]\")\n .appName(\"MovieRating App\")\n .config(\"spark.sql.warehouse.dir\", \".\")\n .config(\"spark.executor.memory\", \"2g\")\n .getOrCreate()\n```", "```scala\nLogger.getLogger(\"org\").setLevel(Level.ERROR)\n```", "```scala\nimport spark.implicits._\n val ratings = spark.read.textFile(ratingsFile).map(*parseRating*)\n```", "```scala\nratings.createOrReplaceTempView(\"ratings\")\n```", "```scala\nval resultDF = spark.sql(\"select ratings.userId, count(*) as count from ratings group by ratings.userId\")\nresultDF.show(25, false);\n```", "```scala\nval scatterPlotDataset = new XYSeriesCollection()\n val xy = new XYSeries(\"\")\n\n resultDF.collect().foreach({r => xy.add( r.getAs[Integer](\"userId\"), r.getAs[Integer](\"count\")) })\n\n scatterPlotDataset.addSeries(xy)\n\n val chart = ChartFactory.*createScatterPlot*(\n \"\", \"User\", \"Ratings Per User\", scatterPlotDataset, PlotOrientation.*VERTICAL*, false, false, false)\n val chartPlot = chart.getXYPlot()\n\n val xAxis = chartPlot.getDomainAxis().asInstanceOf[NumberAxis]\n xAxis.setNumberFormatOverride(new DecimalFormat(\"####\"))\n```", "```scala\n*show*(chart)\n```", "```scala\nspark.stop()\n```", "```scala\npackage spark.ml.cookbook.chapter7\n```", "```scala\nimport org.apache.log4j.{Level, Logger}\n import org.apache.spark.sql.SparkSession\n import org.apache.spark.ml.recommendation.ALS\n```", "```scala\ncase class Movie(movieId: Int, title: String, year: Int, genre: Seq[String])\n case class FullRating(userId: Int, movieId: Int, rating: Float, timestamp: Long)\n```", "```scala\ndef parseMovie(str: String): Movie = {\nval columns = str.split(\"::\")\n*assert*(columns.size == 3)\n\nval titleYearStriped = \"\"\"\\(|\\)\"\"\".r.replaceAllIn(columns(1), \" \")\nval titleYearData = titleYearStriped.split(\" \")\n\n*Movie*(columns(0).toInt,\n     titleYearData.take(titleYearData.size - 1).mkString(\" \"),\n     titleYearData.last.toInt,\n     columns(2).split(\"|\"))\n }\n\ndef parseFullRating(str: String): FullRating = {\nval columns = str.split(\"::\")\n*assert*(columns.size == 4)\n*FullRating*(columns(0).toInt, columns(1).toInt, columns(2).toFloat, columns(3).toLong)\n }\n```", "```scala\nval movieFile = \"../data/sparkml2/chapter7/movies.dat\" val ratingsFile = \"../data/sparkml2/chapter7/ratings.dat\"\n```", "```scala\nval spark = SparkSession\n .builder\n.master(\"local[*]\")\n .appName(\"MovieLens App\")\n .config(\"spark.sql.warehouse.dir\", \".\")\n .config(\"spark.executor.memory\", \"2g\")\n .getOrCreate()\n```", "```scala\nLogger.getLogger(\"org\").setLevel(Level.ERROR)\n```", "```scala\nval ratings = spark.read.textFile(ratingsFile).map(*parseFullRating*)\n\n val movies = spark.read.textFile(movieFile).map(*parseMovie*).cache()\n movies.createOrReplaceTempView(\"movies\")\n```", "```scala\nval rs = spark.sql(\"select movies.title from movies\")\nrs.show(25)\n```", "```scala\nval splits = ratings.randomSplit(*Array*(0.8, 0.2), 0L)\nval training = splits(0).cache()\nval test = splits(1).cache()\n\nval numTraining = training.count()\nval numTest = test.count()\n*println*(s\"Training: $numTraining, test: $numTest.\")\n```", "```scala\nval testWithOurUser = spark.createDataset(Seq(\n  FullRating(0, 260, 0f, 0), // Star Wars: Episode IV - A New Hope\n  FullRating(0, 261, 0f, 0), // Little Women\n  FullRating(0, 924, 0f, 0), // 2001: A Space Odyssey\n  FullRating(0, 1200, 0f, 0), // Aliens\n  FullRating(0, 1307, 0f, 0) // When Harry Met Sally...\n)).as[FullRating]\n\nval trainWithOurUser = spark.createDataset(Seq(\n  FullRating(0, 76, 3f, 0), // Screamers\n  FullRating(0, 165, 4f, 0), // Die Hard: With a Vengeance\n  FullRating(0, 145, 2f, 0), // Bad Boys\n  FullRating(0, 316, 5f, 0), // Stargate\n  FullRating(0, 1371, 5f, 0), // Star Trek: The Motion Picture\n  FullRating(0, 3578, 4f, 0), // Gladiator\n  FullRating(0, 3528, 1f, 0) // Prince of Tides\n)).as[FullRating]\n```", "```scala\nval testSet = test.union(testWithOurUser)\n test.unpersist()\nval trainSet = training.union(trainWithOurUser)\n training.unpersist()\n```", "```scala\nval als = new ALS()\n .setUserCol(\"userId\")\n .setItemCol(\"movieId\")\n .setRank(10)\n .setMaxIter(10)\n .setRegParam(0.1)\n .setNumBlocks(10)\nval model = als.fit(trainSet.toDF)\n```", "```scala\nval predictions = model.transform(testSet.toDF())\n predictions.cache()\n predictions.show(10, false)\n```", "```scala\nval allPredictions = predictions.join(movies, movies(\"movieId\") === predictions(\"movieId\"), \"left\")\n\n```", "```scala\nallPredictions.select(\"userId\", \"rating\", \"prediction\", \"title\")show(false)\n```", "```scala\nallPredictions.select(\"userId\", \"rating\", \"prediction\", \"title\").where(\"userId=0\").show(false)\n```", "```scala\nspark.stop()\n```", "```scala\n{numBlocks: -1, rank: 10, iterations: 10, lambda: 0.\nnumBlocks: -1,\nrank: 10,\niterations: 10,\nlambda: 0.01,\nimplicitPrefs: false,\nalpha: 1.0\n```"]