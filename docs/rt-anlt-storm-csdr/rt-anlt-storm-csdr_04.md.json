["```scala\n    zkp-1.mydomain.net \u2013 value of myId =1\n    zkp-2.mydomain.net \u2013 value of myId =2\n    zkp-3.mydomain.net \u2013 value of myId =3\n    ```", "```scala\n    server.1=zkp-1.mydomain.net:2888:3888\n    server.2=zkp-2\\. mydomain.net:2888:3888\n    server.3=zkp-3\\. mydomain.net:2888:3888\n    ```", "```scala\nnumBackUps=3\ndataDir=/usr/local/zookeeper/tmp\nlogDir=/mnt/my_logs/\necho `date`' Time to clean up StormZkTxn logs' >>  $logDir/cleanStormZk.out\njava -cp /usr/local/zookeeper/zookeeper-3.4.5/zookeeper- 3.4.5.jar:/usr/local/zookeeper/zookeeper-3.4.5/lib/log4j- 1.2.15.jar:/usr/local/zookeeper/zookeeper-3.4.5/lib/slf4j-api- 1.6.1.jar org.apache.zookeeper.server.PurgeTxnLog $dataDir -n  $numBackUps >> $logDir/cleanStormZk.out\n```", "```scala\nstorm.zookeeper.servers:\n- \"zkp-1.mydomain.net \"\n- \"zkp-2.mydomain.net \"\n- \"zkp-3.mydomain.net \"\n\nstorm.zookeeper.port: 2182\nstorm.local.dir: \"/usr/local/storm/tmp\"\nnimbus.host: \"nim-zkp-flm-3.mydomain.net\"\ntopology.message.timeout.secs: 60\ntopology.debug: false\n\nsupervisor.slots.ports:\n    - 6700\n    - 6701\n    - 6702\n    - 6703\n```", "```scala\n<appender name=\"A1\"  class=\"ch.qos.logback.core.rolling.RollingFileAppender\">\n    <file>${storm.log.dir}/${logfile.name}</file>\n    <rollingPolicy  class=\"ch.qos.logback.core.rolling.FixedWindowRollingPolicy\">\n      <fileNamePattern>${storm.log.dir}/${logfile.name}.%i</fileNamePattern >\n      <minIndex>1</minIndex>\n <maxIndex>9</maxIndex>\n    </rollingPolicy>\n\n    <triggeringPolicy  class=\"ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy\">\n      <maxFileSize>100MB</maxFileSize>\n    </triggeringPolicy>\n\n    <encoder>\n      <pattern>%d{yyyy-MM-dd HH:mm:ss} %c{1} [%p] %m%n</pattern>\n    </encoder>\n </appender>\n\n  <root level=\"INFO\">\n    <appender-ref ref=\"A1\"/>\n  </root>\n```", "```scala\nword-count, is the name of that topology:\n\n```", "```scala\n\nIn our preceding sample screenshot, **AAA-topology-1407803669812** is the name of the topology.**ID**: This is the Storm-generated unique ID that is a combination of the topology name, timestamp, and ID, which is used by Storm to identify and differentiate the topology.**Status**: This denotes the state of the topology, which could be *active* for a live topology, *killed* when a topology is killed using the UI or CLI, *inactive* for a deactivated topology, and *rebalancing* for a topology where the rebalance command is executed wherein the number of workers allocated to the topology is increased or decreased.**Uptime**: As the name suggests, this mentions the duration for which the topology has been running. For example, our sample topology has been running for 8 days 15 hours 6 months 16 seconds.**Num workers**: This specifies how many workers are allocated to the topology. Again, if we refer to `WordCountTopology.java`, we will see this snippet where it is declared as `3`:\n\n```", "```scala\n\n**Num executors**: This specifies the sum total of the number of executors in the topology. This is connected to the parallelism hint that is specified during the overall integration of the topology in the topology builder as follows:\n\n```", "```scala\n\nHere, in our `WordCount` topology, we have specified the parallelism of the spout as `5`, so five instances of the spout will be spawned in the topology.\n\n**Num tasks**: This gains the sum total of another parameter that is specified at the time of overall integration in the topology, as shown:\n\n```", "```scala\n\nHere, we are specifying that for `5` executors dedicated to the spout, the total value of `numtasks` is `10`, so two tasks each will be spawned on each of the executors.\n\nWhat we see on the UI is a total of all `numtasks`  values across all topology components.\n\n```", "```scala\n    Capacity = (Number of tuples Executed*Average execute  latency)/Window_Size*1000)\n    ```"]