["```scala\nwget http://memcached.org/latest\ntar -zxvfmemcached-1.x.x.tar.gz\ncdmemcached-1.x.x\n./configure && make && make test &&sudo make install\n\n```", "```scala\npublic class MemCacheClient {\n  private static MemcachedClient client = null;\n  private static final Logger logger =  LogUtils.getLogger(MemCacheClient.class);\n\n  /**\n  * Constructor that accepts the cache properties as parameter  and initialises the client object accordingly.\n   * @param properties\n   * @throws Exception\n   */\n\n  publicMemCacheClient(Properties properties) throws Exception {\n    super();\n    try {\n      if (null == client) {\n        client = new MemcachedClient(new InetSocketAddress(\n          102.23.34.22,\n          5454)));\n    }\n  } catch (IOException e) {\n    if (null != client)\n      shutdown();\n    throw new Exception(\"Error while initiating MemCacheClient\",  e);\n  }\n}\n\n/**\n * Shutdown the client and nullify it\n */\n\npublic void shutdown() {\n    logger.info(\"Shutting down memcache client \");\n    client.shutdown();\n    client = null;\n  }\n\n  /**\n    * This method sets a value in cache with a specific key and  timeout \n    * @param key the unique key to identify the value \n    * @paramtimeOut the time interval in ms after which the value  would be refreshed\n    * @paramval\n    * @return\n    */\n\n  public Future < Boolean > addToMemCache(String key, inttimeOut,  Object val) {\n    if (null != client) {\n      Future < Boolean > future = client.set(key, timeOut, val);\n      return future;\n    } else {\n      return null;\n    }\n  }\n\n  /**\n    * retrives and returns the value object against the key passed  in as parameter\n    * @param key\n    * @return\n    */\n\npublic Object getMemcachedValue(String key) {\n  if (null != client) {\n    try {\n      returnclient.get(key);\n    } catch (OperationTimeoutException e) {\n      logger.error(\n        \"Error while fetching value from memcache server for key \"  + key, e);\n      return null;\n    }\n  } else\n    return null;\n  }\n}\n```", "```scala\ncache:\n```", "```scala\npublic class MyCacheReaderBolt extends BaseBasicBolt {\n  MyCacheReadercacheReader;\n  @Override\n  public void prepare(Map stormConf, TopologyContext context) {\n      super.prepare(stormConf, context);\n      try {\n        cacheReader = new MyCacheReader();\n      } catch (Exception e) {\n        logger.error(\"Error while initializing Cache\", e);\n      }\n    }\n\n  /**\n     * Called whenever a new tuple is received by this bolt.  Responsible for \n     * emitting cache enriched event onto output stream \n  */\n\n  public void execute(Tuple tuple, BasicOutputCollector collector)  {\n    logger.info(\"execute method :: Start \");\n    event = tuple.getString(0);\n    populateEventFromCache(event);\n    collector.emit(outputStream, new Values(event));\n  } else {\n    logger.warn(\"Event not parsed :: \" + tuple.getString(0));\n  }\n} catch (Exception e) {\n  logger.error(\"Error in execute() \", e);\n  }\n}\nlogger.info(\"execute method :: End \");\n}\n\nprivate void populateEventFromCache(Event event) {\n  HashMapfetchMap = (HashMap)  cacheReader.get(searchObj.hashCode());\n  if (null != fetchMap) {\n    event.setAccountID(Integer.parseInt((String)  fetchMap.get(\"account_id\")));\n    logger.debug(\"Populating event\" + event + \" using cache \" +  fetchMap);\n  } else {\n    logger.debug(\"No matching event found in cache.\");\n  }\n  logger.info(\"Time to fetch from cache=\" +  (System.currentTimeMillis() - t1) + \"msec\");\n  }\n}\n\n/**\n * Declares output streams and tuple fields emitted from this bolt\n */\n  @Override\n    public void declareOutputFields(OutputFieldsDeclarer declarer)  {\n    String stormStreamName = logStream.getName() + \"_\" +  eventType;\n    declarer.declareStream(stormStreamName, new  Fields(stormStreamName));\n  logger.debug(\"Topology : \" + topology.getTopologyName() + \",  Declared output stream : \" + stormStreamName + \", Output field :  \" + stormStreamName);\n}\n```", "```scala\n dimensional data from memcache, and emits the enriched bolt to the streams to the following bolts in the DAG topology.\n```", "```scala\n<dependency>\n<groupId>com.espertech</groupId>\n<artifactId>esper</artifactId>\n<version> ... </version>\n</dependency>\nRef :Espertech.com\n```", "```scala\nCasinoWinEvent, a value object where we store the name of the game, the prize amount, and the timestamp:\n```", "```scala\npublic static class CasinoWinEvent {\n  String game;\n  Double prizeAmount;\n  Date timeStamp;\n\n  publicCasinoWinEvent(String s, double p, long t) {\n    game = s;\n    prizeAmount = p;\n    timeStamp = new Date(t);\n  }\n  public double getPrizeAmount() {\n    return prizeAmount;\n  }\n  public String getGame() {\n    return game;\n  }\n  public Date getTimeStamp() {\n    return timeStamp;\n  }\n\n  @\n  Override\n  public String toString() {\n    return \"Price: \" + price.toString() + \" time: \" +  timeStamp.toString();\n  }\n}\n```", "```scala\npublic class myEsperMain {\n  private static Random generator = new Random();\n  public static void GenerateRandomCasinoWinEvent(EPRuntimecepRT)  {\n    doubleprizeAmount = (double) generator.nextInt(10);\n    longtimeStamp = System.currentTimeMillis();\n    String game = \"Roulette\";\n    CasinoWinEventcasinoEvent = new CasinoWinEvent(game,  prizeAmount, timeStamp);\n    System.out.println(\"Sending Event:\" + casinoEvent);\n    cepRT.sendEvent(casinoEvent);\n  }\n  public static class CEPListener implements UpdateListener {\n    public void update(EventBean[] newData, EventBean[] oldData) {\n      System.out.println(\"Event received: \" +  newData[0].getUnderlying());\n    }\n  }\n  public static void main(String[] args) {\n    //The Configuration is meant only as an initialization-time  object.\n    Configuration cepConfig = new Configuration();\n    cepConfig.addEventType(\"CasinoEvent\",  CasinoWinEvent.class.getName());\n    EPServiceProvidercep =  EPServiceProviderManager.getProvider(\"myCEPEngine\",  cepConfig);\n    EPRuntimecepRT = cep.getEPRuntime();\n    EPAdministratorcepAdm = cep.getEPAdministrator();\n    EPStatementcepStatement = cepAdm.createEPL(\"select * from \" +   \"CasinoEvent(symbol='Roulette').win:length(2) \" + \"having  avg(prizeAmount) > 10000.0\");\n\n    cepStatement.addListener(new CEPListener());\n    // We generate a few ticks...\n    for (inti = 0; i < 5; i++) {\n      GenerateRandomCasinoWinEvent(cepRT);\n    }\n  }\n}\n```", "```scala\nZeroDuration filter bolt that filters the CALL_END events that have a duration of 0 seconds to be emitted onto the stream feeding the Esper bolt:\n```", "```scala\n  /*\n  * Bolt responsible for forwarding events which satisfy following  criteria:\n  * <ul>\n  * <li>event should belong to 'End'  type</li>\n  * <li>duration should be zero</li>\n  * </ul>\n  */\n\npublic class ZeroSecondsCDRBolt extends BaseRichBolt {\n\n  /**\n  * Called when {@link ZeroSecondsCDRBolt} is initialized\n  */\n  @Override\n  public void prepare(Map conf, TopologyContext context,\n    OutputCollector collector) {\n    logger.info(\"prepare method :: Start \");\n    this.collector = collector;\n    logger.info(\"prepare() conf {},Collector {}\", conf.toString(),  collector.toString());\n    logger.info(\"prepare method :: End \");\n  }\n\n  /**\n  * Called whenever a new tuple is received by this bolt. This  method \n   * filters zero duration End records \n   */\n\n  @\n  Override\n  public void execute(Tuple tuple) {\n    logger.info(\"execute method :: Start \");\n\n    if (tuple != null && tuple.getString(0) != null) {\n      eventCounter++;\n      String event = tuple.getString(0);\n      logger.info(\"execute :event recd :: {}\", event);\n      if (event != null && event.contains(\"CALL_END\")) {\n        emitCallEndRecords(tuple);\n      }\n      collector.ack(tuple);\n    }\n    logger.info(\"execute method :: End \");\n  }\n\n  private void emitCallEndRecords(Tuple tuple) {\n    String event = tuple.getString(0);\n\n      try {\n        //splitting the event based on semicolon\n        String[] eventTokens = event.split(\",\");\n        duration = Long.parseLong(eventTokens[4]);\n        callId = Long.parseLong(eventTokens[0]);\n        logger.debug(\" Event (callId = {}) is a Zero duration  Qualifier \", callId);\n        collector.emit(....);\n\n      } catch (Exception e) {\n        logger.error(\"Corrupt Stopped record. Error occurred while  parsing the event : {}\", event);\n      }\n    }\n\n  /**\n  * Declares output fields in tuple emitted from this bolt\n  */\n\n  @Override\n  public void declareOutputFields(OutputFieldsDeclarer declarer) {\n    declarer.declareStream(CALL_END, new Fields());\n  }\n\n  @\n  Override\n  public Map < String, Object > getComponentConfiguration() {\n    return null;\n  }\n}\n```", "```scala\nEsperBoltesperBolt = newEsperBolt.Builder()\n  .inputs()\n  .aliasComponent(\"ZeroSecondCallBolt\")\n  .withFields(\"a\", \"b\")\n  .ofType(Integer.class)\n  .toEventType(\"CALL_END\")\n  .outputs()\n  .outputs().onDefaultStream().emit(\"count\")\n  .statements()\n  .add(\"select callID as CALL_ID,callType as CALL_TYPE, count(*)  as OCCURRENCE_CNT from CDR.win:time_batch(5 minutes)  where  (eventType = 'CALL_END') and (duration = 0) group by  callID,eventType having count(*) > 0 order by  OCCURRENCE_CNTdesc\")\n  .build();\n```", "```scala\nselectcallID as CALL_ID,callType as CALL_TYPE, count(*) as  OCCURRENCE_CNT\n```", "```scala\nfromCDR.win:time_batch(5 minutes)  where (eventType = 'CALL_END')  and (duration = 0) group by callID,eventTypehaving count(*) > 0\norder by OCCURRENCE_CNTdesc\n```"]