["```scala\npublic class FileSpout extends BaseRichSpout {\n  //declaration section\n  SpoutOutputCollector _collector;\n  DataInputStream in ;\n  BufferedReader br;\n  Queue qe;\n\n  //constructor\n    public FileSpout() {\n        qe = new LinkedList();\n    }\n\n  // the messageId builder method\n  private String getMsgId(int i) {\n    return (new StringBuilder(\"#@#MsgId\")).append(i).toString();\n    }\n\n  //The function that is called at every line being read by  readFile\n  //method and adds messageId at the end of each line and then add\n  // the line to the linked list\n    private void queueIt() {\n      int msgId = 0;\n      String strLine;\n      try {\n          while ((strLine = br.readLine()) != null) {\n              qe.add((new  StringBuilder(String.valueOf(strLine))).append(\"#@#\"  + getMsgId(msgId)).toString());\n              msgId++;\n          }\n      } catch (IOException e) {\n          e.printStackTrace();\n      } catch (Exception e) {\n          e.printStackTrace();\n      }\n    }\n\n  //function to read line from file at specified location \n  private void readFile() {\n        try {\n          FileInputStream fstream = new  FileInputStream(\"/home/mylog\"); in =  new DataInputStream(fstream);\n          br = new BufferedReader(new InputStreamReader( in ));\n          queueIt();\n          System.out.println(\"FileSpout file reading done\");\n        } catch (FileNotFoundException e) {\n            e.printStackTrace();\n        }\n    }\n\n  //open function that is called at the time of spout  initialization\n  // it calls the readFile method that reads the file , adds  events \n  // to the linked list to be fed to the spout as tuples\n  @\n    Override\n    public void open(Map conf, TopologyContext context,  SpoutOutputCollector  collector) {\n      _collector = collector;\n      readFile();\n    }\n\n  //this method is called every 100 ms and it polls the list\n  //for message which is read off as next tuple and emit the spout  to\n  //the topology. When queue doesn't have any events, it reads the\n  //file again calling the readFile method\n    @\n    Override\n    public void nextTuple() {\n      Utils.sleep(100);\n      String fullMsg = (String) qe.poll();\n      String msg[] = (String[]) null;\n      if (fullMsg != null) {\n          msg = (new String(fullMsg)).split(\"#@#\");\n          _collector.emit(new Values(msg[0]));\n          System.out.println((new StringBuilder(\"nextTuple done  \")).append(msg[1]).toString());\n      } else {\n          readFile();\n      }\n    }\n\n  @\n  Override\n  public void ack(Object id) {}\n\n  @\n  Override\n  public void fail(Object id) {}\n\n  @\n  Override\n  public void declareOutputFields(OutputFieldsDeclarer declarer) {\n      declarer.declare(new Fields(\"word\"));\n  }\n}\n```", "```scala\npublic static void main(String[] args) throws Exception {\n  TopologyBuilder builder = new TopologyBuilder();\n//builder.setSpout(\"spout\", new RandomSentenceSpout(), 5);\n  builder.setSpout(\"spout\", new FileSpout(), 1);\n```", "```scala\npublic class SocketSpout extends BaseRichSpout{\n  static SpoutOutputCollector collector;\n  //The socket\n    static Socket myclientSocket;\n    static ServerSocket myserverSocket;\n    static int myport;\n\n  public SocketSpout(int port){\n    myport=port;\n  }\n\n  public void open(Map conf,TopologyContext context,  SpoutOutputCollector collector){\n    _collector=collector;\n    myserverSocket=new ServerSocket(myport);\n  }\n\n  public void nextTuple(){\n    myclientSocket=myserverSocket.accept();\n    InputStream incomingIS=myclientSocket.getInputStream();\n    byte[] b=new byte[8196];\n    int len=b.incomingIS.read(b);\n    _collector.emit(new Values(b));\n  }\n}\n```", "```scala\n      public void execute(Tuple tuple) {\n          String sentence = tuple.getString(0);\n          for(String word: sentence.split(\" \")) {\n              _collector.emit(tuple, new Values(word)); //1\n          }\n          _collector.ack(tuple); //2\n      }\n      public void declareOutputFields(OutputFieldsDeclarer  declarer) {\n          declarer.declare(new Fields(\"word\")); //3\n      }\n    }\n    ```", "```scala\n      builder.setBolt(\"count\", new WordCount(), 12).fieldsGrouping(\"split\", new Fields(\"word\"));\n    ```", "```scala\njava _collector.emit(new Values(word));\n```", "```scala\nWordCount topology (which we reated earlier), which demonstrates the usage of shuffle grouping:\n```", "```scala\nTopologyBuilder myBuilder = new TopologyBuilder();\nbuilder.setSpout(\"spout\", new RandomSentenceSpout(), 5);\nbuilder.setBolt(\"split\", new SplitSentence(),  8).shuffleGrouping(\"spout\");\nbuilder.setBolt(\"count\", new WordCount(),  12).fieldsGrouping(\"split\", new Fields(\"word\"));\n```"]