["```scala\n# yum install openssh-clients  \n```", "```scala\n    $ ssh-keygen -t rsa -P ''\n    Generating public/private rsa key pair.\n    Enter file in which to save the key (/home/anand/.ssh/id_rsa): \n    Your identification has been saved in /home/anand/.ssh/id_rsa.\n    Your public key has been saved in /home/anand/.ssh/id_rsa.pub.\n    The key fingerprint is:\n    b7:06:2d:76:ed:df:f9:1d:7e:5f:ed:88:93:54:0f:24 anand@localhost.localdomain\n    The key's randomart image is:\n    +--[ RSA 2048]----+\n    |                 |\n    |            E .  |\n    |             o   |\n    |         . .  o  |\n    |        S + .. o |\n    |       . = o.   o|\n    |          o... .o|\n    |         .  oo.+*|\n    |            ..ooX|\n    +-----------------+\n\n```", "```scala\n$ cp ~/.ssh/id_rsa.pub ~/.ssh/authorized_keys  \n```", "```scala\n$ ssh localhost\nLast login: Wed Apr  2 09:12:17 2014 from localhost  \n```", "```scala\n$ tar xzf hadoop-2.2.0.tar.gz\n$ cd hadoop-2.2.0  \n```", "```scala\n    export JAVA_HOME=/usr/java/jdk1.7.0_45\n    export HADOOP_HOME=/home/anand/opt/hadoop-2.2.0\n    export HADOOP_COMMON_HOME=/home/anand/opt/hadoop-2.2.0\n    export HADOOP_HDFS_HOME=$HADOOP_COMMON_HOME\n    export HADOOP_MAPRED_HOME=$HADOOP_COMMON_HOME\n    export HADOOP_YARN_HOME=$HADOOP_COMMON_HOME\n    export HADOOP_CONF_DIR=$HADOOP_COMMON_HOME/etc/hadoop\n    export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_COMMON_HOME/lib/native\n    export HADOOP_OPTS=\"-Djava.library.path=$HADOOP_COMMON_HOME/lib\"\n\n    export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_COMMON_HOME/bin:$HADOOP_COMMON_HOME/sbin\n\n```", "```scala\n$ source ~/.bashrc  \n```", "```scala\n$ hadoop version\nHadoop 2.2.0\nSubversion https://svn.apache.org/repos/asf/hadoop/common -r 1529768\nCompiled by hortonmu on 2013-10-07T06:28Z\nCompiled with protoc 2.5.0\nFrom source with checksum 79e53ce7994d1628b240f09af91e1af4\nThis command was run using /home/anand/opt/hadoop-\n2.2.0/share/hadoop/common/hadoop-common-2.2.0.jar  \n```", "```scala\n$ mkdir -p ~/mydata/hdfs/namenode\n$ mkdir -p ~/mydata/hdfs/datanode  \n```", "```scala\n<property> \n        <name>fs.default.name</name> \n        <value>hdfs://localhost:19000</value> \n   <!-- The default port for HDFS is 9000, but we are using 19000 Storm-Yarn uses port 9000 for its application master --> \n</property> \n```", "```scala\n<property> \n        <name>dfs.replication</name> \n        <value>1</value> \n   <!-- Since we have only one node, we have replication factor=1 --> \n</property> \n<property> \n        <name>dfs.namenode.name.dir</name> \n        <value>file:/home/anand/hadoop-data/hdfs/namenode</value> \n   <!-- specify absolute path of the namenode directory --> \n</property> \n<property> \n        <name>dfs.datanode.data.dir</name> \n        <value>file:/home/anand/hadoop-data/hdfs/datanode</value> \n   <!-- specify absolute path of the datanode directory --> \n</property> \n```", "```scala\n    $ hdfs namenode -format\n    14/04/02 09:03:06 INFO namenode.NameNode: STARTUP_MSG: \n    /*********************************************************\n    STARTUP_MSG: Starting NameNode\n    STARTUP_MSG:   host = localhost.localdomain/127.0.0.1\n    STARTUP_MSG:   args = [-format]\n    STARTUP_MSG:   version = 2.2.0\n    ... ...\n    14/04/02 09:03:08 INFO namenode.NameNode: SHUTDOWN_MSG: \n    /*********************************************************\n    SHUTDOWN_MSG: Shutting down NameNode at localhost.localdomain/127.0.0.1\n    ********************************************************/\n\n```", "```scala\n    $ start-dfs.sh \n    14/04/02 09:27:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n    Starting namenodes on [localhost]\n    localhost: starting namenode, logging to /home/anand/opt/hadoop-2.2.0/logs/hadoop-anand-namenode-localhost.localdomain.out\n    localhost: starting datanode, logging to /home/anand/opt/hadoop-2.2.0/logs/hadoop-anand-datanode-localhost.localdomain.out\n    Starting secondary namenodes [0.0.0.0]\n    0.0.0.0: starting secondarynamenode, logging to /home/anand/opt/hadoop-2.2.0/logs/hadoop-anand-secondarynamenode-localhost.localdomain.out\n    14/04/02 09:27:32 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n\n```", "```scala\n$ jps\n50275 NameNode\n50547 SecondaryNameNode\n50394 DataNode\n51091 Jps  \n```", "```scala\n$ cp $HADOOP_CONF_DIR/mapred-site.xml.template $HADOOP_CONF_DIR/mapred-\nsite.xml  \n```", "```scala\n<property> \n        <name>mapreduce.framework.name</name> \n        <value>yarn</value> \n</property> \n```", "```scala\n<property> \n        <name>yarn.nodemanager.aux-services</name> \n        <value>mapreduce_shuffle</value> \n</property> \n\n<property> \n        <name>yarn.scheduler.minimum-allocation-mb</name> \n        <value>1024</value> \n</property> \n\n<property> \n        <name>yarn.nodemanager.resource.memory-mb</name> \n        <value>4096</value> \n</property> \n\n<property> \n        <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name> \n   <value>org.apache.hadoop.mapred.ShuffleHandler</value> \n</property> \n<property> \n        <name>yarn.nodemanager.vmem-pmem-ratio</name> \n        <value>8</value> \n</property> \n```", "```scala\n$ start-yarn.sh \nstarting yarn daemons\nstarting resourcemanager, logging to /home/anand/opt/hadoop-2.2.0/logs/yarn-anand-resourcemanager-localhost.localdomain.out\nlocalhost: starting nodemanager, logging to /home/anand/opt/hadoop-2.2.0/logs/yarn-anand-nodemanager-localhost.localdomain.out  \n```", "```scala\n$ jps\n50275 NameNode\n50547 SecondaryNameNode\n50394 DataNode\n51091 Jps\n50813 NodeManager\n50716 ResourceManager  \n```", "```scala\n    $ yarn application -list\n    14/04/02 11:41:42 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n    14/04/02 11:41:42 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n    Total number of applications (application-types: [] and states: [SUBMITTED, ACCEPTED, RUNNING]):0\n                    Application-Id          Application-Name        Application-Type          User       Queue               State             Final-State             Progress                          Tracking-URL\n\n```", "```scala\n         <dependency> \n               <groupId>org.codehaus.jackson</groupId> \n               <artifactId>jackson-mapper-asl</artifactId> \n               <version>1.9.13</version> \n         </dependency> \n\n         <dependency> \n               <groupId>org.apache.hadoop</groupId> \n               <artifactId>hadoop-client</artifactId> \n               <version>2.2.0</version> \n               <exclusions> \n                     <exclusion> \n                           <groupId>org.slf4j</groupId> \n                           <artifactId>slf4j-log4j12</artifactId> \n                     </exclusion> \n               </exclusions> \n         </dependency> \n         <dependency> \n               <groupId>org.apache.hadoop</groupId> \n               <artifactId>hadoop-hdfs</artifactId> \n               <version>2.2.0</version> \n               <exclusions> \n                     <exclusion> \n                           <groupId>org.slf4j</groupId> \n                           <artifactId>slf4j-log4j12</artifactId> \n                     </exclusion> \n               </exclusions> \n         </dependency> \n         <!-- Dependency for Storm-Kafka spout --> \n         <dependency> \n               <groupId>org.apache.storm</groupId> \n               <artifactId>storm-kafka</artifactId> \n               <version>1.0.2</version> \n               <exclusions> \n                     <exclusion> \n                           <groupId>org.apache.kafka</groupId> \n                           <artifactId>kafka-clients</artifactId> \n                     </exclusion> \n               </exclusions> \n         </dependency> \n\n         <dependency> \n               <groupId>org.apache.kafka</groupId> \n               <artifactId>kafka_2.10</artifactId> \n               <version>0.9.0.1</version> \n               <exclusions> \n                     <exclusion> \n                           <groupId>com.sun.jdmk</groupId> \n                           <artifactId>jmxtools</artifactId> \n                     </exclusion> \n                     <exclusion> \n                           <groupId>com.sun.jmx</groupId> \n                           <artifactId>jmxri</artifactId> \n                     </exclusion> \n               </exclusions> \n         </dependency> \n\n         <dependency> \n               <groupId>org.apache.storm</groupId> \n               <artifactId>storm-core</artifactId> \n               <version>1.0.2</version> \n               <scope>provided</scope> \n         </dependency> \n   </dependencies> \n   <repositories> \n         <repository> \n               <id>clojars.org</id> \n               <url>http://clojars.org/repo</url> \n         </repository> \n   </repositories> \n```", "```scala\n         // zookeeper hosts for the Kafka cluster \n         BrokerHosts zkHosts = new ZkHosts(\"localhost:2181\"); \n\n         // Create the KafkaReadSpout configuartion \n         // Second argument is the topic name \n         // Third argument is the zookeeper root for Kafka \n         // Fourth argument is consumer group id \n         SpoutConfig kafkaConfig = new SpoutConfig(zkHosts, \"dataTopic\", \"\", \n                     \"id7\"); \n\n         // Specify that the kafka messages are String \n         kafkaConfig.scheme = new SchemeAsMultiScheme(new StringScheme()); \n\n         // We want to consume all the first messages in the topic everytime \n         // we run the topology to help in debugging. In production, this \n         // property should be false \n         kafkaConfig.startOffsetTime = kafka.api.OffsetRequest.EarliestTime(); \n\n         // Now we create the topology \n         TopologyBuilder builder = new TopologyBuilder(); \n\n         // set the kafka spout class \n         builder.setSpout(\"KafkaReadSpout\", new KafkaSpout(kafkaConfig), 1); \n```", "```scala\n         // use \"|\" instead of \",\" for field delimiter \n         RecordFormat format = new DelimitedRecordFormat() \n                     .withFieldDelimiter(\",\"); \n\n         // sync the filesystem after every 1k tuples \n         SyncPolicy syncPolicy = new CountSyncPolicy(1000); \n\n         // rotate files when they reach 5MB \n         FileRotationPolicy rotationPolicy = new FileSizeRotationPolicy(5.0f, \n                     Units.MB); \n\n         FileNameFormat fileNameFormatHDFS = new DefaultFileNameFormat() \n                     .withPath(\"/hdfs-bolt-output/\"); \n\n         HdfsBolt hdfsBolt2 = new HdfsBolt().withFsUrl(\"hdfs://127.0.0.1:8020\") \n                     .withFileNameFormat(fileNameFormatHDFS) \n                     .withRecordFormat(format).withRotationPolicy(rotationPolicy) \n                     .withSyncPolicy(syncPolicy); \n```", "```scala\nHdfsBolt hdfsBolt2 = new HdfsBolt().withFsUrl(\"hdfs://127.0.0.1:8020\") \n                     .withFileNameFormat(fileNameFormatHDFS) \n                     .withRecordFormat(format).withRotationPolicy(rotationPolicy) \n                     .withSyncPolicy(syncPolicy); \n```", "```scala\n# yum install git-core  \n```", "```scala\n$ cd ~/opt\n$ git clone https://github.com/yahoo/storm-yarn.git\n$ cd storm-yarn  \n```", "```scala\n    $ mvn package\n    [INFO] Scanning for projects...\n    [INFO] \n    [INFO] ----------------------------------------------------\n    [INFO] Building storm-yarn 1.0-alpha\n    [INFO] ----------------------------------------------------\n    ...\n    [INFO] ----------------------------------------------------\n    [INFO] BUILD SUCCESS\n    [INFO] ----------------------------------------------------\n    [INFO] Total time: 32.049s\n    [INFO] Finished at: Fri Apr 04 09:45:06 IST 2014\n    [INFO] Final Memory: 14M/152M\n    [INFO] ----------------------------------------------------\n\n```", "```scala\n$ hdfs dfs -mkdir -p  /lib/storm/1.0.2-wip21\n$ hdfs dfs -put lib/storm.zip /lib/storm/1.0.2-wip21/storm.zip  \n```", "```scala\n$ mkdir -p ~/storm-data\n$ cp lib/storm.zip ~/storm-data/\n$ cd ~/storm-data/\n$ unzip storm.zip  \n```", "```scala\nstorm.zookeeper.servers: \n     - \"localhost\" \n\nnimbus.host: \"localhost\" \n\nmaster.initial-num-supervisors: 2 \nmaster.container.size-mb: 128 \n```", "```scala\nexport PATH=$PATH:/home/anand/storm-data/storm-1.0.2-wip21/bin:/home/anand/opt/storm-yarn/bin \n```", "```scala\n$ source ~/.bashrc  \n```", "```scala\n$ ~/opt/zookeeper-3.4.5/bin/zkServer.sh start  \n```", "```scala\n    $ storm-yarn launch ~/storm-data/storm-1.0.2-wip21/conf/storm.yaml \n    14/04/15 10:14:49 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n    14/04/15 10:14:49 INFO yarn.StormOnYarn: Copy App Master jar from local filesystem and add to local environment\n    ... ... \n    14/04/15 10:14:51 INFO impl.YarnClientImpl: Submitted application application_1397537047058_0001 to ResourceManager at /0.0.0.0:8032\n    application_1397537047058_0001\n\n```", "```scala\n    $ yarn application -list\n    14/04/15 10:23:13 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n    Total number of applications (application-types: [] and states: [SUBMITTED, ACCEPTED, RUNNING]):1\n                    Application-Id          Application-Name        Application-Type          User       Queue               State             Final-State             Progress                          Tracking-URL\n    application_1397537047058_0001             Storm-on-Yarn                    YARN         anand    default             RUNNING               UNDEFINED                  50%                                   N/A\n\n```", "```scala\n    $ mkdir ~/.storm\n    $ storm-yarn getStormConfig --appId application_1397537047058_0001 --output ~/.storm/storm.yaml\n    14/04/15 10:32:01 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n    14/04/15 10:32:02 INFO yarn.StormOnYarn: application report for application_1397537047058_0001 :localhost.localdomain:9000\n    14/04/15 10:32:02 INFO yarn.StormOnYarn: Attaching to localhost.localdomain:9000 to talk to app master application_1397537047058_0001\n    14/04/15 10:32:02 INFO yarn.StormMasterCommand: storm.yaml downloaded into /home/anand/.storm/storm.yaml  \n```", "```scala\n$ git clone https://github.com/nathanmarz/storm-starter\n$ cd storm-starter  \n```", "```scala\n$ mvn package -DskipTests  \n```", "```scala\n    $ storm jar target/storm-starter-0.0.1-SNAPSHOT.jar storm.starter.WordCountTopology word-cout-topology\n    545  [main] INFO  backtype.storm.StormSubmitter - Jar not uploaded to master yet. Submitting jar...\n    558  [main] INFO  backtype.storm.StormSubmitter - Uploading topology jar target/storm-starter-0.0.1-SNAPSHOT.jar to assigned location: storm-local/nimbus/inbox/stormjar-9ab704ff-29f3-4b9d-b0ac-e9e41d4399dd.jar\n    609  [main] INFO  backtype.storm.StormSubmitter - Successfully uploaded topology jar to assigned location: storm-local/nimbus/inbox/stormjar-9ab704ff-29f3-4b9d-b0ac-e9e41d4399dd.jar\n    609  [main] INFO  backtype.storm.StormSubmitter - Submitting topology word-cout-topology in distributed mode with conf {\"topology.workers\":3,\"topology.debug\":true}\n    937  [main] INFO  backtype.storm.StormSubmitter - Finished submitting topology: word-cout-topology\n\n```", "```scala\n$ storm-yarn  \n```"]