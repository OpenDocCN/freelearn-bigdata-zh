["```scala\nstorm.scheduler: org.apache.storm.scheduler.IsolationScheduler \n```", "```scala\nisolation.scheduler.machines:  \n  \"Topology-Test1\": 2 \n  \"Topology-Test2\": 1 \n  \"Topology-Test3\": 4 \n```", "```scala\nstorm.scheduler: \"org.apache.storm.scheduler.resource.ResourceAwareScheduler\" \n```", "```scala\npublic T setMemoryLoad(Number onHeap, Number offHeap) \n```", "```scala\npublic T setMemoryLoad(Number onHeap) \n```", "```scala\nSpoutDeclarer spout1 = builder.setSpout(\"spout1\", new spoutComponent(), 4); \nspout1.setMemoryLoad(1024.0, 512.0); \nbuilder.setBolt(\"bolt1\", new boltComponent(), 5).setMemoryLoad(512.0); \n```", "```scala\npublic T setCPULoad(Double amount) \n```", "```scala\nSpoutDeclarer spout1 = builder.setSpout(\"spout1\", new spoutComponent(), 4); \nspout1.setCPULoad(15.0); \nbuilder.setBolt(\"bolt1\", new boltComponent(), 5).setCPULoad(450.0); \n```", "```scala\npublic void setTopologyWorkerMaxHeapSize(Number size) \n```", "```scala\nConfig conf = new Config(); \nconf.setTopologyWorkerMaxHeapSize(1024.0); \n```", "```scala\nsupervisor.memory.capacity.mb: [amount<Double>] \nsupervisor.cpu.capacity: [amount<Double>] \n```", "```scala\nsupervisor.memory.capacity.mb: 10480.0 \nsupervisor.cpu.capacity: 100.0 \n```", "```scala\n//default value if on heap memory requirement is not specified for a component  \ntopology.component.resources.onheap.memory.mb: 128.0 \n\n//default value if off heap memory requirement is not specified for a component  \ntopology.component.resources.offheap.memory.mb: 0.0 \n\n//default value if CPU requirement is not specified for a component  \ntopology.component.cpu.pcore.percent: 10.0 \n\n//default value for the max heap size for a worker   \ntopology.worker.max.heap.size.mb: 768.0 \n```", "```scala\nsupervisor.scheduler.meta: \n  type: GPU \n```", "```scala\nTopologyBuilder builder = new TopologyBuilder(); \nbuilder.setSpout(\"spout\", new SampleSpout(), 1); builder.setBolt(\"bolt1\", new ExampleBolt1(), 1).shuffleGrouping(\"spout\"); \nbuilder.setBolt(\"bolt3\", new SampleBolt2(), 1).shuffleGrouping(\"bolt2\").addConfiguration(\"type\", \"GPU\"); \n```", "```scala\n    private Map<String, ArrayList<SupervisorDetails>> getSupervisorsByType( \n            Collection<SupervisorDetails> supervisorDetails \n    ) { \n        // A map of type -> supervisors, to help with scheduling of components with specific types \n        Map<String, ArrayList<SupervisorDetails>> supervisorsByType = new HashMap<String, ArrayList<SupervisorDetails>>(); \n\n        for (SupervisorDetails supervisor : supervisorDetails) { \n            @SuppressWarnings(\"unchecked\") \n            Map<String, String> metadata = (Map<String, String>) supervisor.getSchedulerMeta(); \n\n            String types; \n\n            if (metadata == null) { \n                types = unType; \n            } else { \n                types = metadata.get(\"types\"); \n\n                if (types == null) { \n                    types = unType; \n                } \n            }\n```", "```scala\n            // If the supervisor has types attached to it, handle it by populating the supervisorsByType map. \n            // Loop through each of the types to handle individually \n            for (String type : types.split(\",\")) { \n                type = type.trim(); \n\n                if (supervisorsByType.containsKey(type)) { \n                    // If we've already seen this type, then just add the supervisor to the existing ArrayList. \n                    supervisorsByType.get(type).add(supervisor); \n                } else { \n                    // If this type is new, then create a new ArrayList<SupervisorDetails>, \n                    // add the current supervisor, and populate the map's type entry with it. \n                    ArrayList<SupervisorDetails> newSupervisorList = new ArrayList<SupervisorDetails>(); \n                    newSupervisorList.add(supervisor); \n                    supervisorsByType.put(type, newSupervisorList); \n                } \n            } \n        } \n\n        return supervisorsByType; \n    } \n```", "```scala\n    private <T> void populateComponentsByType( \n            Map<String, ArrayList<String>> componentsByType, \n            Map<String, T> components \n    ) { \n        // Type T can be either Bolt or SpoutSpec, so that this logic can be reused for both component types \n        JSONParser parser = new JSONParser(); \n\n        for (Entry<String, T> componentEntry : components.entrySet()) { \n            JSONObject conf = null; \n\n            String componentID = componentEntry.getKey(); \n            T component = componentEntry.getValue(); \n\n            try { \n                // Get the component's conf irrespective of its type (via java reflection) \n                Method getCommonComponentMethod = component.getClass().getMethod(\"get_common\"); \n                ComponentCommon commonComponent = (ComponentCommon) getCommonComponentMethod.invoke(component); \n                conf = (JSONObject) parser.parse(commonComponent.get_json_conf()); \n            } catch (Exception ex) { \n                ex.printStackTrace(); \n            } \n\n            String types; \n\n            // If there's no config, use a fake type to group all untypeged components \n            if (conf == null) { \n                types = unType; \n            } else { \n                types = (String) conf.get(\"types\"); \n\n                // If there are no types, use a fake type to group all untypeged components \n                if (types == null) { \n                    types = unType; \n                } \n            } \n\n            // If the component has types attached to it, handle it by populating the componentsByType map. \n            // Loop through each of the types to handle individually \n            for (String type : types.split(\",\")) { \n                type = type.trim(); \n\n                if (componentsByType.containsKey(type)) { \n                    // If we've already seen this type, then just add the component to the existing ArrayList. \n                    componentsByType.get(type).add(componentID); \n                } else { \n                    // If this type is new, then create a new ArrayList, \n                    // add the current component, and populate the map's type entry with it. \n                    ArrayList<String> newComponentList = new ArrayList<String>(); \n                    newComponentList.add(componentID); \n                    componentsByType.put(type, newComponentList); \n                } \n            } \n        } \n    } \n```", "```scala\n    private void populateComponentsByTypeWithStormInternals( \n            Map<String, ArrayList<String>> componentsByType, \n            Set<String> components \n    ) { \n        // Storm uses some internal components, like __acker. \n        // These components are topology-agnostic and are therefore not accessible through a StormTopology object. \n        // While a bit hacky, this is a way to make sure that we schedule those components along with our topology ones: \n        // we treat these internal components as regular untypeged components and add them to the componentsByType map. \n\n        for (String componentID : components) { \n            if (componentID.startsWith(\"__\")) { \n                if (componentsByType.containsKey(unType)) { \n                    // If we've already seen untypeged components, then just add the component to the existing ArrayList. \n                    componentsByType.get(unType).add(componentID); \n                } else { \n                    // If this is the first untypeged component we see, then create a new ArrayList, \n                    // add the current component, and populate the map's untypeged entry with it. \n                    ArrayList<String> newComponentList = new ArrayList<String>(); \n                    newComponentList.add(componentID); \n                    componentsByType.put(unType, newComponentList); \n                } \n            } \n        } \n    } \n```", "```scala\n    private void typeAwareSchedule(Topologies topologies, Cluster cluster) { \n        Collection<SupervisorDetails> supervisorDetails = cluster.getSupervisors().values(); \n\n        // Get the lists of typed and unreserved supervisors. \n        Map<String, ArrayList<SupervisorDetails>> supervisorsByType = getSupervisorsByType(supervisorDetails); \n\n        for (TopologyDetails topologyDetails : cluster.needsSchedulingTopologies(topologies)) { \n            StormTopology stormTopology = topologyDetails.getTopology(); \n            String topologyID = topologyDetails.getId(); \n\n            // Get components from topology \n            Map<String, Bolt> bolts = stormTopology.get_bolts(); \n            Map<String, SpoutSpec> spouts = stormTopology.get_spouts(); \n\n            // Get a map of component to executors \n            Map<String, List<ExecutorDetails>> executorsByComponent = cluster.getNeedsSchedulingComponentToExecutors( \n                    topologyDetails \n            ); \n\n            // Get a map of type to components \n            Map<String, ArrayList<String>> componentsByType = new HashMap<String, ArrayList<String>>(); \n            populateComponentsByType(componentsByType, bolts); \n            populateComponentsByType(componentsByType, spouts); \n            populateComponentsByTypeWithStormInternals(componentsByType, executorsByComponent.keySet()); \n\n            // Get a map of type to executors \n            Map<String, ArrayList<ExecutorDetails>> executorsToBeScheduledByType = getExecutorsToBeScheduledByType( \n                    cluster, topologyDetails, componentsByType \n            ); \n\n            // Initialise a map of slot -> executors \n            Map<WorkerSlot, ArrayList<ExecutorDetails>> componentExecutorsToSlotsMap = ( \n                    new HashMap<WorkerSlot, ArrayList<ExecutorDetails>>() \n            ); \n\n            // Time to match everything up! \n            for (Entry<String, ArrayList<ExecutorDetails>> entry : executorsToBeScheduledByType.entrySet()) { \n                String type = entry.getKey(); \n\n                ArrayList<ExecutorDetails> executorsForType = entry.getValue(); \n                ArrayList<SupervisorDetails> supervisorsForType = supervisorsByType.get(type); \n                ArrayList<String> componentsForType = componentsByType.get(type); \n\n                try { \n                    populateComponentExecutorsToSlotsMap( \n                            componentExecutorsToSlotsMap, \n                            cluster, topologyDetails, supervisorsForType, executorsForType, componentsForType, type \n                    ); \n                } catch (Exception e) { \n                    e.printStackTrace(); \n\n                    // Cut this scheduling short to avoid partial scheduling. \n                    return; \n                } \n            } \n\n            // Do the actual assigning \n            // We do this as a separate step to only perform any assigning if there have been no issues so far. \n            // That's aimed at avoiding partial scheduling from occurring, with some components already scheduled \n            // and alive, while others cannot be scheduled. \n            for (Entry<WorkerSlot, ArrayList<ExecutorDetails>> entry : componentExecutorsToSlotsMap.entrySet()) { \n                WorkerSlot slotToAssign = entry.getKey(); \n                ArrayList<ExecutorDetails> executorsToAssign = entry.getValue(); \n\n                cluster.assign(slotToAssign, topologyID, executorsToAssign); \n            } \n\n            // If we've reached this far, then scheduling must have been successful \n            cluster.setStatus(topologyID, \"SCHEDULING SUCCESSFUL\"); \n        } \n    } \n```", "```scala\nprivate Set<ExecutorDetails> getAllAliveExecutors(Cluster cluster, TopologyDetails topologyDetails) { \n        // Get the existing assignment of the current topology as it's live in the cluster \n        SchedulerAssignment existingAssignment = cluster.getAssignmentById(topologyDetails.getId()); \n\n        // Return alive executors, if any, otherwise an empty set \n        if (existingAssignment != null) { \n            return existingAssignment.getExecutors(); \n        } else { \n            return new HashSet<ExecutorDetails>(); \n        } \n    } \n\n    private Map<String, ArrayList<ExecutorDetails>> getExecutorsToBeScheduledByType( \n            Cluster cluster, \n            TopologyDetails topologyDetails, \n            Map<String, ArrayList<String>> componentsPerType \n    ) { \n        // Initialise the return value \n        Map<String, ArrayList<ExecutorDetails>> executorsByType = new HashMap<String, ArrayList<ExecutorDetails>>(); \n\n        // Find which topology executors are already assigned \n        Set<ExecutorDetails> aliveExecutors = getAllAliveExecutors(cluster, topologyDetails); \n\n        // Get a map of component to executors for the topology that need scheduling \n        Map<String, List<ExecutorDetails>> executorsByComponent = cluster.getNeedsSchedulingComponentToExecutors( \n                topologyDetails \n        ); \n\n        // Loop through componentsPerType to populate the map \n        for (Entry<String, ArrayList<String>> entry : componentsPerType.entrySet()) { \n            String type = entry.getKey(); \n            ArrayList<String> componentIDs = entry.getValue(); \n\n            // Initialise the map entry for the current type \n            ArrayList<ExecutorDetails> executorsForType = new ArrayList<ExecutorDetails>(); \n\n            // Loop through this type's component IDs \n            for (String componentID : componentIDs) { \n                // Fetch the executors for the current component ID \n                List<ExecutorDetails> executorsForComponent = executorsByComponent.get(componentID); \n\n                if (executorsForComponent == null) { \n                    continue; \n                } \n\n                // Convert the list of executors to a set \n                Set<ExecutorDetails> executorsToAssignForComponent = new HashSet<ExecutorDetails>( \n                        executorsForComponent \n                ); \n\n                // Remove already assigned executors from the set of executors to assign, if any \n                executorsToAssignForComponent.removeAll(aliveExecutors); \n\n                // Add the component's waiting to be assigned executors to the current type executors \n                executorsForType.addAll(executorsToAssignForComponent); \n            } \n\n            // Populate the map of executors by type after looping through all of the type's components, \n            // if there are any executors to be scheduled \n            if (!executorsForType.isEmpty()) { \n                executorsByType.put(type, executorsForType); \n            } \n        } \n\n        return executorsByType; \n} \n```", "```scala\n    private void handleFailedScheduling( \n            Cluster cluster, \n            TopologyDetails topologyDetails, \n            String message \n    ) throws Exception { \n        // This is the prefix of the message displayed on Storm's UI for any unsuccessful scheduling \n        String unsuccessfulSchedulingMessage = \"SCHEDULING FAILED: \"; \n\n        cluster.setStatus(topologyDetails.getId(), unsuccessfulSchedulingMessage + message); \n        throw new Exception(message); \n    } \n\n    private Set<WorkerSlot> getAllAliveSlots(Cluster cluster, TopologyDetails topologyDetails) { \n        // Get the existing assignment of the current topology as it's live in the cluster \n        SchedulerAssignment existingAssignment = cluster.getAssignmentById(topologyDetails.getId()); \n\n        // Return alive slots, if any, otherwise an empty set \n        if (existingAssignment != null) { \n            return existingAssignment.getSlots(); \n        } else { \n            return new HashSet<WorkerSlot>(); \n        } \n    } \n\n    private List<WorkerSlot> getAllSlotsToAssign( \n            Cluster cluster, \n            TopologyDetails topologyDetails, \n            List<SupervisorDetails> supervisors, \n            List<String> componentsForType, \n            String type \n    ) throws Exception { \n        String topologyID = topologyDetails.getId(); \n\n        // Collect the available slots of each of the supervisors we were given in a list \n        List<WorkerSlot> availableSlots = new ArrayList<WorkerSlot>(); \n        for (SupervisorDetails supervisor : supervisors) { \n            availableSlots.addAll(cluster.getAvailableSlots(supervisor)); \n        } \n\n        if (availableSlots.isEmpty()) { \n            // This is bad, we have supervisors and executors to assign, but no available slots! \n            String message = String.format( \n                    \"No slots are available for assigning executors for type %s (components: %s)\", \n                    type, componentsForType \n            ); \n            handleFailedScheduling(cluster, topologyDetails, message); \n        } \n\n        Set<WorkerSlot> aliveSlots = getAllAliveSlots(cluster, topologyDetails); \n\n        int numAvailableSlots = availableSlots.size(); \n        int numSlotsNeeded = topologyDetails.getNumWorkers() - aliveSlots.size(); \n\n        // We want to check that we have enough available slots \n        // based on the topology's number of workers and already assigned slots. \n        if (numAvailableSlots < numSlotsNeeded) { \n            // This is bad, we don't have enough slots to assign to! \n            String message = String.format( \n                    \"Not enough slots available for assigning executors for type %s (components: %s). \" \n                            + \"Need %s slots to schedule but found only %s\", \n                    type, componentsForType, numSlotsNeeded, numAvailableSlots \n            ); \n            handleFailedScheduling(cluster, topologyDetails, message); \n        } \n\n        // Now we can use only as many slots as are required. \n        return availableSlots.subList(0, numSlotsNeeded); \n    } \n\n    private Map<WorkerSlot, ArrayList<ExecutorDetails>> getAllExecutorsBySlot( \n            List<WorkerSlot> slots, \n            List<ExecutorDetails> executors \n    ) { \n        Map<WorkerSlot, ArrayList<ExecutorDetails>> assignments = new HashMap<WorkerSlot, ArrayList<ExecutorDetails>>(); \n\n        int numberOfSlots = slots.size(); \n\n        // We want to split the executors as evenly as possible, across each slot available, \n        // so we assign each executor to a slot via round robin \n        for (int i = 0; i < executors.size(); i++) { \n            WorkerSlot slotToAssign = slots.get(i % numberOfSlots); \n            ExecutorDetails executorToAssign = executors.get(i); \n\n            if (assignments.containsKey(slotToAssign)) { \n                // If we've already seen this slot, then just add the executor to the existing ArrayList. \n                assignments.get(slotToAssign).add(executorToAssign); \n            } else { \n                // If this slot is new, then create a new ArrayList, \n                // add the current executor, and populate the map's slot entry with it. \n                ArrayList<ExecutorDetails> newExecutorList = new ArrayList<ExecutorDetails>(); \n                newExecutorList.add(executorToAssign); \n                assignments.put(slotToAssign, newExecutorList); \n            } \n        } \n\n        return assignments; \n    } \n\n    private void populateComponentExecutorsToSlotsMap( \n            Map<WorkerSlot, ArrayList<ExecutorDetails>> componentExecutorsToSlotsMap, \n            Cluster cluster, \n            TopologyDetails topologyDetails, \n            List<SupervisorDetails> supervisors, \n            List<ExecutorDetails> executors, \n            List<String> componentsForType, \n            String type \n    ) throws Exception { \n        String topologyID = topologyDetails.getId(); \n\n        if (supervisors == null) { \n            // This is bad, we don't have any supervisors but have executors to assign! \n            String message = String.format( \n                    \"No supervisors given for executors %s of topology %s and type %s (components: %s)\", \n                    executors, topologyID, type, componentsForType \n            ); \n            handleFailedScheduling(cluster, topologyDetails, message); \n        } \n\n        List<WorkerSlot> slotsToAssign = getAllSlotsToAssign( \n                cluster, topologyDetails, supervisors, componentsForType, type \n        ); \n\n        // Divide the executors evenly across the slots and get a map of slot to executors \n        Map<WorkerSlot, ArrayList<ExecutorDetails>> executorsBySlot = getAllExecutorsBySlot( \n                slotsToAssign, executors \n        ); \n\n        for (Entry<WorkerSlot, ArrayList<ExecutorDetails>> entry : executorsBySlot.entrySet()) { \n            WorkerSlot slotToAssign = entry.getKey(); \n            ArrayList<ExecutorDetails> executorsToAssign = entry.getValue(); \n\n            // Assign the topology's executors to slots in the cluster's supervisors \n            componentExecutorsToSlotsMap.put(slotToAssign, executorsToAssign); \n        } \n    } \n```", "```scala\nstorm.scheduler: \"com.stormadvance.storm_kafka_topology.CustomScheduler\" \n```"]