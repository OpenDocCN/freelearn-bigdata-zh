["```scala\ntar -xvzf kafka_2.10-0.9.0.1.tgz\ncd kafka_2.10-0.9.0.1  \n```", "```scala\nlog.dirs=/var/kafka-logszookeeper.connect=zoo1:2181,zoo2:2181,zoo3:2181\n```", "```scala\n\n> ./bin/kafka-server-start.sh config/server.properties \n\n[2017-04-23 17:44:36,667] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)\n[2017-04-23 17:44:36,668] INFO Kafka version : 0.9.0.1 (org.apache.kafka.common.utils.AppInfoParser)\n[2017-04-23 17:44:36,668] INFO Kafka commitId : a7a17cdec9eaa6c5 (org.apache.kafka.common.utils.AppInfoParser)\n[2017-04-23 17:44:36,670] INFO [Kafka Server 0], started (kafka.server.KafkaServer)  \n```", "```scala\n\n> bin/kafka-topics.sh --zookeeper zoo1:2181 --replication-factor 1 --partition 1 --topic verification-topic --create\n\nCreated topic \"verification-topic\".  \n```", "```scala\n\n> bin/kafka-topics.sh --zookeeper zoo1:2181 --list\n\nverification-topic  \n```", "```scala\n\n> bin/kafka-console-producer.sh --broker-list localhost:9092 --topic verification-topic    \n\n```", "```scala\nMessage 1\nTest Message 2\nMessage 3  \n```", "```scala\n> bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic verification-topic --from-beginning\n\nMessage 1\nTest Message 2\nMessage 3  \n```", "```scala\nbroker.id=0\nport=9092\nhost.name=kafka1\nlog.dirs=/var/kafka-logs\nzookeeper.connect=zoo1:2181,zoo2:2181,zoo3:2181\n```", "```scala\n> ./bin/kafka-server-start.sh config/server.properties\n```", "```scala\n> bin/kafka-topics.sh --zookeeper zoo1:2181 --replication-factor 4 --partition 1 --topic verification --create\n\n    Created topic \"verification-topic\".  \n```", "```scala\n> bin/kafka-topics.sh --zookeeper zoo1:2181 --list\n\n                topic: verification     partition: 0      leader: 0   replicas: 0             isr: 0\n                topic: verification     partition: 1      leader: 1   replicas: 1             isr: 1\n                topic: verification     partition: 2      leader: 2   replicas: 2             isr: 2  \n```", "```scala\n> bin/kafka-console-producer.sh --broker-list kafka1:9092,kafka2:9092,kafka3:9092 --topic verification  \n```", "```scala\nFirst\nSecond\nThird  \n```", "```scala\n> bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic verification --from-beginning\n\nFirst\nSecond\nThird \n```", "```scala\nbroker.id=0 \nport=9092 \nlog.dirs=/var/kafka-logs \nzookeeper.connect=zoo1:2181,zoo2:2181,zoo3:2181 \n```", "```scala\nbroker.id=1 \nport=9093 \nlog.dirs=/var/kafka-1-logs \nzookeeper.connect=zoo1:2181,zoo2:2181,zoo3:2181 \n```", "```scala\nbroker.id=2 \nport=9094 \nlog.dirs=/var/kafka-2-logs \nzookeeper.connect=zoo1:2181,zoo2:2181,zoo3:2181 \n```", "```scala\n> ./bin/kafka-server-start.sh config/server.properties\n> ./bin/kafka-server-start.sh config/server1.properties\n> ./bin/kafka-server-start.sh config/server2.properties\n\n```", "```scala\n> bin/zkCli.sh  \n```", "```scala\n> [zk: localhost:2181(CONNECTED) 0] ls /\n\n**[storm, consumers, isr_change_notification, zookeeper, admin, brokers]**\n```", "```scala\n<dependency> \n  <groupId>org.apache.kafka</groupId> \n  <artifactId>kafka_2.10</artifactId> \n  <version>0.9.0.1</version> \n  <exclusions> \n    <exclusion> \n      <groupId>com.sun.jdmk</groupId> \n      <artifactId>jmxtools</artifactId> \n    </exclusion> \n    <exclusion> \n      <groupId>com.sun.jmx</groupId> \n      <artifactId>jmxri</artifactId> \n    </exclusion> \n  </exclusions> \n</dependency> \n<dependency> \n  <groupId>org.apache.logging.log4j</groupId> \n  <artifactId>log4j-slf4j-impl</artifactId> \n  <version>2.0-beta9</version> \n</dependency> \n<dependency> \n  <groupId>org.apache.logging.log4j</groupId> \n  <artifactId>log4j-1.2-api</artifactId> \n  <version>2.0-beta9</version> \n</dependency>  \n```", "```scala\n<build> \n  <plugins> \n    <plugin> \n      <groupId>org.codehaus.mojo</groupId> \n      <artifactId>exec-maven-plugin</artifactId> \n      <version>1.2.1</version> \n      <executions> \n        <execution> \n          <goals> \n            <goal>exec</goal> \n          </goals> \n        </execution> \n      </executions> \n      <configuration> \n        <executable>java</executable\n        <includeProjectDependencies>true</includeProjectDependencies\n        <includePluginDependencies>false</includePluginDependencies> \n        <classpathScope>compile</classpathScope> \n        <mainClass>com.stormadvance.kafka_producer. KafkaSampleProducer \n        </mainClass> \n      </configuration> \n    </plugin> \n  </plugins> \n</build> \n```", "```scala\npublic class KafkaSampleProducer { \n  public static void main(String[] args) { \n    // Build the configuration required for connecting to Kafka \n    Properties props = new Properties(); \n\n    // List of kafka borkers. Complete list of brokers is not required as \n    // the producer will auto discover the rest of the brokers. \n    props.put(\"bootstrap.servers\", \"Broker1-IP:9092\"); \n    props.put(\"batch.size\", 1); \n    // Serializer used for sending data to kafka. Since we are sending string, \n    // we are using StringSerializer. \n    props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); \n    props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); \n\n    props.put(\"producer.type\", \"sync\"); \n\n    // Create the producer instance \n    Producer<String, String> producer = new KafkaProducer<String, String>(props); \n\n    // Now we break each word from the paragraph \n    for (String word : METAMORPHOSIS_OPENING_PARA.split(\"\\\\s\")) { \n      System.out.println(\"word : \" + word); \n      // Create message to be sent to \"new_topic\" topic with the word \n      ProducerRecord<String, String> data = new ProducerRecord<String, String>(\"new_topic\",word, word); \n      // Send the message \n      producer.send(data); \n    } \n\n    // close the producer \n    producer.close(); \n    System.out.println(\"end : \"); \n  } \n\n  // First paragraph from Franz Kafka's Metamorphosis \n  private static String METAMORPHOSIS_OPENING_PARA = \"One morning, when Gregor Samsa woke from troubled dreams, he found \" \n               + \"himself transformed in his bed into a horrible vermin.  He lay on \" \n               + \"his armour-like back, and if he lifted his head a little he could \" \n               + \"see his brown belly, slightly domed and divided by arches into stiff \" \n               + \"sections.  The bedding was hardly able to cover it and seemed ready \" \n               + \"to slide off any moment.  His many legs, pitifully thin compared \" \n               + \"with the size of the rest of him, waved about helplessly as he \" \n               + \"looked.\"; \n\n}  \n```", "```scala\n\n> bin/kafka-topics.sh --zookeeper ZK1:2181 --replication-factor 1 --partition 1 --topic new_topic --create \n\nCreated topic \"new_topic1\".    \n\n```", "```scala\n> mvn compile exec:java\n......\n103  [com.learningstorm.kafka.WordsProducer.main()] INFO                kafka.client.ClientUti\nls$  - Fetching metadata from broker                                    id:0,host:kafka1,port:9092 with correlation id 0 for 1                  topic(s) Set(words_topic)\n110  [com.learningstorm.kafka.WordsProducer.main()] INFO                kafka.producer.SyncProducer  - Connected to kafka1:9092 for             producing\n140  [com.learningstorm.kafka.WordsProducer.main()] INFO                kafka.producer.SyncProducer  - Disconnecting from                       kafka1:9092\n177  [com.learningstorm.kafka.WordsProducer.main()] INFO                kafka.producer.SyncProducer  - Connected to kafka1:9092 for             producing\n378  [com.learningstorm.kafka.WordsProducer.main()] INFO                kafka.producer.Producer  - Shutting down producer\n378  [com.learningstorm.kafka.WordsProducer.main()] INFO                kafka.producer.ProducerPool  - Closing all sync producers\n381  [com.learningstorm.kafka.WordsProducer.main()] INFO                kafka.producer.SyncProducer  - Disconnecting from                       kafka1:9092\n```", "```scala\n> bin/kafka-console-consumer.sh --zookeeper ZK:2181 --topic verification --from-beginning\n\n                One\n                morning,\n                when\n                Gregor\n                Samsa\n                woke\n                from\n                troubled\n                dreams,\n                he\n                found\n                himself\n                transformed\n                in\n                his\n                bed\n                into\n                a\n                horrible\n                vermin.\n                ......\n```", "```scala\n<dependency> \n  <groupId>org.apache.storm</groupId> \n  <artifactId>storm-kafka</artifactId> \n  <version>1.0.2</version> \n  <exclusions> \n    <exclusion> \n      <groupId>org.apache.kafka</groupId> \n      <artifactId>kafka-clients</artifactId> \n    </exclusion> \n  </exclusions> \n</dependency> \n\n<dependency> \n  <groupId>org.apache.kafka</groupId> \n  <artifactId>kafka_2.10</artifactId> \n  <version>0.9.0.1</version> \n  <exclusions> \n    <exclusion> \n      <groupId>com.sun.jdmk</groupId> \n      <artifactId>jmxtools</artifactId> \n    </exclusion> \n    <exclusion> \n      <groupId>com.sun.jmx</groupId> \n      <artifactId>jmxri</artifactId> \n    </exclusion> \n  </exclusions> \n</dependency> \n\n<dependency> \n  <groupId>org.apache.storm</groupId> \n  <artifactId>storm-core</artifactId> \n  <version>1.0.2</version> \n  <scope>provided</scope> \n</dependency> \n<dependency> \n  <groupId>commons-collections</groupId> \n  <artifactId>commons-collections</artifactId> \n  <version>3.2.1</version> \n</dependency> \n\n<dependency> \n  <groupId>com.google.guava</groupId> \n  <artifactId>guava</artifactId> \n  <version>15.0</version> \n</dependency>  \n```", "```scala\n<build> \n  <plugins> \n    <plugin> \n      <artifactId>maven-assembly-plugin</artifactId> \n      <configuration> \n        <descriptorRefs> \n          descriptorRef>jar-with-dependencies</descriptorRef> \n        </descriptorRefs> \n        <archive> \n          <manifest> \n            <mainClass></mainClass> \n          </manifest> \n        </archive> \n      </configuration> \n      <executions> \n        <execution> \n          <id>make-assembly</id> \n          <phase>package</phase> \n          <goals> \n            <goal>single</goal> \n          </goals> \n        </execution> \n      </executions> \n    </plugin> \n\n    <plugin> \n      <groupId>org.codehaus.mojo</groupId> \n      <artifactId>exec-maven-plugin</artifactId> \n      <version>1.2.1</version> \n      <executions> \n        <execution> \n          <goals> \n            <goal>exec</goal> \n          </goals> \n        </execution> \n      </executions> \n      <configuration> \n        <executable>java</executable\n        <includeProjectDependencies>true</includeProjectDependencies\n        <includePluginDependencies>false</includePluginDependencies> \n        <classpathScope>compile</classpathScope> \n        <mainClass>${main.class}</mainClass> \n      </configuration> \n    </plugin> \n\n    <plugin> \n      <groupId>org.apache.maven.plugins</groupId> \n      <artifactId>maven-compiler-plugin</artifactId> \n    </plugin> \n\n  </plugins> \n</build> \n```", "```scala\npublic class WordBolt extends BaseBasicBolt { \n\n  private static final long serialVersionUID = -5353547217135922477L; \n\n  // list used for aggregating the words \n  private List<String> words = new ArrayList<String>(); \n\n  public void execute(Tuple input, BasicOutputCollector collector) { \n    System.out.println(\"called\"); \n    // Get the word from the tuple \n    String word = input.getString(0); \n\n    if (StringUtils.isBlank(word)) { \n      // ignore blank lines \n      return; \n    } \n\n    System.out.println(\"Received Word:\" + word); \n\n    // add word to current list of words \n    words.add(word); \n\n    if (word.endsWith(\".\")) { \n      // word ends with '.' which means this is // the end of the sentence \n      // publish a sentence tuple \n      collector.emit(ImmutableList.of((Object) StringUtils.join(words, ' '))); \n\n      // reset the words list. \n      words.clear(); \n    } \n  } \n\n  public void declareOutputFields(OutputFieldsDeclarer declarer) { \n    // here we declare we will be emitting tuples with \n    // a single field called \"sentence\" \n    declarer.declare(new Fields(\"sentence\")); \n  } \n} \n```", "```scala\npublic class SentenceBolt extends BaseBasicBolt { \n\n  private static final long serialVersionUID = 7104400131657100876L; \n\n  public void execute(Tuple input, BasicOutputCollector collector) { \n    // get the sentence from the tuple and print it \n    System.out.println(\"Recieved Sentence:\"); \n    String sentence = input.getString(0); \n    System.out.println(\"Recieved Sentence:\" + sentence); \n  } \n\n  public void declareOutputFields(OutputFieldsDeclarer declarer) { \n         // we don't emit anything \n  } \n} \n```", "```scala\npublic class KafkaTopology { \n  public static void main(String[] args) { \n    try { \n      // ZooKeeper hosts for the Kafka cluster \n      BrokerHosts zkHosts = new ZkHosts(\"ZKIP:PORT\"); \n\n      // Create the KafkaSpout configuartion \n      // Second argument is the topic name \n      // Third argument is the zookeepr root for Kafka \n      // Fourth argument is consumer group id \n      SpoutConfig kafkaConfig = new SpoutConfig(zkHosts, \"new_topic\", \"\", \"id1\"); \n\n      // Specify that the kafka messages are String \n      // We want to consume all the first messages in the topic everytime \n      // we run the topology to help in debugging. In production, this \n      // property should be false \n      kafkaConfig.scheme = new SchemeAsMultiScheme(new StringScheme()); \n      kafkaConfig.startOffsetTime = kafka.api.OffsetRequest.EarliestTime(); \n\n      // Now we create the topology \n      TopologyBuilder builder = new TopologyBuilder(); \n\n      // set the kafka spout class \n      builder.setSpout(\"KafkaSpout\", new KafkaSpout(kafkaConfig), 2); \n\n      // set the word and sentence bolt class \n      builder.setBolt(\"WordBolt\", new WordBolt(), 1).globalGrouping(\"KafkaSpout\"); \n      builder.setBolt(\"SentenceBolt\", new SentenceBolt(), 1).globalGrouping(\"WordBolt\"); \n\n      // create an instance of LocalCluster class for executing topology \n      // in local mode. \n      LocalCluster cluster = new LocalCluster(); \n      Config conf = new Config(); \n      conf.setDebug(true); \n      if (args.length > 0) { \n        conf.setNumWorkers(2); \n        conf.setMaxSpoutPending(5000); \n        StormSubmitter.submitTopology(\"KafkaToplogy1\", conf, builder.createTopology()); \n\n      } else { \n        // Submit topology for execution \n        cluster.submitTopology(\"KafkaToplogy1\", conf, builder.createTopology()); \n        System.out.println(\"called1\"); \n        Thread.sleep(1000000); \n        // Wait for sometime before exiting \n        System.out.println(\"Waiting to consume from kafka\"); \n\n        System.out.println(\"called2\"); \n        // kill the KafkaTopology \n        cluster.killTopology(\"KafkaToplogy1\"); \n        System.out.println(\"called3\"); \n        // shutdown the storm test cluster \n        cluster.shutdown(); \n      } \n\n    } catch (Exception exception) { \n      System.out.println(\"Thread interrupted exception : \" + exception); \n    } \n  } \n} \n```", "```scala\n> mvn clean compile exec:java  -Dmain.class=com.stormadvance.kafka.KafkaTopology \n```", "```scala\nRecieved Word:One\nRecieved Word:morning,\nRecieved Word:when\nRecieved Word:Gregor\nRecieved Word:Samsa\nRecieved Word:woke\nRecieved Word:from\nRecieved Word:troubled\nRecieved Word:dreams,\nRecieved Word:he\nRecieved Word:found\nRecieved Word:himself\nRecieved Word:transformed\nRecieved Word:in\nRecieved Word:his\nRecieved Word:bed\nRecieved Word:into\nRecieved Word:a\nRecieved Word:horrible\nRecieved Word:vermin.\nRecieved Sentence:One morning, when Gregor Samsa woke from              troubled dreams, he found himself transformed in his bed                   into a horrible vermin.  \n```", "```scala\nmvn clean install\n```", "```scala\n------------------------------------------------------------------ ----- [INFO] ----------------------------------------------------------- ----- [INFO] BUILD SUCCESS [INFO] ----------------------------------------------------------- ----- [INFO] Total time: 58.326s [INFO] Finished at: [INFO] Final Memory: 14M/116M [INFO] ----------------------------------------------------------- -----\n```", "```scala\nbin/storm jar jarName.jar [TopologyMainClass] [Args]\n```", "```scala\n$> cd $STORM_HOME\n$> bin/storm jar ~/storm-kafka-topology-0.0.1-SNAPSHOT-jar-with-dependencies.jar com.stormadvance.kafka.KafkaTopology KafkaTopology1\n```"]