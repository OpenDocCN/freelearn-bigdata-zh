["```py\n1  2\n1  3\n2  3\n3  5\n```", "```py\npackage com.tomekl007.chapter_7\n\nimport org.apache.spark.SparkContext\nimport org.apache.spark.sql.SparkSession\nimport org.scalatest.FunSuite\n\nclass CreatingGraph extends FunSuite {\n  val spark: SparkContext = SparkSession.builder().master(\"local[2]\").getOrCreate().sparkContext\n\n  test(\"should load graph from a file\") {\n    //given\n    val path = getClass.getResource(\"/graph.g\").getPath\n```", "```py\n    //when\n    val graph = GraphBuilder.loadFromFile(spark, path)\n```", "```py\npackage com.tomekl007.chapter_7\n\nimport org.apache.spark.SparkContext\nimport org.apache.spark.graphx.{Graph, GraphLoader}\n\nobject GraphBuilder {\n\n  def loadFromFile(sc: SparkContext, path: String): Graph[Int, Int] = {\n    GraphLoader.edgeListFile(sc, path)\n  }\n}\n```", "```py\n  val graph = GraphBuilder.loadFromFile(spark, path)\n```", "```py\n    //then\n    graph.triplets.foreach(println(_))\n```", "```py\n    assert(graph.triplets.count() == 4)\n  }\n\n}\n```", "```py\npackage com.tomekl007.chapter_7\n\nimport org.apache.spark.SparkContext\nimport org.apache.spark.graphx.{Edge, Graph, VertexId}\nimport org.apache.spark.rdd.RDD\nimport org.apache.spark.sql.SparkSession\nimport org.scalatest.FunSuite\n\nclass VertexAPI extends FunSuite {\n  val spark: SparkContext = SparkSession.builder().master(\"local[2]\").getOrCreate().sparkContext\n\n  test(\"Should use Vertex API\") {\n    //given\n    val users: RDD[(VertexId, (String))] =\n      spark.parallelize(Array(\n        (1L, \"a\"),\n        (2L, \"b\"),\n        (3L, \"c\"),\n        (4L, \"d\")\n      ))\n```", "```py\ntype VertexID = Long\n```", "```py\n    val users: RDD[(VertexId, (String))] =\n      spark.parallelize(Array(\n        (1L, \"a\"),\n        (2L, \"b\"),\n        (3L, \"c\"),\n        (4L, \"d\")\n      ))\n```", "```py\n    val relationships =\n      spark.parallelize(Array(\n        Edge(1L, 2L, \"friend\"),\n        Edge(1L, 3L, \"friend\"),\n        Edge(2L, 4L, \"wife\")\n      ))\n```", "```py\n    val graph = Graph(users, relationships)\n```", "```py\n    val res = graph.mapVertices((_, att) => att.toUpperCase())\n```", "```py\n    val users: RDD[(VertexId, (String))] =\n      spark.parallelize(Array(\n        (1L, \"a\"),\n        (2L, \"b\"),\n        (3L, \"c\"),\n        (4L, \"d\")\n      ))\n```", "```py\n    println(res.vertices.collect().toList)\n  }\n\n}\n```", "```py\nimport org.apache.spark.SparkContext\nimport org.apache.spark.graphx.{Edge, Graph, VertexId}\nimport org.apache.spark.rdd.RDD\nimport org.apache.spark.sql.SparkSession\nimport org.scalatest.FunSuite\n\nclass EdgeAPI extends FunSuite {\n  val spark: SparkContext = SparkSession.builder().master(\"local[2]\").getOrCreate().sparkContext\n\n  test(\"Should use Edge API\") {\n    //given\n    val users: RDD[(VertexId, (String))] =\n      spark.parallelize(Array(\n        (1L, \"a\"),\n        (2L, \"b\"),\n        (3L, \"c\"),\n        (4L, \"d\")\n      ))\n\n    val relationships =\n      spark.parallelize(Array(\n        Edge(1L, 2L, \"friend\"),\n        Edge(1L, 3L, \"friend\"),\n        Edge(2L, 4L, \"wife\")\n      ))\n\n    val graph = Graph(users, relationships)\n\n    //when\n val resFromFilter = graph.edges.filter((e1) => e1.attr == \"friend\").collect().toList\n println(resFromFilter)\n```", "```py\n    val res = graph.mapEdges(e => e.attr.toUpperCase)\n```", "```py\n    println(res.edges.collect().toList)\n```", "```py\npackage com.tomekl007.chapter_7\n\nimport org.apache.spark.SparkContext\nimport org.apache.spark.graphx.{Edge, Graph, VertexId}\nimport org.apache.spark.rdd.RDD\nimport org.apache.spark.sql.SparkSession\nimport org.scalatest.FunSuite\nimport org.scalatest.Matchers._\n\nclass CalculateDegreeTest extends FunSuite {\n  val spark: SparkContext = SparkSession.builder().master(\"local[2]\").getOrCreate().sparkContext\n\n  test(\"should calculate degree of vertices\") {\n    //given\n    val users: RDD[(VertexId, (String))] =\n      spark.parallelize(Array(\n        (1L, \"a\"),\n        (2L, \"b\"),\n        (3L, \"c\"),\n        (4L, \"d\")\n      ))\n\n    val relationships =\n      spark.parallelize(Array(\n        Edge(1L, 2L, \"friend\"),\n        Edge(1L, 3L, \"friend\"),\n        Edge(2L, 4L, \"wife\")\n      ))\n```", "```py\n    val graph = Graph(users, relationships)\n\n    //when\n    val degrees = graph.degrees.collect().toList\n```", "```py\n    //then\n    degrees should contain theSameElementsAs List(\n      (4L, 1L),\n      (2L, 2L),\n      (1L, 2L),\n      (3L, 1L)\n    )\n  }\n```", "```py\n  test(\"should calculate in-degree of vertices\") {\n    //given\n    val users: RDD[(VertexId, (String))] =\n      spark.parallelize(Array(\n        (1L, \"a\"),\n        (2L, \"b\"),\n        (3L, \"c\"),\n        (4L, \"d\")\n      ))\n\n    val relationships =\n      spark.parallelize(Array(\n        Edge(1L, 2L, \"friend\"),\n        Edge(1L, 3L, \"friend\"),\n        Edge(2L, 4L, \"wife\")\n      ))\n\n    val graph = Graph(users, relationships)\n\n    //when\n    val degrees = graph.inDegrees.collect().toList\n\n    //then\n    degrees should contain theSameElementsAs List(\n      (2L, 1L),\n      (3L, 1L),\n      (4L, 1L)\n    )\n  }\n```", "```py\nval degrees = graph.outDegrees.collect().toList\n```", "```py\n  test(\"should calculate out-degree of vertices\") {\n    //given\n    val users: RDD[(VertexId, (String))] =\n      spark.parallelize(Array(\n        (1L, \"a\"),\n        (2L, \"b\"),\n        (3L, \"c\"),\n        (4L, \"d\")\n      ))\n\n    val relationships =\n      spark.parallelize(Array(\n        Edge(1L, 2L, \"friend\"),\n        Edge(1L, 3L, \"friend\"),\n        Edge(2L, 4L, \"wife\")\n      ))\n\n    val graph = Graph(users, relationships)\n\n    //when\n    val degrees = graph.outDegrees.collect().toList\n\n    //then\n    degrees should contain theSameElementsAs List(\n      (1L, 2L),\n      (2L, 1L)\n    )\n  }\n\n}\n```", "```py\npackage com.tomekl007.chapter_7\n\nimport org.apache.spark.graphx.GraphLoader\nimport org.apache.spark.sql.SparkSession\nimport org.scalatest.FunSuite\nimport org.scalatest.Matchers._\n\nclass PageRankTest extends FunSuite {\n  private val sc = SparkSession.builder().master(\"local[2]\").getOrCreate().sparkContext\n\n  test(\"should calculate page rank using GraphX API\") {\n    //given\n    val graph = GraphLoader.edgeListFile(sc, getClass.getResource(\"/pagerank/followers.txt\").getPath)\n```", "```py\n    val ranks = graph.pageRank(0.0001).vertices\n```", "```py\n    val users = sc.textFile(getClass.getResource(\"/pagerank/users.txt\").getPath).map { line =>\n```", "```py\n      val fields = line.split(\",\")\n      (fields(0).toLong, fields(1))\n    }\n```", "```py\n    //when\n val rankByUsername = users.join(ranks).map {\n      case (_, (username, rank)) => (username, rank)\n    }.sortBy((t) => t._2, ascending = false)\n      .collect()\n      .toList\n```", "```py\n    println(rankByUsername)\n    //then\n    rankByUsername.map(_._1) should contain theSameElementsInOrderAs List(\n      \"BarackObama\",\n      \"ladygaga\",\n      \"odersky\",\n      \"jeresig\",\n      \"matei_zaharia\",\n      \"justinbieber\"\n    )\n  }\n\n}\n```"]