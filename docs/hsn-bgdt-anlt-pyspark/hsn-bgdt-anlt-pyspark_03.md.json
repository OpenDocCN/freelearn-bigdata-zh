["```py\nsc\n```", "```py\nSparkContext\nSpark UI\nVersion\n v2.3.3\nMaster\n local[*]\nAppName\n PySparkShell\n```", "```py\nfrom time import time\n```", "```py\nraw_data = sc.textFile(\"./kdd.data.gz\")\n```", "```py\nsampled = raw_data.sample(False, 0.1, 42)\n```", "```py\ncontains_normal_sample = sampled.map(lambda x: x.split(\",\")).filter(lambda x: \"normal\" in x)\n```", "```py\nt0 = time()\nnum_sampled = contains_normal_sample.count()\nduration = time() - t0\n```", "```py\nduration\n```", "```py\n23.724565505981445\n```", "```py\ncontains_normal = raw_data.map(lambda x: x.split(\",\")).filter(lambda x: \"normal\" in x)\nt0 = time()\nnum_sampled = contains_normal.count()\nduration = time() - t0\n```", "```py\nduration \n```", "```py\n36.51565098762512\n```", "```py\ndata_in_memory = raw_data.takeSample(False, 10, 42)\n```", "```py\ncontains_normal_py = [line.split(\",\") for line in data_in_memory if \"normal\" in line]\nlen(contains_normal_py)\n```", "```py\n1\n```", "```py\nnormal_sample = sampled.filter(lambda line: \"normal.\" in line)\n```", "```py\nnon_normal_sample = sampled.subtract(normal_sample)\n```", "```py\nsampled.count()\n```", "```py\n490705\n```", "```py\nnormal_sample.count()\n```", "```py\n97404\n```", "```py\nnon_normal_sample.count()\n```", "```py\n393301\n```", "```py\nfeature_1 = sampled.map(lambda line: line.split(\",\")).map(lambda features: features[1]).distinct()\n```", "```py\nfeature_2 = sampled.map(lambda line: line.split(\",\")).map(lambda features: features[2]).distinct()\n```", "```py\nf1 = feature_1.collect()\nf2 = feature_2.collect()\n```", "```py\nf1\n```", "```py\n['tcp', 'udp', 'icmp']\n```", "```py\nf2\n```", "```py\nlen(feature_1.cartesian(feature_2).collect())\n```", "```py\n198\n```"]