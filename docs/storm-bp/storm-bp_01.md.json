["```scala\n{ \"sentence\":\"my dog has fleas\" }\n```", "```scala\n{ \"word\" : \"my\" }\n{ \"word\" : \"dog\" }\n{ \"word\" : \"has\" }\n{ \"word\" : \"fleas\" }\n```", "```scala\n{ \"word\" : \"dog\", \"count\" : 5 }\n```", "```scala\n$ mvn archetype:create -DgroupId=storm.blueprints \n-DartifactId=Chapter1 -DpackageName=storm.blueprints.chapter1.v1\n\n```", "```scala\n<dependency>\n    <groupId>org.apache.storm</groupId>\n    <artifactId>storm-core</artifactId>\n    <version>0.9.1-incubating</version>\n</dependency>\n```", "```scala\n$ mvn install\n\n```", "```scala\npublic class SentenceSpout extends BaseRichSpout {\n\n    private SpoutOutputCollector collector;\n    private String[] sentences = {\n        \"my dog has fleas\",\n        \"i like cold beverages\",\n        \"the dog ate my homework\",\n        \"don't have a cow man\",\n        \"i don't think i like fleas\"\n    };\n    private int index = 0;\n\n    public void declareOutputFields(OutputFieldsDeclarer declarer) {\n        declarer.declare(new Fields(\"sentence\"));\n    }\n\n    public void open(Map config, TopologyContext context, \n            SpoutOutputCollector collector) {\n        this.collector = collector;\n    }\n\n    public void nextTuple() {\n        this.collector.emit(new Values(sentences[index]));\n        index++;\n        if (index >= sentences.length) {\n            index = 0;\n        }\n        Utils.waitForMillis(1);\n    }\n}\n```", "```scala\npublic class SplitSentenceBolt extends BaseRichBolt{\n    private OutputCollector collector;\n\n    public void prepare(Map config, TopologyContext context,\n OutputCollector collector) {\n        this.collector = collector;\n    }\n\n    public void execute(Tuple tuple) {\n        String sentence = tuple.getStringByField(\"sentence\");\n        String[] words = sentence.split(\" \");\n        for(String word : words){\n            this.collector.emit(new Values(word));\n        }\n    }\n\n    public void declareOutputFields(OutputFieldsDeclarer declarer) {\n        declarer.declare(new Fields(\"word\"));\n    }\n}\n```", "```scala\npublic class WordCountBolt extends BaseRichBolt{\n    private OutputCollector collector;\n    private HashMap<String, Long> counts = null;\n\n    public void prepare(Map config, TopologyContext context, \n            OutputCollector collector) {\n        this.collector = collector;\n        this.counts = new HashMap<String, Long>();\n    }\n\n    public void execute(Tuple tuple) {\n        String word = tuple.getStringByField(\"word\");\n        Long count = this.counts.get(word);\n        if(count == null){\n            count = 0L;\n        }\n        count++;\n        this.counts.put(word, count);\n        this.collector.emit(new Values(word, count));\n    }\n\n    public void declareOutputFields(OutputFieldsDeclarer declarer) {\n        declarer.declare(new Fields(\"word\", \"count\"));\n    }\n}\n```", "```scala\npublic class ReportBolt extends BaseRichBolt {\n\n    private HashMap<String, Long> counts = null;\n\n    public void prepare(Map config, TopologyContext context, OutputCollector collector) {\n        this.counts = new HashMap<String, Long>();\n    }\n\n    public void execute(Tuple tuple) {\n        String word = tuple.getStringByField(\"word\");\n        Long count = tuple.getLongByField(\"count\");\n        this.counts.put(word, count);\n    }\n\n    public void declareOutputFields(OutputFieldsDeclarer declarer) {\n        // this bolt does not emit anything\n    }\n\n    public void cleanup() {\n        System.out.println(\"--- FINAL COUNTS ---\");\n        List<String> keys = new ArrayList<String>();\n        keys.addAll(this.counts.keySet());\n        Collections.sort(keys);\n        for (String key : keys) {\n            System.out.println(key + \" : \" + this.counts.get(key));\n        }\n        System.out.println(\"--------------\");\n    }\n}\n```", "```scala\npublic class WordCountTopology {\n\n    private static final String SENTENCE_SPOUT_ID = \"sentence-spout\";\n    private static final String SPLIT_BOLT_ID = \"split-bolt\";\n    private static final String COUNT_BOLT_ID = \"count-bolt\";\n    private static final String REPORT_BOLT_ID = \"report-bolt\";\n    private static final String TOPOLOGY_NAME = \"word-count-topology\";\n\n    public static void main(String[] args) throws Exception {\n\n        SentenceSpout spout = new SentenceSpout();\n        SplitSentenceBolt splitBolt = new SplitSentenceBolt();\n        WordCountBolt countBolt = new WordCountBolt();\n        ReportBolt reportBolt = new ReportBolt();\n\n        TopologyBuilder builder = new TopologyBuilder();\n\n        builder.setSpout(SENTENCE_SPOUT_ID, spout);\n        // SentenceSpout --> SplitSentenceBolt\n        builder.setBolt(SPLIT_BOLT_ID, splitBolt)\n                .shuffleGrouping(SENTENCE_SPOUT_ID);\n        // SplitSentenceBolt --> WordCountBolt\n        builder.setBolt(COUNT_BOLT_ID, countBolt)\n                .fieldsGrouping(SPLIT_BOLT_ID, new Fields(\"word\"));\n        // WordCountBolt --> ReportBolt\n        builder.setBolt(REPORT_BOLT_ID, reportBolt)\n                .globalGrouping(COUNT_BOLT_ID);\n\n        Config config = new Config();\n\n        LocalCluster cluster = new LocalCluster();\n\n        cluster.submitTopology(TOPOLOGY_NAME, config, builder.createTopology());\n        waitForSeconds(10);\n        cluster.killTopology(TOPOLOGY_NAME);\n        cluster.shutdown();\n    }\n}\n```", "```scala\nbuilder.setSpout(SENTENCE_SPOUT_ID, spout);\n```", "```scala\nbuilder.setBolt(SPLIT_BOLT_ID, splitBolt)\n                .shuffleGrouping(SENTENCE_SPOUT_ID);\n```", "```scala\nbuilder.setBolt(COUNT_BOLT_ID, countBolt)\n                .fieldsGrouping(SPLIT_BOLT_ID, new Fields(\"word\"));\n```", "```scala\nbuilder.setBolt(REPORT_BOLT_ID, reportBolt)\n                .globalGrouping(COUNT_BOLT_ID);\n```", "```scala\nConfig config = new Config();\n\nLocalCluster cluster = new LocalCluster();\n\n        cluster.submitTopology(TOPOLOGY_NAME, config, builder.createTopology());\n        waitForSeconds(10);\n        cluster.killTopology(TOPOLOGY_NAME);\n        cluster.shutdown();\n```", "```scala\n--- FINAL COUNTS ---\na : 1426\nate : 1426\nbeverages : 1426\ncold : 1426\ncow : 1426\ndog : 2852\ndon't : 2851\nfleas : 2851\nhas : 1426\nhave : 1426\nhomework : 1426\ni : 4276\nlike : 2851\nman : 1426\nmy : 2852\nthe : 1426\nthink : 1425\n-------------- \n```", "```scala\n    Config config = new Config();\n    config.setNumWorkers(2);\n```", "```scala\nbuilder.setSpout(SENTENCE_SPOUT_ID, spout, 2);\n```", "```scala\nbuilder.setBolt(SPLIT_BOLT_ID, splitBolt, 2)\n              .setNumTasks(4)\n                .shuffleGrouping(SENTENCE_SPOUT_ID);\n\nbuilder.setBolt(COUNT_BOLT_ID, countBolt, 4)\n                .fieldsGrouping(SPLIT_BOLT_ID, new Fields(\"word\"));\n```", "```scala\n--- FINAL COUNTS ---\na : 2726\nate : 2722\nbeverages : 2723\ncold : 2723\ncow : 2726\ndog : 5445\ndon't : 5444\nfleas : 5451\nhas : 2723\nhave : 2722\nhomework : 2722\ni : 8175\nlike : 5449\nman : 2722\nmy : 5445\nthe : 2727\nthink : 2722\n--------------\n```", "```scala\npublic interface CustomStreamGrouping extends Serializable {\n\nvoid prepare(WorkerTopologyContext context, \nGlobalStreamId stream, List<Integer> targetTasks);\n\nList<Integer> chooseTasks(int taskId, List<Object> values); \n}\n```", "```scala\npublic void nextTuple() {\n        if(index < sentences.length){\n            this.collector.emit(new Values(sentences[index]));\n            index++;\n        }\n        Utils.waitForMillis(1);\n    }\n```", "```scala\n--- FINAL COUNTS ---\na : 2\nate : 2\nbeverages : 2\ncold : 2\ncow : 2\ndog : 4\ndon't : 4\nfleas : 4\nhas : 2\nhave : 2\nhomework : 2\ni : 6\nlike : 4\nman : 2\nmy : 4\nthe : 2\nthink : 2\n--------------\n```", "```scala\nbuilder.setBolt(COUNT_BOLT_ID, countBolt, 4)\n                .shuffleGrouping(SPLIT_BOLT_ID);\n```", "```scala\n--- FINAL COUNTS ---\na : 1\nate : 2\nbeverages : 1\ncold : 1\ncow : 1\ndog : 2\ndon't : 2\nfleas : 1\nhas : 1\nhave : 1\nhomework : 1\ni : 3\nlike : 1\nman : 1\nmy : 1\nthe : 1\nthink : 1\n--------------\n```", "```scala\npublic interface ISpout extends Serializable {\n    void open(Map conf, TopologyContext context, SpoutOutputCollector collector);\n    void close();\n    void nextTuple();\n    void ack(Object msgId);\n    void fail(Object msgId);\n}\n```", "```scala\ncollector.emit(new Values(\"value1\", \"value2\") , msgId);\n```", "```scala\ncollector.emit(tuple, new Values(word));\n```", "```scala\ncollector.emit(new Values(word));));\n```", "```scala\nthis.collector.ack(tuple);\n```", "```scala\nthis.collector.fail(tuple)\n```", "```scala\npublic class SentenceSpout extends BaseRichSpout {\n\n    private ConcurrentHashMap<UUID, Values> pending;\n    private SpoutOutputCollector collector;\n    private String[] sentences = {\n        \"my dog has fleas\",\n        \"i like cold beverages\",\n        \"the dog ate my homework\",\n        \"don't have a cow man\",\n        \"i don't think i like fleas\"\n    };\n    private int index = 0;\n\n    public void declareOutputFields(OutputFieldsDeclarer declarer) {\n        declarer.declare(new Fields(\"sentence\"));\n    }\n\n    public void open(Map config, TopologyContext context, \n            SpoutOutputCollector collector) {\n        this.collector = collector;\n        this.pending = new ConcurrentHashMap<UUID, Values>();\n    }\n\n    public void nextTuple() {\n        Values values = new Values(sentences[index]);\n        UUID msgId = UUID.randomUUID();\n        this.pending.put(msgId, values);\n        this.collector.emit(values, msgId);\n        index++;\n        if (index >= sentences.length) {\n            index = 0;\n        }\n        Utils.waitForMillis(1);\n    }\n\n    public void ack(Object msgId) {\n        this.pending.remove(msgId);\n    }\n\n    public void fail(Object msgId) {\n        this.collector.emit(this.pending.get(msgId), msgId);\n    }    \n}\n```", "```scala\npublic class SplitSentenceBolt extends BaseRichBolt{\n    private OutputCollector collector;\n\n    public void prepare(Map config, TopologyContext context, OutputCollector collector) {\n        this.collector = collector;\n    }\n\n    public void execute(Tuple tuple) {\n        String sentence = tuple.getStringByField(\"sentence\");\n        String[] words = sentence.split(\" \");\n        for(String word : words){\n            this.collector.emit(tuple, new Values(word));\n        }\n        this.collector.ack(tuple);\n    }\n\n    public void declareOutputFields(OutputFieldsDeclarer declarer) {\n        declarer.declare(new Fields(\"word\"));\n    }\n}\n```"]