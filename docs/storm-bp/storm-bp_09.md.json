["```scala\nexport HADOOP_PREFIX=/home/user/hadoop\nexport HADOOP_YARN_HOME=/home/user/hadoop\nexport HADOOP_CONF_DIR=/home/user/hadoop/etc/Hadoop\n```", "```scala\nexport PATH=$PATH:$HADOOP_YARN_HOME/bin\n```", "```scala\n$ yarn version\nYou should see output similar to the following:\nHadoop 2.1.0-beta\nSubversion https://svn.apache.org/repos/asf/hadoop/common -r 1514472\nCompiled by hortonmu on 2013-08-15T20:48Z\nCompiled with protoc 2.5.0\nFrom source with checksum 8d753df8229fd48437b976c5c77e80a\nThis command was run using /Users/bone/tools/hadoop-2.1.0-beta/share/hadoop/common/hadoop-common-2.1.0-beta.jar\n\n```", "```scala\n<configuration>\n    <property>\n        <name>fs.default.name</name>\n        <value>hdfs://master:8020</value>\n    </property>\n</configuration>\n```", "```scala\n<configuration>\n   <property>\n       <name>dfs.name.dir</name>\n       <value>/home/user/hadoop/name/data</value>\n   </property>\n   <property>\n       <name>dfs.permissions</name>\n       <value>false</value>\n   </property>\n</configuration>\n```", "```scala\nhdfs namenode -format <cluster_name>\n\n```", "```scala\n$HADOOP_PREFIX/sbin/hadoop-daemon.sh --config $HADOOP_CONF_DIR --script hdfs start namenode\n\n```", "```scala\nstarting namenode, logging to /home/user/hadoop/logs/hadoop-master.hmsonline.com.out\n\n```", "```scala\norg.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /home/user/hadoop-2.1.0-beta/name/data is in an inconsistent state: storage directory does not exist or is not accessible.\n```", "```scala\nboneill@master:~-> jps\n30080 NameNode\n```", "```scala\n<configuration>\n   <property>\n       <name>dfs.datanode.data.dir</name>\n       <value>/vol/local/storage/</value>\n   </property>\n</configuration>\n```", "```scala\n$HADOOP_PREFIX/sbin/hadoop-daemon.sh --config $HADOOP_CONF_DIR --script hdfs start datanode\n\n```", "```scala\n<configuration>\n   <property>\n       <name>yarn.resourcemanager.address</name>\n       <value>master:8022</value>\n   </property>\n   <property>\n       <name>yarn.resourcemanager.admin.address</name>\n       <value>master:8033</value>\n   </property>\n   <property>\n       <name>yarn.resourcemanager.resource-tracker.address</name>\n        <value>master:8025</value>\n   </property>\n   <property>\n       <name>yarn.resourcemanager.scheduler.address</name>\n       <value>master:8030</value>\n   </property>\n   <property>\n       <name>yarn.acl.enable</name>\n       <value>false</value>\n   </property>\n   <property>\n       <name>yarn.nodemanager.local-dirs</name>\n       <value>/home/user/hadoop_work/mapred/nodemanager</value>\n       <final>true</final>\n   </property>\n   <property>\n     <name>yarn.nodemanager.aux-services</name>\n     <value>mapreduce.shuffle</value>\n   </property>\n</configuration>\n```", "```scala\n$HADOOP_YARN_HOME/sbin/yarn-daemon.sh --config $HADOOP_CONF_DIR start resourcemanager\n\n```", "```scala\n$HADOOP_YARN_HOME/sbin/yarn-daemon.sh --config $HADOOP_CONF_DIR start nodemanager\n\n```", "```scala\nhadoop fs -mkdir /user/bone/temp\nhadoop fs -copyFromLocal click_thru_data.txt /user/bone/temp/\n\n```", "```scala\nexport PIG_CLASSPATH=/home/user/hadoop/etc/hadoop\nexport PIG_HOME=/home/user/pig\nexport PATH=PATH:$HOME/bin:$PIG_HOME/bin:$HADOOP_YARN_HOME/bin\n```", "```scala\nboneill@master:~-> pig\n2013-10-07 23:35:41,179 [main] INFO  org.apache.pig.Main - Apache Pig version 0.11.1 (r1459641) compiled Mar 22 2013, 02:13:53\n...\n2013-10-07 23:35:42,639 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - Connecting to hadoop file system at: hdfs://master:8020\ngrunt>\n\n```", "```scala\ngrunt> ls /user/bone/temp/\nhdfs://master:8020/user/bone/temp/click_thru_data.txt<r 3>\t157\n\ngrunt> cat /user/bone/temp/click_thru_data.txt\nboneill campaign7 productX true\nlisalis campaign10 productX false\nboneill campaign6 productX true\nowen campaign6 productX false\ncollin campaign7 productY true\nmaya campaign8 productY true\nboneill campaign7 productX true\nowen campaign6 productX true\nolive campaign6 productX false\nmaryanne campaign7 productY true\ndennis campaign7 productY true\npatrick campaign7 productX false\ncharity campaign10 productY false\ndrago campaign7 productY false\n```", "```scala\nhadoop fs -mkdir /user/bone/lib/\nhadoop fs -copyFromLocal ./lib/storm-0.9.0-wip21.zip /user/bone/lib/\n\n```", "```scala\nmaster.host: \"master\"\nmaster.thrift.port: 9000\nmaster.initial-num-supervisors: 2\nmaster.container.priority: 0\nmaster.container.size-mb: 5120\nmaster.heartbeat.interval.millis: 1000\nmaster.timeout.secs: 1000\nyarn.report.wait.millis: 10000\nnimbusui.startup.ms: 10000\n\nui.port: 7070\n\nstorm.messaging.transport: \"backtype.storm.messaging.netty.Context\"\nstorm.messaging.netty.buffer_size: 1048576\nstorm.messaging.netty.max_retries: 100\nstorm.messaging.netty.min_wait_ms: 1000\nstorm.messaging.netty.max_wait_ms: 5000\n\nstorm.zookeeper.servers:\n     - \"zkhost\"\n```", "```scala\nstorm-yarn launch ../your.yaml --queue default -appname storm-yarn-2.1.0-deta-demo --stormZip lib/storm-0.9.0-wip21.zip\n\n```", "```scala\n13/10/09 21:40:10 INFO yarn.StormAMRMClient: Use NMClient to launch supervisors in container.  \n13/10/09 21:40:10 INFO impl.ContainerManagementProtocolProxy: Opening proxy : slave05:35847 \n13/10/09 21:40:12 INFO yarn.StormAMRMClient: Supervisor log: http://slave05:8042/node/containerlogs/container_1381197763696_0004_01_000002/boneill/supervisor.log \n13/10/09 21:40:14 INFO yarn.MasterServer: HB: Received allocated containers (1) 13/10/09 21:40:14 INFO yarn.MasterServer: HB: Supervisors are to run, so queueing (1) containers... \n13/10/09 21:40:14 INFO yarn.MasterServer: LAUNCHER: Taking container with id (container_1381197763696_0004_01_000004) from the queue. \n13/10/09 21:40:14 INFO yarn.MasterServer: LAUNCHER: Supervisors are to run, so launching container id (container_1381197763696_0004_01_000004) \n13/10/09 21:40:16 INFO yarn.StormAMRMClient: Use NMClient to launch supervisors in container.  13/10/09 21:40:16 INFO impl.ContainerManagementProtocolProxy: Opening proxy : dlwolfpack02.hmsonline.com:35125 \n13/10/09 21:40:16 INFO yarn.StormAMRMClient: Supervisor log: http://slave02:8042/node/containerlogs/container_1381197763696_0004_01_000004/boneill/supervisor.log\n\n```", "```scala\n master.initial-num-supervisors: 2\n\n```", "```scala\n./storm-yarn shutdown -appId application_1381197763696_0002\n\n```", "```scala\nclick_thru_data = LOAD '../click_thru_data.txt' using PigStorage(' ')\n  AS (cookie_id:chararray,\n      campaign_id:chararray,\n      product_id:chararray,\n      click:chararray);\n\nclick_thrus = FILTER click_thru_data BY click == 'true';\ndistinct_click_thrus = DISTINCT click_thrus;\ndistinct_click_thrus_by_campaign = GROUP distinct_click_thrus BY campaign_id;\ncount_of_click_thrus_by_campaign = FOREACH distinct_click_thrus_by_campaign GENERATE group, COUNT($1);\n-- dump count_of_click_thrus_by_campaign;\n\nimpressions_by_campaign = GROUP click_thru_data BY campaign_id;\ncount_of_impressions_by_campaign = FOREACH impressions_by_campaign GENERATE group, COUNT($1);\n-- dump count_of_impressions_by_campaign;\n\njoined_data = JOIN count_of_impressions_by_campaign BY $0 LEFT OUTER, count_of_click_thrus_by_campaign BY $0 USING 'replicated';\n-- dump joined_data;\n\nresult = FOREACH joined_data GENERATE $0 as campaign, ($3 is null ? 0 : $3) as clicks, $1 as impressions, (double)$3/(double)$1 as effectiveness:double;\ndump result;\n```", "```scala\n(campaign6,2,4,0.5)\n(campaign7,4,7,0.5714285714285714)\n(campaign8,1,1,1.0)\n(campaign10,0,2,)\n```", "```scala\nStream inputStream = topology.newStream(\"clickthru\", spout);\nStream click_thru_stream = inputStream.each(\nnew Fields(\"cookie\", \"campaign\", \"product\", \"click\"), \nnew Filter(\"click\", \"true\"))\n.each(new Fields(\"cookie\", \"campaign\", \"product\", \"click\"), \nnew Distinct())\n                .groupBy(new Fields(\"campaign\"))              \n                .persistentAggregate(\nnew MemoryMapState.Factory(), new Count(), \nnew Fields(\"click_thru_count\"))\n                .newValuesStream();\n\nStream impressions_stream = inputStream.groupBy(\nnew Fields(\"campaign\"))\n                .persistentAggregate(\nnew MemoryMapState.Factory(), new Count(), \nnew Fields(\"impression_count\"))\n                .newValuesStream();\n\ntopology.join(click_thru_stream, new Fields(\"campaign\"),\nimpressions_stream, new Fields(\"campaign\"), \n  new Fields(\"campaign\", \"click_thru_count\", \"impression_count\"))\n                .each(new Fields(\"campaign\", \n\"click_thru_count\", \"impression_count\"), \nnew CampaignEffectiveness(), new Fields(\"\"));\n```", "```scala\nStateFactory clickThruMemory = new MemoryMapState.Factory();\nClickThruSpout spout = new ClickThruSpout();\nStream inputStream = topology.newStream(\"clithru\", spout);\nTridentState clickThruState = inputStream.each(\nnew Fields(\"cookie\", \"campaign\", \"product\", \"click\"),\nnew Filter(\"click\", \"true\"))\n   .each(new Fields(\"cookie\", \"campaign\", \"product\", \"click\"),\nnew Distinct())\n   .groupBy(new Fields(\"campaign\"))\n   .persistentAggregate(clickThruMemory, new Count(),\nnew Fields(\"click_thru_count\"));\n\ninputStream.groupBy(new Fields(\"campaign\"))\n.persistentAggregate(new MemoryMapState.Factory(),\nnew Count(), new Fields(\"impression_count\"))\n.newValuesStream()\n.stateQuery(clickThruState, new Fields(\"campaign\"),\nnew MapGet(), new Fields(\"click_thru_count\"))\n.each(new Fields(\"campaign\", \"impression_count\",\n      \"click_thru_count\"),\nnew CampaignEffectiveness(), new Fields(\"\"));\n```", "```scala\npublic class ClickThruEmitter\nimplements Emitter<Long>, Serializable {\n...\n@Override\npublic void emitBatch(TransactionAttempt tx,\nLong coordinatorMeta, TridentCollector collector) {\n     File file = new File(\"click_thru_data.txt\");\n     try {\n         BufferedReader br = \nnew BufferedReader(new FileReader(file));\n         String line = null;\n         while ((line = br.readLine()) != null) {\n          String[] data = line.split(\" \");\n          List<Object> tuple = new ArrayList<Object>();\n          tuple.add(data[0]); // cookie\n          tuple.add(data[1]); // campaign\n          tuple.add(data[2]); // product\n          tuple.add(data[3]); // click\n          collector.emit(tuple);\n         }\n         br.close();\n     } catch (Exception e) {\n         throw new RuntimeException(e);\n     }\n}\n     ...\n}\n```", "```scala\npublic class Filter extends BaseFilter {\n    private static final long serialVersionUID = 1L;\n    private String fieldName = null;\n    private String value = null;\n\n    public Filter(String fieldName, String value){\n        this.fieldName = fieldName;\n        this.value = value;        \n    }\n\n    @Override\n    public boolean isKeep(TridentTuple tuple) {\n        String tupleValue = tuple.getStringByField(fieldName); \n        if (tupleValue.equals(this.value)) {\n          return true;\n        }\n        return false;\n    }\n}\n```", "```scala\npublic class Distinct extends BaseFilter {\n    private static final long serialVersionUID = 1L;\n    private Set<String> distincter = Collections.synchronizedSet(new HashSet<String>());\n\n    @Override\n    public boolean isKeep(TridentTuple tuple) {        \n        String id = this.getId(tuple);\n   return distincter.add(id);\n    }\n\n    public String getId(TridentTuple t){\n        StringBuilder sb = new StringBuilder();\n        for (int i = 0; i < t.size(); i++){\n           sb.append(t.getString(i));\n        }\n        return sb.toString();\n    }\n}\n```", "```scala\n.stateQuery(clickThruState, new Fields(\"campaign\"),\nnew MapGet(), new Fields(\"click_thru_count\"))\n```", "```scala\npublic class CampaignEffectiveness extends BaseFunction {\n    private static final long serialVersionUID = 1L;\n\n    @Override\n    public void execute(TridentTuple tuple, TridentCollector collector) {\n   String campaign = (String) tuple.getValue(0);\n        Long impressions_count = (Long) tuple.getValue(1);\n        Long click_thru_count = (Long) tuple.getValue(2);\n        if (click_thru_count == null) \n            click_thru_count = new Long(0);\n        double effectiveness = (double) click_thru_count / (double) impressions_count;\n   Log.error(\"[\" + campaign + \",\" + String.valueOf(click_thru_count) + \",\" + impressions_count + \", \" + effectiveness + \"]\");\n   List<Object> values = new ArrayList<Object>();\n   values.add(campaign);\n   collector.emit(values);\n    }\n}\n```", "```scala\nstorm-yarn getStormConfig ../your.yaml --appId application_1381197763696_0004 --output output.yaml\n\n```", "```scala\nstorm jar <appJar>\n```", "```scala\n00:00 ERROR: [campaign10,0,2, 0.0]\n00:00 ERROR: [campaign6,2,4, 0.5]\n00:00 ERROR: [campaign7,4,7, 0.5714285714285714]\n00:00 ERROR: [campaign8,1,1, 1.0]\n```", "```scala\n00:03 ERROR: [campaign10,0,112, 0.0]\n00:03 ERROR: [campaign6,2,224, 0.008928571428571428]\n00:03 ERROR: [campaign7,4,392, 0.01020408163265306]\n00:03 ERROR: [campaign8,1,56, 0.017857142857142856]\n```"]