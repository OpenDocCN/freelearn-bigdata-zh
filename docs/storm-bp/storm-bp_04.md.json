["```scala\ntar -zxf kafka-0.7.2-incubating-src.tgz\ncd kafka-0.7.2-incubating-src\n```", "```scala\n./sbt update package\n```", "```scala\n./bin/zookeeper-server-start.sh ./config/zookeeper.properties\n```", "```scala\n./bin/kafka-server-start.sh ./config/server.properties\n```", "```scala\npublic class RogueApplication {\n    private static final Logger LOG = LoggerFactory.getLogger(RogueApplication.class);\n\n    public static void main(String[] args) throws Exception {\n        int slowCount = 6;\n        int fastCount = 15;\n        // slow state\n        for(int i = 0; i < slowCount; i++){\n            LOG.warn(\"This is a warning (slow state).\");\n            Thread.sleep(5000);\n        }\n        // enter rapid state\n        for(int i = 0; i < fastCount; i++){\n            LOG.warn(\"This is a warning (rapid state).\");\n            Thread.sleep(1000);\n        }\n        // return to slow state\n        for(int i = 0; i < slowCount; i++){\n            LOG.warn(\"This is a warning (slow state).\");\n            Thread.sleep(5000);\n        }\n    }\n}\n```", "```scala\n  abstract protected void append(E eventObject);\n```", "```scala\n public void start();\n public void stop();\n```", "```scala\npublic class KafkaAppender extends AppenderBase<ILoggingEvent> {\n\n    private String topic;\n    private String zookeeperHost;\n    private Producer<String, String> producer;\n    private Formatter formatter;\n\n    // java bean definitions used to inject\n    // configuration values from logback.xml\n    public String getTopic() {\n        return topic;\n    }\n\n    public void setTopic(String topic) {\n        this.topic = topic;\n    }\n\n    public String getZookeeperHost() {\n        return zookeeperHost;\n    }\n\n    public void setZookeeperHost(String zookeeperHost) {\n        this.zookeeperHost = zookeeperHost;\n    }\n\n    public Formatter getFormatter() {\n        return formatter;\n    }\n\n    public void setFormatter(Formatter formatter) {\n        this.formatter = formatter;\n    }\n\n    // overrides\n    @Override\n    public void start() {\n        if (this.formatter == null) {\n            this.formatter = new MessageFormatter();\n        }\n        super.start();\n        Properties props = new Properties();\n        props.put(\"zk.connect\", this.zookeeperHost);\n        props.put(\"serializer.class\", \"kafka.serializer.StringEncoder\");\n        ProducerConfig config = new ProducerConfig(props);\n        this.producer = new Producer<String, String>(config);\n    }\n\n    @Override\n    public void stop() {\n        super.stop();\n        this.producer.close();\n    }\n\n    @Override\n    protected void append(ILoggingEvent event) {\n        String payload = this.formatter.format(event);\n        ProducerData<String, String> data = new ProducerData<String, String>(this.topic, payload);\n        this.producer.send(data);\n    }\n\n}\n```", "```scala\npublic interface Formatter {\n    String format(ILoggingEvent event);\n}\n```", "```scala\npublic class MessageFormatter implements Formatter {\n\n    public String format(ILoggingEvent event) {\n        return event.getFormattedMessage();\n    }\n}\n```", "```scala\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<configuration>\n    <appender name=\"KAFKA\"\n        class=\"com.github.ptgoetz.logback.kafka.KafkaAppender\">\n        <topic>mytopic</topic>\n        <zookeeperHost>localhost:2181</zookeeperHost>\n    </appender>\n    <root level=\"debug\">\n        <appender-ref ref=\"KAFKA\" />\n    </root>\n</configuration>\n```", "```scala\npublic class JsonFormatter implements Formatter {\n    private static final String QUOTE = \"\\\"\";\n    private static final String COLON = \":\";\n    private static final String COMMA = \",\";\n\n    private boolean expectJson = false;\n\n    public String format(ILoggingEvent event) {\n        StringBuilder sb = new StringBuilder();\n        sb.append(\"{\");\n        fieldName(\"level\", sb);\n        quote(event.getLevel().levelStr, sb);\n        sb.append(COMMA);\n        fieldName(\"logger\", sb);\n        quote(event.getLoggerName(), sb);\n        sb.append(COMMA);\n        fieldName(\"timestamp\", sb);\n        sb.append(event.getTimeStamp());\n        sb.append(COMMA);\n        fieldName(\"message\", sb);\n        if (this.expectJson) {\n            sb.append(event.getFormattedMessage());\n        } else {\n            quote(event.getFormattedMessage(), sb);\n        }\n\n        sb.append(\"}\");\n        return sb.toString();\n    }\n\n    private static void fieldName(String name, StringBuilder sb) {\n        quote(name, sb);\n        sb.append(COLON);\n    }\n\n    private static void quote(String value, StringBuilder sb) {\n        sb.append(QUOTE);\n        sb.append(value);\n        sb.append(QUOTE);\n    }\n\n    public boolean isExpectJson() {\n        return expectJson;\n    }\n\n    public void setExpectJson(boolean expectJson) {\n        this.expectJson = expectJson;\n    }\n}\n```", "```scala\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<configuration>\n    <appender name=\"KAFKA\"\n        class=\"com.github.ptgoetz.logback.kafka.KafkaAppender\">\n        <topic>foo</topic>\n        <zookeeperHost>localhost:2181</zookeeperHost>\n        <!-- specify a custom formatter -->\n        <formatter class=\"com.github.ptgoetz.logback.kafka.formatter.JsonFormatter\">\n            <!-- \n            Whether we expect the log message to be JSON encoded or not.\n            If set to \"false\", the log message will be treated as a string, and wrapped in quotes. Otherwise it will be treated as a parseable JSON object.\n            -->\n            <expectJson>false</expectJson>\n        </formatter>\n    </appender>\n\t<root level=\"debug\">\n\t\t<appender-ref ref=\"KAFKA\" />\n\t</root>\n</configuration>\n```", "```scala\n        TridentTopology topology = new TridentTopology();\n\n        StaticHosts kafkaHosts = KafkaConfig.StaticHosts.fromHostString(Arrays.asList(new String[] { \"localhost\" }), 1);\n        TridentKafkaConfig spoutConf = new TridentKafkaConfig(kafkaHosts, \"log-analysis\");\n        spoutConf.scheme = new StringScheme();\n        spoutConf.forceStartOffsetTime(-1);\n        OpaqueTridentKafkaSpout spout = new OpaqueTridentKafkaSpout(spoutConf);\n\n        Stream spoutStream = topology.newStream(\"kafka-stream\", spout);\n```", "```scala\npublic class JsonProjectFunction extends BaseFunction {\n\n    private Fields fields;\n\n    public JsonProjectFunction(Fields fields) {\n        this.fields = fields;\n    }\n\n    public void execute(TridentTuple tuple, TridentCollector collector) {\n        String json = tuple.getString(0);\n        Map<String, Object> map = (Map<String, Object>)  \n            JSONValue.parse(json);\n        Values values = new Values();\n        for (int i = 0; i < this.fields.size(); i++) {\n            values.add(map.get(this.fields.get(i)));\n        }\n        collector.emit(values);\n    }\n\n}\n```", "```scala\n        Fields jsonFields = new Fields(\"level\", \"timestamp\", \"message\", \"logger\");\n        Stream parsedStream = spoutStream.each(new Fields(\"str\"), new JsonProjectFunction(jsonFields), jsonFields);\n```", "```scala\n{\n  \"message\" : \"foo\",\n  \"timestamp\" : 1370918376296,\n  \"level\" : \"INFO\",\n  \"logger\" : \"test\"\n}\n```", "```scala\n[INFO, 1370918376296, test, foo]\n```", "```scala\ndiff = currentTime - lastEventTime\ncurrentAverage = (1.0 - alpha) * diff + alpha * lastAverage\n```", "```scala\nif (currentTime - lastEventTime) > slidingWindowInterval\n    currentAverage = 0\nend if\n```", "```scala\npublic class EWMA implements Serializable {\n\n    public static enum Time {\n        MILLISECONDS(1), SECONDS(1000), MINUTES(SECONDS.getTime() * 60), HOURS(MINUTES.getTime() * 60), DAYS(HOURS\n                .getTime() * 24), WEEKS(DAYS.getTime() * 7);\n\n        private long millis;\n\n        private Time(long millis) {\n            this.millis = millis;\n        }\n\n        public long getTime() {\n            return this.millis;\n        }\n    }\n\n    // Unix load average-style alpha constants\n    public static final double ONE_MINUTE_ALPHA = 1 - Math.exp(-5d / 60d / 1d);\n    public static final double FIVE_MINUTE_ALPHA = 1 - Math.exp(-5d / 60d / 5d);\n    public static final double FIFTEEN_MINUTE_ALPHA = 1 - Math.exp(-5d / 60d / 15d);\n\n    private long window;\n    private long alphaWindow;\n    private long last;\n    private double average;\n    private double alpha = -1D;\n    private boolean sliding = false;\n\n    public EWMA() {\n    }\n\n    public EWMA sliding(double count, Time time) {\n        return this.sliding((long) (time.getTime() * count));\n    }\n\n    public EWMA sliding(long window) {\n        this.sliding = true;\n        this.window = window;\n        return this;\n    }\n\n    public EWMA withAlpha(double alpha) {\n        if (!(alpha > 0.0D && alpha <= 1.0D)) {\n            throw new IllegalArgumentException(\"Alpha must be between 0.0 and 1.0\");\n        }\n        this.alpha = alpha;\n        return this;\n    }\n\n    public EWMA withAlphaWindow(long alphaWindow) {\n        this.alpha = -1;\n        this.alphaWindow = alphaWindow;\n        return this;\n    }\n\n    public EWMA withAlphaWindow(double count, Time time) {\n        return this.withAlphaWindow((long) (time.getTime() * count));\n    }\n\n    public void mark() {\n        mark(System.currentTimeMillis());\n    }\n\n    public synchronized void mark(long time) {\n        if (this.sliding) {\n            if (time - this.last > this.window) {\n                // reset the sliding window\n                this.last = 0;\n            }\n        }\n        if (this.last == 0) {\n            this.average = 0;\n            this.last = time;\n        }\n        long diff = time - this.last;\n        double alpha = this.alpha != -1.0 ? this.alpha : Math.exp(-1.0 * ((double) diff / this.alphaWindow));\n        this.average = (1.0 - alpha) * diff + alpha * this.average;\n        this.last = time;\n    }\n\n    public double getAverage() {\n        return this.average;\n    }\n\n    public double getAverageIn(Time time) {\n        return this.average == 0.0 ? this.average : this.average / time.getTime();\n    }\n\n    public double getAverageRatePer(Time time) {\n        return this.average == 0.0 ? this.average : time.getTime() / this.average;\n    }\n\n}\n```", "```scala\nEWMA ewma = new EWMA().sliding(1.0, Time.MINUTES).withAlpha(EWMA.ONE_MINUTE_ALPHA);\n```", "```scala\npublic class MovingAverageFunction extends BaseFunction {\n    private static final Logger LOG = LoggerFactory.getLogger(BaseFunction.class);\n\n    private EWMA ewma;\n    private Time emitRatePer;\n\n    public MovingAverageFunction(EWMA ewma, Time emitRatePer){\n        this.ewma = ewma;\n        this.emitRatePer = emitRatePer;\n    }\n\n    public void execute(TridentTuple tuple, TridentCollector collector) {\n        this.ewma.mark(tuple.getLong(0));\n        LOG.debug(\"Rate: {}\", this.ewma.getAverageRatePer(this.emitRatePer));\n        collector.emit(new Values(this.ewma.getAverageRatePer(this.emitRatePer)));\n    }\n}\n```", "```scala\n[INFO, 1370918376296, test, foo]\n```", "```scala\n[INFO, 1370918376296, test, foo, 3.72234]\n```", "```scala\n        EWMA ewma = new EWMA().sliding(1.0, Time.MINUTES).withAlpha(EWMA.ONE_MINUTE_ALPHA);\n        Stream averageStream = parsedStream.each(new Fields(\"timestamp\"),\n                new MovingAverageFunction(ewma, Time.MINUTES), new Fields(\"average\"));\n```", "```scala\npublic class ThresholdFilterFunction extends BaseFunction {\n    private static final Logger LOG = LoggerFactory.getLogger(ThresholdFilterFunction.class);\n\n    private static enum State {\n        BELOW, ABOVE;\n    }\n\n    private State last = State.BELOW;\n    private double threshold;\n\n    public ThresholdFilterFunction(double threshold){\n        this.threshold = threshold;\n    }\n\n    public void execute(TridentTuple tuple, TridentCollector collector) {\n        double val = tuple.getDouble(0);\n        State newState = val < this.threshold ? State.BELOW : State.ABOVE;\n        boolean stateChange = this.last != newState;\n        collector.emit(new Values(stateChange, threshold));\n        this.last = newState;\n        LOG.debug(\"State change? --> {}\", stateChange);\n    }\n}\n```", "```scala\npublic class BooleanFilter extends BaseFilter {\n\n    public boolean isKeep(TridentTuple tuple) {\n        return tuple.getBoolean(0);\n    }\n}\n```", "```scala\n        ThresholdFilterFunction tff = new ThresholdFilterFunction(50D);\n        Stream thresholdStream = averageStream.each(new Fields(\"average\"), tff, new Fields(\"change\", \"threshold\"));\n\n        Stream filteredStream = thresholdStream.each(new Fields(\"change\"), new BooleanFilter());\n```", "```scala\n        // connect to XMPP server and login\n        ConnectionConfiguration config = new\n            ConnectionConfiguration(\"jabber.org\");\n        XMPPConnection client = new XMPPConnection(config);\n        client.connect();\n        client.login(\"username\", \"password\");\n\n        // send a message to another user\n        Message message =\n           new Message(\"myfriend@jabber.org\", Type.normal);\n        message.setBody(\"How are you today?\");\n        client.sendPacket(message);\n```", "```scala\npublic interface MessageMapper extends Serializable {\n    public String toMessageBody(TridentTuple tuple);\n}\n```", "```scala\npublic class XMPPFunction extends BaseFunction {\n    private static final Logger LOG = LoggerFactory.getLogger(XMPPFunction.class);\n\n    public static final String XMPP_TO = \"storm.xmpp.to\";\n    public static final String XMPP_USER = \"storm.xmpp.user\";\n    public static final String XMPP_PASSWORD = \"storm.xmpp.password\";\n    public static final String XMPP_SERVER = \"storm.xmpp.server\";\n\n    private XMPPConnection xmppConnection;\n    private String to;\n    private MessageMapper mapper;\n\n    public XMPPFunction(MessageMapper mapper) {\n        this.mapper = mapper;\n    }\n\n    @Override\n    public void prepare(Map conf, TridentOperationContext context) {\n        LOG.debug(\"Prepare: {}\", conf);\n        super.prepare(conf, context);\n        this.to = (String) conf.get(XMPP_TO);\n        ConnectionConfiguration config = new ConnectionConfiguration((String) conf.get(XMPP_SERVER));\n        this.xmppConnection = new XMPPConnection(config);\n        try {\n            this.xmppConnection.connect();\n            this.xmppConnection.login((String) conf.get(XMPP_USER), (String) conf.get(XMPP_PASSWORD));\n        } catch (XMPPException e) {\n            LOG.warn(\"Error initializing XMPP Channel\", e);\n        }\n    }\n\n    public void execute(TridentTuple tuple, TridentCollector collector) {\n        Message msg = new Message(this.to, Type.normal);\n        msg.setBody(this.mapper.toMessageBody(tuple));\n        this.xmppConnection.sendPacket(msg);\n\n    }\n\n}\n```", "```scala\npublic class NotifyMessageMapper implements MessageMapper {\n\n    public String toMessageBody(TridentTuple tuple) {\n        StringBuilder sb = new StringBuilder();\n        sb.append(\"On \" + new Date(tuple.getLongByField(\"timestamp\")) + \" \");\n        sb.append(\"the application \\\"\" + tuple.getStringByField(\"logger\") + \"\\\" \");\n        sb.append(\"changed alert state based on a threshold of \" + tuple.getDoubleByField(\"threshold\") + \".\\n\");\n        sb.append(\"The last value was \" + tuple.getDoubleByField(\"average\") + \"\\n\");\n        sb.append(\"The last message was \\\"\" + tuple.getStringByField(\"message\") + \"\\\"\");\n        return sb.toString();\n    }\n}\n```", "```scala\npublic class LogAnalysisTopology {\n\n    public static StormTopology buildTopology() {\n        TridentTopology topology = new TridentTopology();\n\n        StaticHosts kafkaHosts = KafkaConfig.StaticHosts.fromHostString(Arrays.asList(new String[] { \"localhost\" }), 1);\n        TridentKafkaConfig spoutConf = new TridentKafkaConfig(kafkaHosts, \"log-analysis\");\n        spoutConf.scheme = new StringScheme();\n        spoutConf.forceStartOffsetTime(-1);\n        OpaqueTridentKafkaSpout spout = new OpaqueTridentKafkaSpout(spoutConf);\n\n        Stream spoutStream = topology.newStream(\"kafka-stream\", spout);\n\n        Fields jsonFields = new Fields(\"level\", \"timestamp\", \"message\", \"logger\");\n        Stream parsedStream = spoutStream.each(new Fields(\"str\"), new JsonProjectFunction(jsonFields), jsonFields);\n\n        // drop the unparsed JSON to reduce tuple size\n        parsedStream = parsedStream.project(jsonFields);\n\n        EWMA ewma = new EWMA().sliding(1.0, Time.MINUTES).withAlpha(EWMA.ONE_MINUTE_ALPHA);\n        Stream averageStream = parsedStream.each(new Fields(\"timestamp\"),\n                new MovingAverageFunction(ewma, Time.MINUTES), new Fields(\"average\"));\n\n        ThresholdFilterFunction tff = new ThresholdFilterFunction(50D);\n        Stream thresholdStream = averageStream.each(new Fields(\"average\"), tff, new Fields(\"change\", \"threshold\"));\n\n        Stream filteredStream = thresholdStream.each(new Fields(\"change\"), new BooleanFilter());\n\n        filteredStream.each(filteredStream.getOutputFields(), new XMPPFunction(new NotifyMessageMapper()), new Fields());\n\n        return topology.build();\n    }\n\n    public static void main(String[] args) throws Exception {\n        Config conf = new Config();\n        conf.put(XMPPFunction.XMPP_USER, \"storm@budreau.local\");\n        conf.put(XMPPFunction.XMPP_PASSWORD, \"storm\");\n        conf.put(XMPPFunction.XMPP_SERVER, \"budreau.local\");\n        conf.put(XMPPFunction.XMPP_TO, \"tgoetz@budreau.local\");\n\n        conf.setMaxSpoutPending(5);\n        if (args.length == 0) {\n            LocalCluster cluster = new LocalCluster();\n            cluster.submitTopology(\"log-analysis\", conf, buildTopology());\n\n        } else {\n            conf.setNumWorkers(3);\n            StormSubmitter.submitTopology(args[0], conf, buildTopology());\n        }\n    }\n}\n```"]