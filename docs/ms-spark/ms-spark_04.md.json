["```scala\nval sqlContext = new org.apache.spark.sql.SQLContext(sc)\nimport sqlContext.implicits._\n\n```", "```scala\nsc.textFile(\"/data/spark/tweets.txt\",6)\nsc.textFile(\"file:///data/spark/tweets.txt\",6)\nsc.textFile(\"hdfs://server1:4014/data/spark/tweets.txt\",6)\n\n```", "```scala\nval dframe = sqlContext.jsonFile(\"hdfs:///data/spark/device.json\")\n\n```", "```scala\nimport org.apache.spark._\nimport org.apache.spark.SparkContext._\nimport org.apache.spark.sql.Row;\nimport org.apache.spark.sql.types.{StructType,StructField,StringType};\n\n```", "```scala\nobject sql1 {\n\n def main(args: Array[String]) {\n\n val appName = \"sql example 1\"\n val conf    = new SparkConf()\n\n conf.setAppName(appName)\n\n val sc = new SparkContext(conf)\n\n```", "```scala\n val sqlContext = new org.apache.spark.sql.SQLContext(sc)\n\n val rawRdd = sc.textFile(\"hdfs:///data/spark/sql/adult.test.data_1x\")\n\n val schemaString = \"age workclass fnlwgt education \" +   \"educational-num  marital-status occupation relationship \" +\n\"race gender capital-gain capital-loss hours-per-week \" +\n\"native-country income\"\n\n val schema =\n StructType(\n schemaString.split(\" \").map(fieldName => StructField(fieldName, StringType, true)))\n\n```", "```scala\n val rowRDD = rawRdd.map(_.split(\",\"))\n .map(p => Row( p(0),p(1),p(2),p(3),p(4),p(5),p(6),p(7),p(8),\n p(9),p(10),p(11),p(12),p(13),p(14) ))\n\n val adultDataFrame = sqlContext.createDataFrame(rowRDD, schema)\n\n val jsonData = adultDataFrame.toJSON\n\n jsonData.saveAsTextFile(\"hdfs:///data/spark/sql/adult.json\")\n\n } // end main\n\n} // end sql1\n\n```", "```scala\n[hadoop@hc2nn sql]$ hdfs dfs -ls /data/spark/sql/adult.json\n\nFound 3 items\n-rw-r--r--   3 hadoop supergroup          0 2015-06-20 17:17 /data/spark/sql/adult.json/_SUCCESS\n-rw-r--r--   3 hadoop supergroup       1731 2015-06-20 17:17 /data/spark/sql/adult.json/part-00000\n-rw-r--r--   3 hadoop supergroup       1724 2015-06-20 17:17 /data/spark/sql/adult.json/part-00001\n\n```", "```scala\n[hadoop@hc2nn sql]$ hdfs dfs -cat /data/spark/sql/adult.json/part-00000 | more\n\n{\"age\":\"25\",\"workclass\":\" Private\",\"fnlwgt\":\" 226802\",\"education\":\" 11th\",\"educational-num\":\"\n 7\",\"marital-status\":\" Never-married\",\"occupation\":\" Machine-op-inspct\",\"relationship\":\" Own-\nchild\",\"race\":\" Black\",\"gender\":\" Male\",\"capital-gain\":\" 0\",\"capital-loss\":\" 0\",\"hours-per-we\nek\":\" 40\",\"native-country\":\" United-States\",\"income\":\" <=50K\"}\n\n```", "```scala\n val adultDataFrame = sqlContext.createDataFrame(rowRDD, schema)\n adultDataFrame.save(\"hdfs:///data/spark/sql/adult.parquet\",\"parquet\")\n\n } // end main\n\n} // end sql2\n\n```", "```scala\n[hadoop@hc2nn sql]$ hdfs dfs -ls /data/spark/sql/adult.parquet\nFound 3 items\n-rw-r--r--   3 hadoop supergroup       1412 2015-06-21 13:17 /data/spark/sql/adult.parquet/_common_metadata\n-rw-r--r--   3 hadoop supergroup       1412 2015-06-21 13:17 /data/spark/sql/adult.parquet/_metadata\ndrwxr-xr-x   - hadoop supergroup          0 2015-06-21 13:17 /data/spark/sql/adult.parquet/_temporary\n\n```", "```scala\n[hadoop@hc2nn sql]$ hdfs dfs -cat /data/spark/sql/adult.parquet/_metadata | more\ns%\nct\",\"fields\":[{\"name\":\"age\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"workclass\n\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"fnlwgt\",\"type\":\"string\",\"nullable\":\ntrue,\"metadata\":{}},\n\n```", "```scala\nspark.apache.org/docs/<version>/api/scala/index.html\n\n```", "```scala\nadultDataFrame.printSchema()\n\nroot\n |-- age: string (nullable = true)\n |-- workclass: string (nullable = true)\n |-- fnlwgt: string (nullable = true)\n |-- education: string (nullable = true)\n |-- educational-num: string (nullable = true)\n |-- marital-status: string (nullable = true)\n |-- occupation: string (nullable = true)\n |-- relationship: string (nullable = true)\n |-- race: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- capital-gain: string (nullable = true)\n |-- capital-loss: string (nullable = true)\n |-- hours-per-week: string (nullable = true)\n |-- native-country: string (nullable = true)\n |-- income: string (nullable = true)\n\n```", "```scala\nadultDataFrame.select(\"workclass\",\"age\",\"education\",\"income\").show()\n\nworkclass         age education     income\n Private          25   11th          <=50K\n Private          38   HS-grad       <=50K\n Local-gov        28   Assoc-acdm    >50K\n Private          44   Some-college  >50K\n none             18   Some-college  <=50K\n Private          34   10th          <=50K\n none             29   HS-grad       <=50K\n Self-emp-not-inc 63   Prof-school   >50K\n Private          24   Some-college  <=50K\n Private          55   7th-8th       <=50K\n\n```", "```scala\n adultDataFrame\n .select(\"workclass\",\"age\",\"education\",\"occupation\",\"income\")\n .filter( adultDataFrame(\"age\") > 30 )\n .show()\n\nworkclass         age education     occupation         income\n Private          38   HS-grad       Farming-fishing    <=50K\n Private          44   Some-college  Machine-op-inspct  >50K\n Private          34   10th          Other-service      <=50K\n Self-emp-not-inc 63   Prof-school   Prof-specialty     >50K\n Private          55   7th-8th       Craft-repair       <=50K\n\n```", "```scala\n adultDataFrame\n .groupBy(\"income\")\n .count()\n .show()\n\nincome count\n <=50K 24720\n >50K  7841\n\n```", "```scala\n adultDataFrame\n .groupBy(\"income\",\"occupation\")\n .count()\n .sort(\"occupation\")\n .show()\n\nincome occupation         count\n >50K   Adm-clerical      507\n <=50K  Adm-clerical      3263\n <=50K  Armed-Forces      8\n >50K   Armed-Forces      1\n <=50K  Craft-repair      3170\n >50K   Craft-repair      929\n <=50K  Exec-managerial   2098\n >50K   Exec-managerial   1968\n <=50K  Farming-fishing   879\n >50K   Farming-fishing   115\n <=50K  Handlers-cleaners 1284\n >50K   Handlers-cleaners 86\n >50K   Machine-op-inspct 250\n <=50K  Machine-op-inspct 1752\n >50K   Other-service     137\n <=50K  Other-service     3158\n >50K   Priv-house-serv   1\n <=50K  Priv-house-serv   148\n >50K   Prof-specialty    1859\n <=50K  Prof-specialty    2281\n\n```", "```scala\n adultDataFrame.registerTempTable(\"adult\")\n\n val resRDD = sqlContext.sql(\"SELECT COUNT(*) FROM adult\")\n\n resRDD.map(t => \"Count - \" + t(0)).collect().foreach(println)\n\n```", "```scala\nCount \u2013 32561\n\n```", "```scala\n val resRDD = sqlContext.sql(\"SELECT * FROM adult LIMIT 10\")\n\n resRDD.map(t => t(0)  + \" \" + t(1)  + \" \" + t(2)  + \" \" + t(3)  + \" \" +\n t(4)  + \" \" + t(5)  + \" \" + t(6)  + \" \" + t(7)  + \" \" +\n t(8)  + \" \" + t(9)  + \" \" + t(10) + \" \" + t(11) + \" \" +\n t(12) + \" \" + t(13) + \" \" + t(14)\n )\n .collect().foreach(println)\n\n```", "```scala\n50  Private  283676  Some-college  10  Married-civ-spouse  Craft-repair  Husband  White  Male  0  0  40  United-States  >50K\n\n```", "```scala\nimport org.apache.spark.sql.types._\n\n```", "```scala\n val schema =\n StructType(\n StructField(\"age\",                IntegerType, false) ::\n StructField(\"workclass\",          StringType,  false) ::\n StructField(\"fnlwgt\",             IntegerType, false) ::\n StructField(\"education\",          StringType,  false) ::\n StructField(\"educational-num\",    IntegerType, false) ::\n StructField(\"marital-status\",     StringType,  false) ::\n StructField(\"occupation\",         StringType,  false) ::\n StructField(\"relationship\",       StringType,  false) ::\n StructField(\"race\",               StringType,  false) ::\n StructField(\"gender\",             StringType,  false) ::\n StructField(\"capital-gain\",       IntegerType, false) ::\n StructField(\"capital-loss\",       IntegerType, false) ::\n StructField(\"hours-per-week\",     IntegerType, false) ::\n StructField(\"native-country\",     StringType,  false) ::\n StructField(\"income\",             StringType,  false) ::\n Nil)\n\n val rowRDD = rawRdd.map(_.split(\",\"))\n .map(p => Row( p(0).trim.toInt,p(1),p(2).trim.toInt,p(3),\n p(4).trim.toInt,p(5),p(6),p(7),p(8),\n p(9),p(10).trim.toInt,p(11).trim.toInt,\n p(12).trim.toInt,p(13),p(14) ))\n\n```", "```scala\n val resRDD = sqlContext.sql(\"SELECT COUNT(*) FROM adult WHERE age < 60\")\n resRDD.map(t => \"Count - \" + t(0)).collect().foreach(println)\n\n```", "```scala\nCount \u2013 29917\n\n```", "```scala\n val selectClause = \"SELECT COUNT(*) FROM adult \"\n val filterClause = \"WHERE age > 25 AND age < 60\"\n val resRDD = sqlContext.sql( selectClause + filterClause )\n resRDD.map(t => \"Count - \" + t(0)).collect().foreach(println)\n\n```", "```scala\nCount \u2013 23506\n\n```", "```scala\n val selectClause = \"SELECT COUNT(*) FROM adult \"\n val filterClause =\n \"WHERE ( age > 15 AND age < 25 ) OR ( age > 30 AND age < 45 ) \"\n\n val resRDD = sqlContext.sql( selectClause + filterClause )\n resRDD.map(t => \"Count - \" + t(0)).collect().foreach(println)\n\n```", "```scala\nCount \u2013 17198\n\n```", "```scala\n val selectClause = \"SELECT COUNT(*) FROM \"\n val tableClause = \" ( SELECT age,education,occupation from adult) t1 \"\n val filterClause = \"WHERE ( t1.age > 25 ) \"\n val groupClause = \"\"\n val orderClause = \"\"\n\n val resRDD = sqlContext.sql( selectClause + tableClause +\n filterClause +\n groupClause + orderClause\n )\n\n resRDD.map(t => \"Count - \" + t(0)).collect().foreach(println)\n\n```", "```scala\n[hadoop@hc2nn sql]$ hdfs dfs -cat /data/spark/sql/adult.train.data2 | head -2\n\n1,39, State-gov, 77516, Bachelors, 13, Never-married, Adm-clerical, Not-in-family, White, Male, 2174, 0, 40, United-States, <=50K\n2,50, Self-emp-not-inc, 83311, Bachelors, 13, Married-civ-spouse, Exec-managerial, Husband, White, Male, 0, 0, 13, United-States, <=50K\n\n```", "```scala\n val schema =\n StructType(\n StructField(\"idx\",                IntegerType, false) ::\n StructField(\"age\",                IntegerType, false) ::\n StructField(\"workclass\",          StringType,  false) ::\n StructField(\"fnlwgt\",             IntegerType, false) ::\n StructField(\"education\",          StringType,  false) ::\n StructField(\"educational-num\",    IntegerType, false) ::\n StructField(\"marital-status\",     StringType,  false) ::\n StructField(\"occupation\",         StringType,  false) ::\n StructField(\"relationship\",       StringType,  false) ::\n StructField(\"race\",               StringType,  false) ::\n StructField(\"gender\",             StringType,  false) ::\n StructField(\"capital-gain\",       IntegerType, false) ::\n StructField(\"capital-loss\",       IntegerType, false) ::\n StructField(\"hours-per-week\",     IntegerType, false) ::\n StructField(\"native-country\",     StringType,  false) ::\n StructField(\"income\",             StringType,  false) ::\n Nil)\n\n```", "```scala\n val rowRDD = rawRdd.map(_.split(\",\"))\n .map(p => Row( p(0).trim.toInt,\n p(1).trim.toInt,\n p(2),\n p(3).trim.toInt,\n p(4),\n p(5).trim.toInt,\n p(6),\n p(7),\n p(8),\n p(9),\n p(10),\n p(11).trim.toInt,\n p(12).trim.toInt,\n p(13).trim.toInt,\n p(14),\n p(15)\n ))\n\n val adultDataFrame = sqlContext.createDataFrame(rowRDD, schema)\n\n```", "```scala\n val selectClause = \"SELECT t1.idx,age,education,occupation,workclass,race,gender FROM \"\n val tableClause1 = \" ( SELECT idx,age,education,occupation FROM adult) t1 JOIN \"\n val tableClause2 = \" ( SELECT idx,workclass,race,gender FROM adult) t2 \"\n val joinClause = \" ON (t1.idx=t2.idx) \"\n val limitClause = \" LIMIT 10\"\n\n val resRDD = sqlContext.sql( selectClause +\n tableClause1 + tableClause2 +\n joinClause   + limitClause\n )\n\n resRDD.map(t => t(0) + \" \" + t(1) + \" \" + t(2) + \" \" +\n t(3) + \" \" + t(4) + \" \" + t(5) + \" \" + t(6)\n )\n .collect().foreach(println)\n\n```", "```scala\n33 45  Bachelors  Exec-managerial  Private  White  Male\n233 25  Some-college  Adm-clerical  Private  White  Male\n433 40  Bachelors  Prof-specialty  Self-emp-not-inc  White  Female\n633 43  Some-college  Craft-repair  Private  White  Male\n833 26  Some-college  Handlers-cleaners  Private  White  Male\n1033 27  Some-college  Sales  Private  White  Male\n1233 27  Bachelors  Adm-clerical  Private  White  Female\n1433 32  Assoc-voc  Sales  Private  White  Male\n1633 40  Assoc-acdm  Adm-clerical  State-gov  White  Male\n1833 46  Some-college  Prof-specialty  Local-gov  White  Male\n\n```", "```scala\n val selectClause = \"SELECT t1.edu_dist FROM \"\n val tableClause  = \" ( SELECT DISTINCT education AS edu_dist FROM adult ) t1 \"\n val orderClause  = \" ORDER BY t1.edu_dist \"\n\n val resRDD = sqlContext.sql( selectClause + tableClause  + orderClause )\n\n resRDD.map(t => t(0)).collect().foreach(println)\n\n```", "```scala\n 10th\n 11th\n 12th\n 1st-4th\n \u2026\u2026\u2026..\n Preschool\n Prof-school\n Some-college\n\n```", "```scala\n def enumEdu( education:String ) : Int =\n {\n var enumval = 9999\n\n if ( education == \"10th\" )         { enumval = 0 }\n else if ( education == \"11th\" )         { enumval = 1 }\n else if ( education == \"12th\" )         { enumval = 2 }\n else if ( education == \"1st-4th\" )      { enumval = 3 }\n else if ( education == \"5th-6th\" )      { enumval = 4 }\n else if ( education == \"7th-8th\" )      { enumval = 5 }\n else if ( education == \"9th\" )          { enumval = 6 }\n else if ( education == \"Assoc-acdm\" )   { enumval = 7 }\n else if ( education == \"Assoc-voc\" )    { enumval = 8 }\n else if ( education == \"Bachelors\" )    { enumval = 9 }\n else if ( education == \"Doctorate\" )    { enumval = 10 }\n else if ( education == \"HS-grad\" )      { enumval = 11 }\n else if ( education == \"Masters\" )      { enumval = 12 }\n else if ( education == \"Preschool\" )    { enumval = 13 }\n else if ( education == \"Prof-school\" )  { enumval = 14 }\n else if ( education == \"Some-college\" ) { enumval = 15 }\n\n return enumval\n }\n\n```", "```scala\n sqlContext.udf.register( \"enumEdu\", enumEdu _ )\n\n```", "```scala\n val selectClause = \"SELECT enumEdu(t1.edu_dist) as idx,t1.edu_dist FROM \"\n val tableClause  = \" ( SELECT DISTINCT education AS edu_dist FROM adult ) t1 \"\n val orderClause  = \" ORDER BY t1.edu_dist \"\n\n val resRDD = sqlContext.sql( selectClause + tableClause  + orderClause )\n\n resRDD.map(t => t(0) + \" \" + t(1) ).collect().foreach(println)\n\n```", "```scala\n0  10th\n1  11th\n2  12th\n3  1st-4th\n4  5th-6th\n5  7th-8th\n6  9th\n7  Assoc-acdm\n8  Assoc-voc\n9  Bachelors\n10  Doctorate\n11  HS-grad\n12  Masters\n13  Preschool\n14  Prof-school\n15  Some-college\n\n```", "```scala\n def ageBracket( age:Int ) : Int =\n {\n var bracket = 9999\n\n if ( age >= 0  && age < 20  ) { bracket = 0 }\n else if ( age >= 20 && age < 40  ) { bracket = 1 }\n else if ( age >= 40 && age < 60  ) { bracket = 2 }\n else if ( age >= 60 && age < 80  ) { bracket = 3 }\n else if ( age >= 80 && age < 100 ) { bracket = 4 }\n else if ( age > 100 )              { bracket = 5 }\n\n return bracket\n }\n\n```", "```scala\n sqlContext.udf.register( \"ageBracket\", ageBracket _ )\n\n```", "```scala\n val selectClause = \"SELECT age, ageBracket(age) as bracket,education FROM \"\n val tableClause  = \" adult \"\n val limitClause  = \" LIMIT 10 \"\n\n val resRDD = sqlContext.sql( selectClause + tableClause  +\n limitClause )\n\n resRDD.map(t => t(0) + \" \" + t(1) + \" \" + t(2) ).collect().foreach(println)\n\n```", "```scala\n39 1  Bachelors\n50 2  Bachelors\n38 1  HS-grad\n53 2  11th\n28 1  Bachelors\n37 1  Masters\n49 2  9th\n52 2  HS-grad\n31 1  Masters\n42 2  Bachelors\n\n```", "```scala\n sqlContext.udf.register( \"dblAge\", (a:Int) => 2*a )\n\n```", "```scala\n val selectClause = \"SELECT age,dblAge(age) FROM \"\n val tableClause  = \" adult \"\n val limitClause  = \" LIMIT 10 \"\n\n val resRDD = sqlContext.sql( selectClause + tableClause  + limitClause )\n\n resRDD.map(t => t(0) + \" \" + t(1) ).collect().foreach(println)\n\n```", "```scala\n39 78\n50 100\n38 76\n53 106\n28 56\n37 74\n49 98\n52 104\n31 62\n42 84\n\n```", "```scala\nimport org.apache.spark.{SparkConf, SparkContext}\nimport org.apache.spark.sql._\nimport org.apache.spark.sql.hive.HiveContext\n\nobject hive_ex1 {\n\n def main(args: Array[String]) {\n\n val appName = \"Hive Spark Ex 1\"\n val conf    = new SparkConf()\n\n conf.setAppName(appName)\n\n val sc = new SparkContext(conf)\n\n```", "```scala\n val hiveContext = new HiveContext(sc)\n\n import hiveContext.implicits._\n import hiveContext.sql\n\n```", "```scala\n hiveContext.sql( \" \n CREATE TABLE IF NOT EXISTS adult2\n (\n idx             INT,\n age             INT,\n workclass       STRING,\n fnlwgt          INT,\n education       STRING,\n educationnum    INT,\n maritalstatus   STRING,\n occupation      STRING,\n relationship    STRING,\n race            STRING,\n gender          STRING,\n capitalgain     INT,\n capitalloss     INT,\n nativecountry   STRING,\n income          STRING\n )\n\n \")\n\n```", "```scala\n val resRDD = hiveContext.sql(\"SELECT COUNT(*) FROM adult2\")\n\n resRDD.map(t => \"Count : \" + t(0) ).collect().foreach(println)\n\n```", "```scala\nCount : 0\n\n```", "```scala\n[hadoop@hc2nn hive]$ hdfs dfs -ls /data/spark/hive\nFound 1 items\n-rw-r--r--   3 hadoop supergroup    4171350 2015-06-24 15:18 /data/spark/hive/adult.train.data2\n\n```", "```scala\n hiveContext.sql(\"\n\n CREATE EXTERNAL TABLE IF NOT EXISTS adult3\n (\n idx             INT,\n age             INT,\n workclass       STRING,\n fnlwgt          INT,\n education       STRING,\n educationnum    INT,\n maritalstatus   STRING,\n occupation      STRING,\n relationship    STRING,\n race            STRING,\n gender          STRING,\n capitalgain     INT,\n capitalloss     INT,\n nativecountry   STRING,\n income          STRING\n )\n ROW FORMAT DELIMITED FIELDS TERMINATED BY ','\n LOCATION '/data/spark/hive'\n\n \")\n\n```", "```scala\n val resRDD = hiveContext.sql(\"SELECT COUNT(*) FROM adult3\")\n\n resRDD.map(t => \"Count : \" + t(0) ).collect().foreach(println)\n\n```", "```scala\nCount : 32561\n\n```", "```scala\n val resRDD = hiveContext.sql(\"\n\n SELECT DISTINCT education AS edu FROM adult3\n ORDER BY edu\n\n \")\n\n resRDD.map(t => t(0) ).collect().foreach(println)\n\n```", "```scala\n 10th\n 11th\n 12th\n 1st-4th\n 5th-6th\n 7th-8th\n 9th\n Assoc-acdm\n Assoc-voc\n Bachelors\n Doctorate\n HS-grad\n Masters\n Preschool\n Prof-school\n Some-college\n\n```", "```scala\n[hadoop@hc2nn hive]$ hdfs dfs -ls /data/spark/dim1/\nFound 1 items\n-rw-r--r--   3 hadoop supergroup        174 2015-06-25 14:08 /data/spark/dim1/education.csv\n[hadoop@hc2nn hive]$ hdfs dfs -cat /data/spark/dim1/education.csv\n1,10th\n2,11th\n3,12th\n\n```", "```scala\n hiveContext.sql(\"  DROP TABLE IF EXISTS education \")\n hiveContext.sql(\"\n\n CREATE TABLE IF NOT EXISTS  education\n (\n idx        INT,\n name       STRING\n )\n ROW FORMAT DELIMITED FIELDS TERMINATED BY ','\n LOCATION '/data/spark/dim1/'\n \")\n\n```", "```scala\nval resRDD = hiveContext.sql(\" SELECT * FROM education \")\nresRDD.map( t => t(0)+\" \"+t(1) ).collect().foreach(println)\n\n```", "```scala\n1 10th\n2 11th\n3 12th\n\u2026\u2026\u2026\n16 Some-college\n\n```", "```scala\n[hadoop@hc2nn hive]$ hdfs dfs -ls /user/hive/warehouse/adult3\nls: `/user/hive/warehouse/adult3': No such file or directory\n\n```", "```scala\n[hadoop@hc2nn bin]# cp /var/run/cloudera-scm-agent/process/1237-hive-HIVEMETASTORE/hive-site.xml /usr/local/spark/conf\n\n```", "```scala\n15/06/25 16:32:24 WARN DataNucleus.Connection: BoneCP specified but not present in CLASSPATH (s)\nCaused by: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.metastore.\nCaused by: java.lang.reflect.InvocationTargetException\nCaused by: javax.jdo.JDOFatalInternalException: Error creating transactional connection factor\nCaused by: org.datanucleus.exceptions.NucleusException: Attempt to invoke the \"dbcp-builtin\" pnectionPool gave an \nerror : The specified datastore driver (\"org.postgresql.Driver\") was not f. Please check your CLASSPATH\nspecification, and the name of the driver.\nCaused by: org.datanucleus.store.rdbms.connectionpool.DatastoreDriverNotFoundException: The spver\n(\"org.postgresql.Driver\") was not found in the CLASSPATH. Please check your CLASSPATH specme of the driver.\n\n```", "```scala\n[root@hc2nn jars]# pwd ; ls postgresql*\n/opt/cloudera/parcels/CDH/jars\npostgresql-9.0-801.jdbc4.jar\n\n```", "```scala\n[hadoop@hc2nn spark]$ java -version\njava version \"1.7.0_75\"\nOpenJDK Runtime Environment (rhel-2.5.4.0.el6_6-x86_64 u75-b13)\nOpenJDK 64-Bit Server VM (build 24.75-b04, mixed mode)\n\n```", "```scala\n[hadoop@hc2nn lib]$ pwd ; ls -l postgresql*\n/usr/local/spark/lib\n-rw-r--r-- 1 hadoop hadoop 648487 Jun 26 13:20 postgresql-9.4-1201.jdbc41.jar\n\n```", "```scala\n[hadoop@hc2nn bin]$ pwd ; tail compute-classpath.sh\n/usr/local/spark/bin\n\n# add postgresql connector to classpath\nappendToClasspath \"${assembly_folder}\"/postgresql-9.4-1201.jdbc41.jar\n\necho \"$CLASSPATH\"\n\n```", "```scala\nCaused by: MetaException(message:Hive Schema version 0.13.1aa does not match metastore's schema version 0.13.0\n\nMetastore is not upgraded or corrupt)\n\n```", "```scala\n <property>\n <name>hive.metastore.schema.verification</name>\n <value>false</value>\n </property>\n\n```", "```scala\n hiveContext.sql( \"\n\n CREATE TABLE IF NOT EXISTS adult2\n (\n idx             INT,\n age             INT,\n workclass       STRING,\n fnlwgt          INT,\n education       STRING,\n educationnum    INT,\n maritalstatus   STRING,\n occupation      STRING,\n relationship    STRING,\n race            STRING,\n gender          STRING,\n capitalgain     INT,\n capitalloss     INT,\n nativecountry   STRING,\n income          STRING\n )\n\n \")\n\n```", "```scala\n hiveContext.sql(\"\n\n CREATE EXTERNAL TABLE IF NOT EXISTS adult3\n (\n idx             INT,\n age             INT,\n workclass       STRING,\n fnlwgt          INT,\n education       STRING,\n educationnum    INT,\n maritalstatus   STRING,\n occupation      STRING,\n relationship    STRING,\n race            STRING,\n gender          STRING,\n capitalgain     INT,\n capitalloss     INT,\n nativecountry   STRING,\n income          STRING\n )\n ROW FORMAT DELIMITED FIELDS TERMINATED BY ','\n LOCATION '/data/spark/hive'\n\n \")\n\n```", "```scala\nhiveContext.sql(\"\n\nADD JAR /opt/cloudera/parcels/CDH-5.3.3-1.cdh5.3.3.p0.5/jars/hive-contrib-0.13.1-cdh5.3.3.jar\n\n \")\n\nhiveContext.sql(\"\n\nCREATE TEMPORARY FUNCTION row_sequence as 'org.apache.hadoop.hive.contrib.udf.UDFRowSequence';\n\n \")\n\n val resRDD = hiveContext.sql(\"\n\n SELECT row_sequence(),t1.edu FROM\n ( SELECT DISTINCT education AS edu FROM adult3 ) t1\n ORDER BY t1.edu\n\n \")\n\n```"]