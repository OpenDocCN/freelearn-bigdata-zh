["```scala\npackage nz.co.semtechsolutions\n\nimport org.apache.spark._\nimport org.apache.spark.SparkContext._\nimport org.apache.spark.streaming._\nimport org.apache.spark.streaming.twitter._\nimport org.apache.spark.streaming.StreamingContext._\nimport org.apache.spark.sql._\nimport org.apache.spark.sql.types.{StructType,StructField,StringType}\n\nobject twitter1 {\n\n  def main(args: Array[String]) {\n```", "```scala\n    val appName = \"Twitter example 1\"\n    val conf    = new SparkConf()\n\n    conf.setAppName(appName)\n    val sc = new SparkContext(conf)\n\n    val consumerKey       = \"QQpl8xx\"\n    val consumerSecret    = \"0HFzxx\"\n    val accessToken       = \"323xx\"\n    val accessTokenSecret = \"Ilxx\"\n```", "```scala\n    System.setProperty(\"twitter4j.oauth.consumerKey\", consumerKey)\n    System.setProperty(\"twitter4j.oauth.consumerSecret\",\n       consumerSecret)\n    System.setProperty(\"twitter4j.oauth.accessToken\", accessToken)\n    System.setProperty(\"twitter4j.oauth.accessTokenSecret\",\n       accessTokenSecret)\n```", "```scala\n    val ssc    = new StreamingContext(sc, Seconds(5) )\n    val stream = TwitterUtils.createStream(ssc,None)\n       .window( Seconds(60) )\n\n    // split out the hash tags from the stream\n\n    val hashTags = stream.flatMap( status => status.getText.split(\" \").filter(_.startsWith(\"#\")))\n```", "```scala\nhashTags.foreachRDD{ rdd =>\n\nval sqlContext = SQLContextSingleton.getInstance(rdd.sparkContext)\nimport sqlContext.implicits._\n\nval dfHashTags = rdd.map(hashT => hashRow(hashT) ).toDF()\n\ndfHashTags.registerTempTable(\"tweets\")\n\nval tweetcount = sqlContext.sql(\"select count(*) from tweets\")\n\nprintln(\"\\n============================================\")\nprintln(  \"============================================\\n\")\n\nprintln(\"Count of hash tags in stream table : \"\n   + tweetcount.toString )\n\ntweetcount.map(c => \"Count of hash tags in stream table : \"\n   + c(0).toString ).collect().foreach(println)\n\nprintln(\"\\n============================================\")\nprintln(  \"============================================\\n\")\n\n} // for each hash tags rdd\n```", "```scala\nval topCounts60 = hashTags.map((_, 1))\n   .reduceByKeyAndWindow(_ + _, Seconds(60))\n.map{case (topic, count) => (count, topic)}\n.transform(_.sortByKey(false))\n\ntopCounts60.foreachRDD(rdd => {\n\n  val topList = rdd.take(5)\n\n  println(\"\\n===========================================\")\n  println(  \"===========================================\\n\")\n  println(\"\\nPopular topics in last 60 seconds (%s total):\"\n     .format(rdd.count()))\n  topList.foreach{case (count, tag) => println(\"%s (%s tweets)\"\n     .format(tag, count))}\n  println(\"\\n===========================================\")\n  println(  \"==========================================\\n\")\n})\n```", "```scala\n    ssc.start()\n    ssc.awaitTermination()\n\n  } // end main\n} // end twitter1\n```", "```scala\nobject SQLContextSingleton {\n  @transient private var instance: SQLContext = null\n\n  def getInstance(sparkContext: SparkContext):\n    SQLContext = synchronized {\n    if (instance == null) {\n      instance = new SQLContext(sparkContext)\n    }\n    instance\n  }\n}\ncase class hashRow( hashTag: String)\n```", "```scala\n[hadoop@hc2nn twitter1]$  cat twitter.sbt\n\nname := \"Databricks\"\nversion := \"1.0\"\nscalaVersion := \"2.10.4\"\nlibraryDependencies += \"org.apache.spark\" % \"streaming\" % \"1.3.1\" from \"file:///usr/local/spark/lib/spark-assembly-1.3.1-hadoop2.3.0.jar\"\nlibraryDependencies += \"org.apache.spark\" % \"sql\" % \"1.3.1\" from \"file:///usr/local/spark/lib/spark-assembly-1.3.1-hadoop2.3.0.jar\"\nlibraryDependencies += \"org.apache.spark.streaming\" % \"twitter\" % \"1.3.1\" from file:///usr/local/spark/lib/spark-examples-1.3.1-hadoop2.3.0.jar\n\n```", "```scala\n[hadoop@hc2nn twitter1]$ more run_twitter.bash\n#!/bin/bash\n\nSPARK_HOME=/usr/local/spark\nSPARK_BIN=$SPARK_HOME/bin\nSPARK_SBIN=$SPARK_HOME/sbin\n\nJAR_PATH=/home/hadoop/spark/twitter1/target/scala-2.10/data-bricks_2.10-1.0.jar\nCLASS_VAL=nz.co.semtechsolutions.twitter1\n\nTWITTER_JAR=/usr/local/spark/lib/spark-examples-1.3.1-hadoop2.3.0.jar\n\ncd $SPARK_BIN\n\n./spark-submit \\\n --class $CLASS_VAL \\\n --master spark://hc2nn.semtech-solutions.co.nz:7077  \\\n --executor-memory 100M \\\n --total-executor-cores 50 \\\n --jars $TWITTER_JAR \\\n $JAR_PATH\n\n```", "```scala\n======================================\nCount of hash tags in stream table : 707\n======================================\nPopular topics in last 60 seconds (704 total):\n#KCAM\u00c9XICO (139 tweets)\n#BE3 (115 tweets)\n#Fallout4 (98 tweets)\n#OrianaSabatini (69 tweets)\n#MartinaStoessel (61 tweets)\n======================================\n\n```", "```scala\n[hadoop@hc2nn ~]$ telnet dbc-bff687af-08b7.cloud.databricks.com 34563\nTrying 52.6.229.109...\nConnected to dbc-bff687af-08b7.cloud.databricks.com.\nEscape character is '^]'.\n\n```", "```scala\ncurl \u2013u  '<user>:<paswd>' <dbc url> -d \"<parameters>\"\n\n```", "```scala\n/api/1.0/clusters/list\n\n```", "```scala\ncurl -u 'xxxx:yyyyy' 'https://dbc-bff687af-08b7.cloud.databricks.com:34563/api/1.0/clusters/list'\n\n [{\"id\":\"0611-014057-waist9\",\"name\":\"semclust1\",\"status\":\"Pending\",\"driverIp\":\"\",\"jdbcPort\":10000,\"numWorkers\":0}]\n\n```", "```scala\n[{\"id\":\"0611-014057-waist9\",\"name\":\"semclust1\",\"status\":\"Running\",\"driverIp\":\"10.0.196.161\",\"jdbcPort\":10000,\"numWorkers\":1}]\n\n```", "```scala\ncurl -u 'xxxx:yyyy' 'https://dbc-bff687af-08b7.cloud.databricks.com:34563/api/1.0/clusters/list'\n\n[{\"id\":\"0611-023105-moms10\",\"name\":\"semclust\", \"status\":\"Pending\",\"driverIp\":\"\",\"jdbcPort\":10000,\"numWorkers\":0},\n {\"id\":\"0611-014057-waist9\",\"name\":\"semclust1\",\"status\":\"Terminated\",\"driverIp\":\"10.0.196.161\",\"jdbcPort\":10000,\"numWorkers\":1}]\n\n```", "```scala\ncurl -u 'xxxx:yyyy' https://dbc-bff687af-08b7.cloud.databricks.com:34563/api/1.0/contexts/create -d \"language=scala&clusterId=0611-023105-moms10\"\n\n```", "```scala\n{\"error\":\"ClusterNotFoundException: Cluster not found: semclust1\"}\n{\"id\":\"8689178710930730361\"}\n{\"id\":\"2876384417314129043\"}\n\n```", "```scala\ncurl -u 'admin:FirmWare1$34' https://dbc-bff687af-08b7.cloud.databricks.com:34563/api/1.0/commands/execute -d\n\"language=sql&clusterId=0611-023105-moms10&contextId=7690632266172649068&command=select count(*) from cmap\"\n\n{\"id\":\"d8ec4989557d4a4ea271d991a603a3af\"}\n\n```", "```scala\ncurl -u 'xxxx:yyyy' https://dbc-bff687af-08b7.cloud.databricks.com:34563/api/1.0/libraries/upload\n -d \"language=scala&clusterId=0611-023105-moms10&name=lib1&uri=file:///home/hadoop/spark/ann/target/scala-2.10/a-n-n_2.10-1.0.jar\"\n\n{\"name\":\"lib1\",\"uri\":\"file:///home/hadoop/spark/ann/target/scala-2.10/a-n-n_2.10-1.0.jar\"}\n\n```"]