["```java\n<configuration> \n    <appender name=\"file\" class=\"ch.qos.logback.core.FileAppender\"> \n        <file>${log.file}</file> \n        <append>false</append> \n        <encoder> \n            <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level   \n            %logger{60} %X{sourceThread} - %msg%n</pattern> \n        </encoder> \n    </appender> \n\n    <!-- This affects logging for both user code and Flink --> \n    <root level=\"INFO\"> \n        <appender-ref ref=\"file\"/> \n    </root> \n\n    <!-- Uncomment this if you want to only change Flink's logging --> \n    <!--<logger name=\"org.apache.flink\" level=\"INFO\">--> \n        <!--<appender-ref ref=\"file\"/>--> \n    <!--</logger>--> \n\n    <!-- The following lines keep the log level of common  \n    libraries/connectors on \n         log level INFO. The root logger does not override this. You \n         have to manually \n         change the log levels here. --> \n    <logger name=\"akka\" level=\"INFO\"> \n        <appender-ref ref=\"file\"/> \n    </logger> \n    <logger name=\"org.apache.kafka\" level=\"INFO\"> \n        <appender-ref ref=\"file\"/> \n    </logger> \n    <logger name=\"org.apache.hadoop\" level=\"INFO\"> \n        <appender-ref ref=\"file\"/> \n    </logger> \n    <logger name=\"org.apache.zookeeper\" level=\"INFO\"> \n        <appender-ref ref=\"file\"/> \n    </logger> \n\n    <!-- Suppress the irrelevant (wrong) warnings from the Netty \n     channel handler --> \n    <logger name=\"org.jboss.netty.channel.DefaultChannelPipeline\" \n    level=\"ERROR\"> \n        <appender-ref ref=\"file\"/> \n    </logger> \n</configuration> \n\n```", "```java\nimport org.slf4j.LoggerFactory \nimport org.slf4j.Logger \n\nLogger LOG = LoggerFactory.getLogger(MyClass.class) \n\n```", "```java\nLOG.info(\"Value of a = {}, value of b= {}\", myobject.a, myobject.b); \n\n```", "```java\ncatch(Exception e){ \n  LOG.error(\"Error occurred {}\",  e); \n} \n\n```", "```java\nString kafkaproperties = \"/path/to/kafka.properties\";\nParameterTool parameter = ParameterTool.fromPropertiesFile(propertiesFile);\n```", "```java\nParameterTool parameters = ParameterTool.fromSystemProperties(); \n\n```", "```java\nParameterTool parameters = ParameterTool.fromArgs(args); \n\n```", "```java\nString propertiesFile = /my.properties\"; \nParameterTool parameters = ParameterTool.fromPropertiesFile(propertiesFile); \n\n```", "```java\nparameter.getRequired(\"key\"); \nparameter.get(\"paramterName\", \"myDefaultValue\"); \nparameter.getLong(\"expectedCount\", -1L); \nparameter.getNumberOfParameters() \n\n```", "```java\n//Initiate Record Tuple\nRecordTuple rc = new RecordTuple(value0, value1, value2, value3, value4, value5, value6, value7);\n\n// Define RecordTuple instead of using Tuple8\npublic static class RecordTuple extends Tuple8<String, String, Integer, String, Integer, Integer, Integer, Integer> {\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 public RecordTuple() {\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 super();\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 }\n\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 public RecordTuple(String value0, String value1, Integer value2, String value3, Integer value4, Integer value5,\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Integer value6, Integer value7) {\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 super(value0, value1, value2, value3, value4, value5, value6, value7);\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 }\n\u00a0\u00a0\u00a0\u00a0\u00a0 }\u00a0\n```", "```java\nfinal ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment(); \n\n// register the class of the serializer as serializer for a type \nenv.getConfig().registerTypeWithKryoSerializer(MyCustomType.class, MyCustomSerializer.class); \n\n// register an instance as serializer for a type \nMySerializer mySerializer = new MySerializer(); \nenv.getConfig().registerTypeWithKryoSerializer(MyCustomType.class, mySerializer); \n\n```", "```java\n<dependency> \n  <groupId>com.twitter</groupId> \n  <artifactId>chill-protobuf</artifactId> \n  <version>0.5.2</version> \n</dependency> \n<dependency> \n  <groupId>com.google.protobuf</groupId> \n  <artifactId>protobuf-java</artifactId> \n  <version>2.5.0</version> \n</dependency> \n\n```", "```java\npublic class TestMapper extends RichMapFunction<String, Integer> { \n  private Counter errorCounter; \n\n  @Override \n  public void open(Configuration config) { \n    this.errorCounter = getRuntimeContext() \n      .getMetricGroup() \n      .counter(\"errorCounter\"); \n  } \n\n  @public Integer map(String value) throws Exception { \n    this.errorCounter.inc(); \n  } \n} \n\n```", "```java\npublic class TestMapper extends RichMapFunction<String, Integer> { \n  private int valueToExpose; \n\n  @Override \n  public void open(Configuration config) { \n    getRuntimeContext() \n      .getMetricGroup() \n      .gauge(\"MyGauge\", new Gauge<Integer>() { \n        @Override \n        public Integer getValue() { \n          return valueToReturn; \n        } \n      }); \n  } \n} \n\n```", "```java\npublic class TestMapper extends RichMapFunction<Long, Integer> { \n  private Histogram histogram; \n\n  @Override \n  public void open(Configuration config) { \n    this.histogram = getRuntimeContext() \n      .getMetricGroup() \n      .histogram(\"myHistogram\", new MyHistogram()); \n  } \n\n  @public Integer map(Long value) throws Exception { \n    this.histogram.update(value); \n  } \n} \n\n```", "```java\npublic class MyMapper extends RichMapFunction<Long, Integer> { \n  private Meter meter; \n\n  @Override \n  public void open(Configuration config) { \n    this.meter = getRuntimeContext() \n      .getMetricGroup() \n      .meter(\"myMeter\", new MyMeter()); \n  } \n\n  @public Integer map(Long value) throws Exception { \n    this.meter.markEvent(); \n  } \n} \n\n```", "```java\nmetrics.reporters: my_jmx_reporter \n\nmetrics.reporter.my_jmx_reporter.class: org.apache.flink.metrics.jmx.JMXReporter \nmetrics.reporter.my_jmx_reporter.port: 9020-9040 \n\n```", "```java\n{ \n    \"refresh-interval\": 3000, \n    \"timezone-offset\": 19800000, \n    \"timezone-name\": \"India Standard Time\", \n    \"flink-version\": \"1.0.3\", \n    \"flink-revision\": \"f3a6b5f @ 06.05.2016 @ 12:58:02 UTC\" \n} \n\n```", "```java\n{ \n    \"taskmanagers\": 1, \n    \"slots-total\": 1, \n    \"slots-available\": 1, \n    \"jobs-running\": 0, \n    \"jobs-finished\": 1, \n    \"jobs-cancelled\": 0, \n    \"jobs-failed\": 0, \n    \"flink-version\": \"1.0.3\", \n    \"flink-commit\": \"f3a6b5f\" \n} \n\n```", "```java\n{ \n    \"jobs-running\": [], \n    \"jobs-finished\": [ \n        \"cd978489f5e76e5988fa0e5a7c76c09b\" \n    ], \n    \"jobs-cancelled\": [], \n    \"jobs-failed\": [] \n} \n\n```", "```java\n{ \n    \"running\": [], \n    \"finished\": [ \n        { \n            \"jid\": \"cd978489f5e76e5988fa0e5a7c76c09b\", \n            \"name\": \"Flink Java Job at Sun Dec 04 16:13:16 IST 2016\", \n            \"state\": \"FINISHED\", \n            \"start-time\": 1480848197679, \n            \"end-time\": 1480848198310, \n            \"duration\": 631, \n            \"last-modification\": 1480848198310, \n            \"tasks\": { \n                \"total\": 3, \n                \"pending\": 0, \n                \"running\": 0, \n                \"finished\": 3, \n                \"canceling\": 0, \n                \"canceled\": 0, \n                \"failed\": 0 \n            } \n        } \n    ] \n} \n\n```", "```java\n{ \n    \"jid\": \"cd978489f5e76e5988fa0e5a7c76c09b\", \n    \"name\": \"Flink Java Job at Sun Dec 04 16:13:16 IST 2016\", \n    \"isStoppable\": false, \n    \"state\": \"FINISHED\", \n    \"start-time\": 1480848197679, \n    \"end-time\": 1480848198310, \n    \"duration\": 631, \n    \"now\": 1480849319207, \n    \"timestamps\": { \n        \"CREATED\": 1480848197679, \n        \"RUNNING\": 1480848197733, \n        \"FAILING\": 0, \n        \"FAILED\": 0, \n        \"CANCELLING\": 0, \n        \"CANCELED\": 0, \n        \"FINISHED\": 1480848198310, \n        \"RESTARTING\": 0 \n    }, \n    \"vertices\": [ \n        { \n            \"id\": \"f590afd023018e19e30ce3cd7a16f4b1\", \n            \"name\": \"CHAIN DataSource (at  \n             getDefaultTextLineDataSet(WordCountData.java:70) \n             (org.apache.flink.api.java.io.CollectionInputFormat)) -> \n             FlatMap (FlatMap at main(WordCount.java:81)) ->   \n             Combine(SUM(1), at main(WordCount.java:84)\", \n            \"parallelism\": 1, \n            \"status\": \"FINISHED\", \n            \"start-time\": 1480848197744, \n            \"end-time\": 1480848198061, \n            \"duration\": 317, \n            \"tasks\": { \n                \"CREATED\": 0, \n                \"SCHEDULED\": 0, \n                \"DEPLOYING\": 0, \n                \"RUNNING\": 0, \n                \"FINISHED\": 1, \n                \"CANCELING\": 0, \n                \"CANCELED\": 0, \n                \"FAILED\": 0 \n            }, \n            \"metrics\": { \n                \"read-bytes\": 0, \n                \"write-bytes\": 1696, \n                \"read-records\": 0, \n                \"write-records\": 170 \n            } \n        }, \n        { \n            \"id\": \"c48c21be9c7bf6b5701cfa4534346f2f\", \n            \"name\": \"Reduce (SUM(1), at main(WordCount.java:84)\", \n            \"parallelism\": 1, \n            \"status\": \"FINISHED\", \n            \"start-time\": 1480848198034, \n            \"end-time\": 1480848198190, \n            \"duration\": 156, \n            \"tasks\": { \n                \"CREATED\": 0, \n                \"SCHEDULED\": 0, \n                \"DEPLOYING\": 0, \n                \"RUNNING\": 0, \n                \"FINISHED\": 1, \n                \"CANCELING\": 0, \n                \"CANCELED\": 0, \n                \"FAILED\": 0 \n            }, \n            \"metrics\": { \n                \"read-bytes\": 1696, \n                \"write-bytes\": 1696, \n                \"read-records\": 170, \n                \"write-records\": 170 \n            } \n        }, \n        { \n            \"id\": \"ff4625cfad1f2540bd08b99fb447e6c2\", \n            \"name\": \"DataSink (collect())\", \n            \"parallelism\": 1, \n            \"status\": \"FINISHED\", \n            \"start-time\": 1480848198184, \n            \"end-time\": 1480848198269, \n            \"duration\": 85, \n            \"tasks\": { \n                \"CREATED\": 0, \n                \"SCHEDULED\": 0, \n                \"DEPLOYING\": 0, \n                \"RUNNING\": 0, \n                \"FINISHED\": 1, \n                \"CANCELING\": 0, \n                \"CANCELED\": 0, \n                \"FAILED\": 0 \n            }, \n            \"metrics\": { \n                \"read-bytes\": 1696, \n                \"write-bytes\": 0, \n                \"read-records\": 170, \n                \"write-records\": 0 \n            } \n        } \n    ], \n    \"status-counts\": { \n        \"CREATED\": 0, \n        \"SCHEDULED\": 0, \n        \"DEPLOYING\": 0, \n        \"RUNNING\": 0, \n        \"FINISHED\": 3, \n        \"CANCELING\": 0, \n        \"CANCELED\": 0, \n        \"FAILED\": 0 \n    }, \n    \"plan\": { \n//plan details \n\n    } \n} \n\n```", "```java\n{ \n    \"jid\": \"cd978489f5e76e5988fa0e5a7c76c09b\", \n    \"name\": \"Flink Java Job at Sun Dec 04 16:13:16 IST 2016\", \n    \"execution-config\": { \n        \"execution-mode\": \"PIPELINED\", \n        \"restart-strategy\": \"default\", \n        \"job-parallelism\": -1, \n        \"object-reuse-mode\": false, \n        \"user-config\": {} \n    } \n} \n\n```", "```java\n/config \n/overview \n/jobs \n/joboverview/running \n/joboverview/completed \n/jobs/<jobid> \n/jobs/<jobid>/vertices \n/jobs/<jobid>/config \n/jobs/<jobid>/exceptions \n/jobs/<jobid>/accumulators \n/jobs/<jobid>/vertices/<vertexid> \n/jobs/<jobid>/vertices/<vertexid>/subtasktimes \n/jobs/<jobid>/vertices/<vertexid>/taskmanagers \n/jobs/<jobid>/vertices/<vertexid>/accumulators \n/jobs/<jobid>/vertices/<vertexid>/subtasks/accumulators \n/jobs/<jobid>/vertices/<vertexid>/subtasks/<subtasknum> \n/jobs/<jobid>/vertices/<vertexid>/subtasks/<subtasknum>/attempts/<attempt> \n/jobs/<jobid>/vertices/<vertexid>/subtasks/<subtasknum>/attempts/<attempt>/accumulators \n/jobs/<jobid>/plan \n\n```"]