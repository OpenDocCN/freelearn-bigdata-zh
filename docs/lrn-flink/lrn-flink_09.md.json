["```java\nwget \n    https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-\n    cloud-sdk-135.0.0-linux-x86_64.tar.gz\n\n```", "```java\ntar -xzf google-cloud-sdk-135.0.0-linux-x86_64.tar.gz\n\n```", "```java\ncd google-cloud-sdk\nbin/gcloud init\n\n```", "```java\ngcloud auth login\n\n```", "```java\nwget \n    https://github.com/GoogleCloudPlatform/bdutil/archive/master.zip\n\n```", "```java\nunzip master.zip\ncd bdutil-master\n\n```", "```java\n # A GCS bucket used for sharing generated SSH keys and GHFS configuration. \nCONFIGBUCKET=\"bdutil-flink-bucket\" \n\n# The Google Cloud Platform text-based project-id which owns the GCE resources. \nPROJECT=\"bdutil-flink-project\" \n\n###################### Cluster/Hardware Configuration ######### \n# These settings describe the name, location, shape and size of your cluster, \n# though these settings may also be used in deployment-configuration--for \n# example, to whitelist intra-cluster SSH using the cluster prefix. \n\n# GCE settings. \nGCE_IMAGE='https://www.googleapis.com/compute/v1/projects/debian-cloud/global/images/backports-debian-7-wheezy-v20160531' \nGCE_MACHINE_TYPE='n1-standard-4' \nGCE_ZONE=\"europe-west1-d\" \n# When setting a network it's important for all nodes be able to communicate \n# with eachother and for SSH connections to be allowed inbound to complete \n# cluster setup and configuration. \n\n```", "```java\n./bdutil -e extensions/flink/flink_env.sh deploy\n\n```", "```java\ngcloud --project=bdutil ssh --zone=europe-west1-c hadoop-m \nSat Nov 19 06:12:27 UTC 2016: Staging files successfully deleted. \nSat Nov 19 06:12:27 UTC 2016: Invoking on master: ./deploy-ssh-master-setup.sh \n.Sat Nov 19 06:12:27 UTC 2016: Waiting on async 'ssh' jobs to finish. Might take a while... \n. \nSat Nov 19 06:12:29 UTC 2016: Step 'deploy-ssh-master-setup,*' done... \nSat Nov 19 06:12:29 UTC 2016: Invoking on workers: ./deploy-core-setup.sh \n..Sat Nov 19 06:12:29 UTC 2016: Invoking on master: ./deploy-core-setup.sh \n.Sat Nov 19 06:12:30 UTC 2016: Waiting on async 'ssh' jobs to finish. Might take a while... \n... \nSat Nov 19 06:13:14 UTC 2016: Step 'deploy-core-setup,deploy-core-setup' done... \nSat Nov 19 06:13:14 UTC 2016: Invoking on workers: ./deploy-ssh-worker-setup.sh \n..Sat Nov 19 06:13:15 UTC 2016: Waiting on async 'ssh' jobs to finish. Might take a while... \n.. \nSat Nov 19 06:13:17 UTC 2016: Step '*,deploy-ssh-worker-setup' done... \nSat Nov 19 06:13:17 UTC 2016: Invoking on master: ./deploy-master-nfs-setup.sh \n.Sat Nov 19 06:13:17 UTC 2016: Waiting on async 'ssh' jobs to finish. Might take a while... \n. \nSat Nov 19 06:13:23 UTC 2016: Step 'deploy-master-nfs-setup,*' done... \nSat Nov 19 06:13:23 UTC 2016: Invoking on workers: ./deploy-client-nfs-setup.sh \n..Sat Nov 19 06:13:23 UTC 2016: Invoking on master: ./deploy-client-nfs-setup.sh \n.Sat Nov 19 06:13:24 UTC 2016: Waiting on async 'ssh' jobs to finish. Might take a while... \n... \nSat Nov 19 06:13:33 UTC 2016: Step 'deploy-client-nfs-setup,deploy-client-nfs-setup' done... \nSat Nov 19 06:13:33 UTC 2016: Invoking on master: ./deploy-start.sh \n.Sat Nov 19 06:13:34 UTC 2016: Waiting on async 'ssh' jobs to finish. Might take a while... \n. \nSat Nov 19 06:13:49 UTC 2016: Step 'deploy-start,*' done... \nSat Nov 19 06:13:49 UTC 2016: Invoking on workers: ./install_flink.sh \n..Sat Nov 19 06:13:49 UTC 2016: Invoking on master: ./install_flink.sh \n.Sat Nov 19 06:13:49 UTC 2016: Waiting on async 'ssh' jobs to finish. Might take a while... \n... \nSat Nov 19 06:13:53 UTC 2016: Step 'install_flink,install_flink' done... \nSat Nov 19 06:13:53 UTC 2016: Invoking on master: ./start_flink.sh \n.Sat Nov 19 06:13:54 UTC 2016: Waiting on async 'ssh' jobs to finish. Might take a while... \n. \nSat Nov 19 06:13:55 UTC 2016: Step 'start_flink,*' done... \nSat Nov 19 06:13:55 UTC 2016: Command steps complete. \nSat Nov 19 06:13:55 UTC 2016: Execution complete. Cleaning up temporary files... \nSat Nov 19 06:13:55 UTC 2016: Cleanup complete. \n\n```", "```java\n/home/hadoop/flink-install/bin$ ./flink run   \n    ../examples/WordCount.jar\n\n11/19/2016 06:56:05     Job execution switched to status RUNNING. \n11/19/2016 06:56:05     CHAIN DataSource (at getDefaultTextLineDataSet(WordCountData.java:70) (org.apache.flink.api.java.io.CollectionInputFormat)) -> FlatMap (FlatMap at main(WordCount.java:69)) -> Combine(SUM(1), at main(WordCount.java:72)(1/1) switched to SCHEDULED \n11/19/2016 06:56:05     CHAIN DataSource (at getDefaultTextLineDataSet(WordCountData.java:70) (org.apache.flink.api.java.io.CollectionInputFormat)) -> FlatMap (FlatMap at main(WordCount.java:69)) -> Combine(SUM(1), at main(WordCount.java:72)(1/1) switched to DEPLOYING \n11/19/2016 06:56:05     CHAIN DataSource (at getDefaultTextLineDataSet(WordCountData.java:70) (org.apache.flink.api.java.io.CollectionInputFormat)) -> FlatMap (FlatMap at main(WordCount.java:69)) -> Combine(SUM(1), at main(WordCount.java:72)(1/1) switched to RUNNING \n11/19/2016 06:56:05     CHAIN Reduce (SUM(1), at main(WordCount.java:72) -> FlatMap (collect())(1/4) switched to SCHEDULED \n11/19/2016 06:56:05     CHAIN DataSource (at getDefaultTextLineDataSet(WordCountData.java:70) (org.apache.flink.api.java.io.CollectionInputFormat)) -> FlatMap (FlatMap at main(WordCount.java:69)) -> Combine(SUM(1), at main(WordCount.java:72)(1/1) switched to FINISHED \n... \nRUNNING \n11/19/2016 06:56:06     DataSink (collect() sink)(3/4) switched to SCHEDULED \n11/19/2016 06:56:06     DataSink (collect() sink)(3/4) switched to DEPLOYING \n11/19/2016 06:56:06     DataSink (collect() sink)(1/4) switched to SCHEDULED \n11/19/2016 06:56:06     DataSink (collect() sink)(1/4) switched to DEPLOYING \n11/19/2016 06:56:06     CHAIN Reduce (SUM(1), at main(WordCount.java:72) -> FlatMap (collect())(1/4) switched to FINISHED \n11/19/2016 06:56:06     CHAIN Reduce (SUM(1), at main(WordCount.java:72) -> FlatMap (collect())(3/4) switched to FINISHED \n11/19/2016 06:56:06     DataSink (collect() sink)(3/4) switched to  \n11/19/2016 06:56:06     CHAIN Reduce (SUM(1), at  \n11/19/2016 06:56:06     DataSink (collect() sink)(2/4) switched to FINISHED \n11/19/2016 06:56:06     Job execution switched to status FINISHED. \n(after,1) \n(arms,1) \n(arrows,1) \n(awry,1) \n(bare,1) \n(be,4) \n(coil,1) \n(consummation,1) \n(contumely,1) \n(d,4) \n(delay,1) \n(despis,1) \n... \n\n```", "```java\n./bdutil -e extensions/flink/flink_env.sh delete\n\n```", "```java\n    wget http://www-eu.apache.org/dist/flink/flink-1.1.4/flink-\n            1.1.4-bin-hadoop27-scala_2.11.tgz\n\n    ```", "```java\n    tar -xzf flink-1.1.4-bin-hadoop27-scala_2.11.tgz\n\n    ```", "```java\n    cd flink-1.1.4\n    export HADOOP_CONF_DIR=/etc/hadoop/conf\n    export YARN_CONF_DIR=/etc/hadoop/conf\n\n    ```", "```java\n./bin/flink run -m yarn-cluster -yn 2 \n    ./examples/batch/WordCount.jar\n\n```", "```java\n2016-11-20 06:41:45,760 INFO  org.apache.flink.yarn.YarnClusterClient                       - Submitting job with JobID: 0004040e04879e432365825f50acc80c. Waiting for job completion. \nSubmitting job with JobID: 0004040e04879e432365825f50acc80c. Waiting for job completion. \nConnected to JobManager at Actor[akka.tcp://flink@172.31.0.221:46603/user/jobmanager#478604577] \n11/20/2016 06:41:45     Job execution switched to status RUNNING. \n11/20/2016 06:41:46     CHAIN DataSource (at getDefaultTextLineDataSet(WordCountData.java:70) (org.apache.flink.api.java.io.CollectionInputFormat)) -> FlatMap (FlatMap at main(WordCount.java:80)) -> Combine(SUM(1), at main(WordCount.java:83)(1/1) switched to RUNNING \n11/20/2016 06:41:46     Reduce (SUM(1), at  \ngetDefaultTextLineDataSet(WordCountData.java:70) (org.apache.flink.api.java.io.CollectionInputFormat)) -> FlatMap (FlatMap at main(WordCount.java:80)) -> Combine(SUM(1), at main(WordCount.java:83)(1/1) switched to FINISHED \n11/20/2016 06:41:46     Reduce (SUM(1), at main(WordCount.java:83)(1/2) switched to DEPLOYING \n11/20/2016 06:41:46     Reduce (SUM(1), at main(WordCount.java:83)(1/2) switched to RUNNING \n11/20/2016 06:41:46     Reduce (SUM(1), at main(WordCount.java:83)(2/2) switched to RUNNING \n1/20/2016 06:41:46     Reduce (SUM(1), at main(WordCount.java:83)(1/2) switched to FINISHED \n11/20/2016 06:41:46     DataSink (collect())(2/2) switched to DEPLOYING \n11/20/2016 06:41:46     Reduce (SUM(1), at main(WordCount.java:83)(2/2) switched to FINISHED \n11/20/2016 06:41:46     DataSink (collect())(2/2) switched to RUNNING \n11/20/2016 06:41:46     DataSink (collect())(2/2) switched to FINISHED \n11/20/2016 06:41:46     Job execution switched to status FINISHED. \n(action,1) \n(after,1) \n(against,1) \n(and,12) \n(arms,1) \n(arrows,1) \n(awry,1) \n(ay,1) \n(bare,1) \n(be,4) \n(bodkin,1) \n(bourn,1) \n(calamity,1) \n(cast,1) \n(coil,1) \n(come,1) \n\n```", "```java\n$ bin/yarn-session.sh -n 2 -tm 768 -s 4\n\n```", "```java\n2016-11-20 06:49:09,021 INFO  org.apache.flink.yarn.YarnClusterDescriptor                 \n- Using values: \n2016-11-20 06:49:09,023 INFO  org.apache.flink.yarn.YarnClusterDescriptor                   \n-   TaskManager count = 2\n2016-11-20 06:49:09,023 INFO  org.apache.flink.yarn.YarnClusterDescriptor                   \n-   JobManager memory = 1024\n2016-11-20 06:49:09,023 INFO  org.apache.flink.yarn.YarnClusterDescriptor                   \n-   TaskManager memory = 768 \n2016-11-20 06:49:09,488 INFO  org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl     \n- Timeline service address: http://ip-172-31-2-68.ap-south-1.compute.internal:8188/ws/v1/timeline/ \n2016-11-20 06:49:09,613 INFO  org.apache.hadoop.yarn.client.RMProxy                         - Connecting to ResourceManager at ip-172-31-2-68.ap-south-1.compute.internal/172.31.2.68:8032 \n2016-11-20 06:49:10,309 WARN  org.apache.flink.yarn.YarnClusterDescriptor                   \n- The configuration directory ('/home/hadoop/flink-1.1.3/conf') contains both LOG4J and Logback configuration files. Please delete or rename one of them. \n2016-11-20 06:49:10,325 INFO  org.apache.flink.yarn.Utils                                   - Copying from file:/home/hadoop/flink-1.1.3/conf/log4j.properties to hdfs://ip-172-31-2-68.ap-south-1.compute.internal:8020/user/hadoop/.flink/application_1479621657204_0004/log4j.properties \n2016-11-20 06:49:10,558 INFO  org.apache.flink.yarn.Utils                                   - Copying from file:/home/hadoop/flink-1.1.3/lib to hdfs://ip-172-31-2-68.ap-south-1.compute.internal:8020/user/hadoop/.flink/application_1479621657204_0004/lib \n2016-11-20 06:49:12,392 INFO  org.apache.flink.yarn.Utils                                   - Copying from /home/hadoop/flink-1.1.3/conf/flink-conf.yaml to hdfs://ip-172-31-2-68.ap-south-1.compute.internal:8020/user/hadoop/.flink/application_1479621657204_0004/flink-conf.yaml \n2016-11-20 06:49:12,825 INFO  org.apache.flink.yarn.YarnClusterDescriptor                   \n- Submitting application master application_1479621657204_0004 \n2016-11-20 06:49:12,893 INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl         \n- Submitted application application_1479621657204_0004 \n2016-11-20 06:49:12,893 INFO  org.apache.flink.yarn.YarnClusterDescriptor                   \n- Waiting for the cluster to be allocated \n2016-11-20 06:49:17,929 INFO  org.apache.flink.yarn.YarnClusterDescriptor                   \n- YARN application has been deployed successfully. \nFlink JobManager is now running on 172.31.0.220:45056 \nJobManager Web Interface: http://ip-172-31-2-68.ap-south-1.compute.internal:20888/proxy/application_1479621657204_0004/ \n2016-11-20 06:49:18,117 INFO  org.apache.flink.yarn.YarnClusterClient                       - Starting client actor system. \n2016-11-20 06:49:18,591 INFO  akka.event.slf4j.Slf4jLogger                                  - Slf4jLogger started \n2016-11-20 06:49:18,671 INFO  Remoting                                                       \nakka.tcp://flink@172.31.0.220:45056/user/jobmanager. \n2016-11-20 06:49:19,343 INFO  org.apache.flink.yarn.ApplicationClient                       - Successfully registered at the ResourceManager using JobManager Actor[akka.tcp://flink@172.31.0.220:45056/user/jobmanager#1383364724] \nNumber of connected TaskManagers changed to 2\\. Slots available: 8 \n\n```", "```java\n$./bin/flink run ./examples/batch/WordCount.jar\n\n```", "```java\n2016-11-20 06:53:06,439 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                 \n- Found YARN properties file /tmp/.yarn-properties-hadoop \n2016-11-20 06:53:06,439 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                 \n- Found YARN properties file /tmp/.yarn-properties-hadoop \nFound YARN properties file /tmp/.yarn-properties-hadoop \n2016-11-20 06:53:06,508 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                 \n-  \norg.apache.flink.yarn.cli.FlinkYarnSessionCli                 \n- YARN properties set default parallelism to 8 \nYARN properties set default parallelism to 8 \n2016-11-20 06:53:06,510 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                 \n- Found YARN properties file /tmp/.yarn-properties-hadoop \n2016-11-20 06:53:07,069 INFO  org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl     \n- Timeline service address: http://ip-172-31-2-68.ap-south-1.compute.internal:8188/ws/v1/timeline/ \nExecuting WordCount example with default input data set. \nUse --input to specify file input. \nPrinting result to stdout. Use --output to specify output path. \n2016-11-20 06:53:07,728 INFO  org.apache.flink.yarn.YarnClusterClient                       - Waiting until all TaskManagers have connected \nWaiting until all TaskManagers have connected \n2016-11-20 06:53:07,729 INFO  org.apache.flink.yarn.YarnClusterClient                        \nSubmitting job with JobID: a0557f5751fa599b3eec30eb50d0a9ed. Waiting for job completion. \nConnected to JobManager at Actor[akka.tcp://flink@172.31.0.220:45056/user/jobmanager#1383364724] \n11/20/2016 06:53:09     Job execution switched to status RUNNING. \n11/20/2016 06:53:09     CHAIN DataSource (at getDefaultTextLineDataSet(WordCountData.java:70) (org.apache.flink.api.java.io.CollectionInputFormat)) -> FlatMap (FlatMap at main(WordCount.java:80)) -> Combine(SUM(1), at main(WordCount.java:83)(1/1) switched to SCHEDULED \n11/20/2016 06:53:09     CHAIN DataSource (at getDefaultTextLineDataSet(WordCountData.java:70) (org.apache.flink.api.java.io.CollectionInputFormat)) -> FlatMap (FlatMap at main(WordCount.java:80)) -> Combine(SUM(1), at main(WordCount.java:83)(1/1) switched to DEPLOYING \n11/20/2016 06:53:09     CHAIN DataSource (at getDefaultTextLineDataSet(WordCountData.java:70) (org.apache.flink.api.java.io.CollectionInputFormat)) -> FlatMap (FlatMap at main(WordCount.java:80)) -> Combine(SUM(1), at  \n11/20/2016 06:53:10     DataSink (collect())(7/8) switched to FINISHED \n11/20/2016 06:53:10     DataSink (collect())(8/8) switched to FINISHED \n11/20/2016 06:53:10     Job execution switched to status FINISHED. \n(bourn,1) \n(coil,1) \n(come,1) \n(d,4) \n(dread,1) \n(is,3) \n(long,1) \n(make,2) \n(more,1) \n(must,1) \n(no,2) \n(oppressor,1) \n(pangs,1) \n(perchance,1) \n(sicklied,1) \n(something,1) \n(takes,1) \n(these,1) \n(us,3) \n(what,1) \nProgram execution finished \nJob with JobID a0557f5751fa599b3eec30eb50d0a9ed has finished. \nJob Runtime: 903 ms \nAccumulator Results: \n- f895985ab9d76c97aba23bc6689c7936 (java.util.ArrayList) [170 elements] \n\n```", "```java\n// Read data from S3 bucket \nenv.readTextFile(\"s3://<bucket>/<endpoint>\"); \n\n// Write data to S3 bucket \nstream.writeAsText(\"s3://<bucket>/<endpoint>\"); \n\n// Use S3 as FsStatebackend \nenv.setStateBackend(new FsStateBackend(\"s3://<your-bucket>/<endpoint>\"));\n\n```"]