["```scala\n// Read in the data\nval oilPriceDF = spark\n\u00a0\u00a0 .read\n\u00a0\u00a0 .option(\"header\",\"true\")\n\u00a0\u00a0 .option(\"inferSchema\", \"true\")\n\u00a0\u00a0 .csv(\"brent_oil_prices.csv\")\n```", "```scala\n// A date conversion UDF\ndef convertDate(date:String) : String = {\n\u00a0\u00a0\u00a0\u00a0 val dt = new SimpleDateFormat(\"dd/MM/yyyy\").parse(date)\n\u00a0\u00a0\u00a0\u00a0 val newDate = new SimpleDateFormat(\"yyyy-MM-dd\").format(dt)\n\u00a0\u00a0\u00a0\u00a0 newDate\n}\n```", "```scala\nval convertDateUDF = udf {(Date: String) => convertDate(Date)}\nval oilPriceDatedDF = oilPriceDF\n\u00a0\u00a0\u00a0 .withColumn(\"DATE\", convertDate(oilPriceDF(\"DATE\")))\n```", "```scala\nval oilPriceDated2015DF = oilPriceDatedDF.filter(\"year(DATE)==2015\")\n```", "```scala\nval windowDF = oilPriceDatedDF.groupBy(\n\u00a0\u00a0 window(oilPriceDatedDF.col(\"DATE\"),\"1 week\", \"1 week\", \"4 days\"))\n```", "```scala\nwindowDF.count.show(20, false)\n```", "```scala\n+---------------------------------------------+-----+ \n|window                                       |count| \n+---------------------------------------------+-----+ \n|[2011-11-07 00:00:00.0,2011-11-14 00:00:00.0]|5    | \n|[2011-11-14 00:00:00.0,2011-11-21 00:00:00.0]|5    | \n|[2011-11-21 00:00:00.0,2011-11-28 00:00:00.0]|5    | \n+---------------------------------------------+-----+ \n\n```", "```scala\nimport java.text.SimpleDateFormat\nimport java.util.Date\nimport org.apache.spark.sql.Row\nimport org.apache.spark.sql.expressions.{MutableAggregationBuffer, UserDefinedAggregateFunction}\nimport org.apache.spark.sql.types._\n\nclass HighLowCalc extends UserDefinedAggregateFunction {\n\n// we will input (date, price) tuples\ndef inputSchema: org.apache.spark.sql.types.StructType = StructType(\n\u00a0 StructField(\"date\", StringType) ::\n\u00a0 StructField(\"price\", DoubleType) :: Nil)\n\n// these are the values we will keep a track of internally\ndef bufferSchema: StructType = StructType(\n\u00a0 StructField(\"HighestHighDate\", StringType) ::\n\u00a0 StructField(\"HighestHighPrice\", DoubleType) ::\n\u00a0 StructField(\"LowestLowDate\", StringType) ::\n\u00a0 StructField(\"LowestLowPrice\", DoubleType) :: Nil\n)\n\n// the schema of our final output data\ndef dataType: DataType = DataTypes.createStructType(\n\u00a0 Array(\n\u00a0\u00a0\u00a0 StructField(\"HighestHighDate\", StringType),\n\u00a0\u00a0\u00a0 StructField(\"HighestHighPrice\", DoubleType),\n\u00a0\u00a0\u00a0 StructField(\"LowestLowDate\", StringType),\n\u00a0\u00a0\u00a0 StructField(\"LowestLowPrice\", DoubleType)\n\u00a0 )\n)\n\n// this function is deterministic\ndef deterministic: Boolean = true\n\n// define our initial state using the bufferSchema\ndef initialize(buffer: MutableAggregationBuffer): Unit = {\n\u00a0 // the date of the highest price so far\n\u00a0 buffer(0) = \"\"\n\u00a0 // the highest price seen so far\n\u00a0 buffer(1) = 0d\n\u00a0 // the date of the lowest price so far\n\u00a0 buffer(2) = \"\"\n\u00a0 // the lowest price seen so far\n\u00a0 buffer(3) = 1000000d\n}\n\n// how to behave given new input (date, price)\ndef update(buffer: MutableAggregationBuffer,input: Row): Unit = {\n\n\u00a0 // find out how the input price compares\n\u00a0 // to the current internal value - looking for highest price only\n\u00a0 (input.getDouble(1) compare buffer.getAs[Double](1)).signum match {\n\u00a0\u00a0\u00a0 // if the input price is lower then do nothing\n\u00a0\u00a0\u00a0 case -1 => {}\n\u00a0\u00a0\u00a0 // if the input price is higher then update the internal status\n\u00a0\u00a0\u00a0 case\u00a0 1 => {\n\u00a0\u00a0\u00a0\u00a0\u00a0 buffer(1) = input.getDouble(1)\n\u00a0\u00a0\u00a0\u00a0\u00a0 buffer(0) = input.getString(0)\n\u00a0\u00a0\u00a0 }\n\u00a0\u00a0\u00a0 // if the input price is the same then ensure we have the earliest date\n\u00a0\u00a0\u00a0 case\u00a0 0 => {\n\u00a0\u00a0\u00a0\u00a0\u00a0 // if new date earlier than current date, replace\n\u00a0\u00a0\u00a0\u00a0\u00a0 (parseDate(input.getString(0)),parseDate(buffer.getAs[String](0)))\n\u00a0\u00a0\u00a0\u00a0\u00a0 match {\n\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0case (Some(a), Some(b)) => {\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0if(a.before(b)){\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0buffer(0) = input.getString(0)\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0}\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 }\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 // anything else do nothing\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 case _ => {}\n\u00a0\u00a0\u00a0\u00a0\u00a0 }\n\u00a0\u00a0\u00a0 }\n\u00a0 }\n\u00a0 // now repeat to find the lowest price\n\u00a0 (input.getDouble(1) compare buffer.getAs[Double](3)).signum match {\n\u00a0\u00a0\u00a0 // if the input price is lower then update the internal state\n\u00a0\u00a0\u00a0 case -1 => {\n\u00a0\u00a0\u00a0\u00a0\u00a0 buffer(3) = input.getDouble(1)\n\u00a0\u00a0\u00a0\u00a0\u00a0 buffer(2) = input.getString(0)\n\u00a0\u00a0\u00a0 }\n\u00a0\u00a0\u00a0 // if the input price is higher then do nothing\n\u00a0\u00a0\u00a0 case\u00a0 1 => {}\n\u00a0\u00a0\u00a0 // if the input price is the same then ensure we have the latest date\n\u00a0\u00a0\u00a0 case\u00a0 0 => {\n\u00a0\u00a0\u00a0\u00a0\u00a0 // if new date later than current date, replace\n\u00a0\u00a0\u00a0 \u00a0\u00a0(parseDate(input.getString(0)),parseDate(buffer.getAs[String](2)))\n\u00a0\u00a0\u00a0\u00a0\u00a0 match {\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 case (Some(a), Some(b)) => {\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 if(a.after(b)){\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0buffer(2) = input.getString(0)\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 }\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 }\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 // anything else do nothing\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0case _ => {}\n\u00a0\u00a0\u00a0\u00a0\u00a0 }\n\u00a0\u00a0\u00a0 }\n\u00a0 }\n}\n\n// define the behaviour to merge two aggregation buffers together\ndef merge(buffer1: MutableAggregationBuffer, buffer2: Row): Unit = {\n\u00a0 // first deal with the high prices\n\u00a0 (buffer2.getDouble(1) compare buffer1.getAs[Double](1)).signum match {\n\u00a0\u00a0\u00a0 case -1 => {}\n\u00a0\u00a0\u00a0 case\u00a0 1 => {\n\u00a0\u00a0\u00a0 \u00a0\u00a0buffer1(1) = buffer2.getDouble(1)\n\u00a0\u00a0\u00a0 \u00a0\u00a0buffer1(0) = buffer2.getString(0)\n\u00a0\u00a0 \u00a0}\n\u00a0\u00a0 \u00a0case\u00a0 0 => {\n\u00a0\u00a0\u00a0\u00a0 \u00a0// work out which date is earlier\n\u00a0\u00a0\u00a0\u00a0 \u00a0(parseDate(buffer2.getString(0)),parseDate(buffer1.getAs[String](0)))\n\u00a0\u00a0\u00a0\u00a0\u00a0 match {\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 case (Some(a), Some(b)) => {\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 if(a.before(b)){\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 buffer1(0) = buffer2.getString(0)\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 }\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 }\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 case _ => {}\n\u00a0\u00a0\u00a0\u00a0\u00a0 }\n\u00a0\u00a0\u00a0 }\n\u00a0 }\n\u00a0 // now deal with the low prices\n\u00a0 (buffer2.getDouble(3) compare buffer1.getAs[Double](3)).signum match {\n\u00a0\u00a0\u00a0 case -1 => {\n\u00a0\u00a0\u00a0 \u00a0\u00a0buffer1(3) = buffer2.getDouble(3)\n\u00a0\u00a0\u00a0\u00a0\u00a0 buffer1(2) = buffer2.getString(2)\n\u00a0\u00a0\u00a0 }\n\u00a0\u00a0\u00a0 case\u00a0 1 => {}\n\u00a0\u00a0\u00a0 case\u00a0 0 => {\n\u00a0\u00a0\u00a0\u00a0\u00a0 // work out which date is later\n\u00a0\u00a0\u00a0\u00a0\u00a0 (parseDate(buffer2.getString(2)),parseDate(buffer1.getAs[String](2)))\n\u00a0\u00a0\u00a0\u00a0\u00a0 match {\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 case (Some(a), Some(b)) => {\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 if(a.after(b)){\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0buffer1(2) = buffer2.getString(2)\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 }\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 }\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 case _ => {}\n\u00a0\u00a0\u00a0\u00a0\u00a0 }\n\u00a0\u00a0\u00a0 }\n\u00a0 }\n}\n\n// when all is complete, output:\n// (highestDate, highestPrice, lowestDate, lowestPrice)\ndef evaluate(buffer: Row): Any = {\n\u00a0 (buffer(0), buffer(1), buffer(2), buffer(3))\n}\n\n// convert a String to a Date for easy comparison\ndef parseDate(value: String): Option[Date] = {\n\u00a0 try {\n\u00a0 \u00a0\u00a0Some(new SimpleDateFormat(\"yyyy-MM-dd\").parse(value))\n\u00a0 } catch {\n\u00a0\u00a0\u00a0 case e: Exception => None\n\u00a0\u00a0}\n}\n\n}\n```", "```scala\nList(\"1\", \"2\", \"a\", \"b\", \"3\", \"c\").flatMap(a =>\n\u00a0\u00a0 try {\n\u00a0\u00a0\u00a0\u00a0\u00a0 Some(Integer.parseInt(a.trim))\n\u00a0\u00a0 } catch {\n\u00a0\u00a0\u00a0\u00a0\u00a0 case e: NumberFormatException => None\n\u00a0\u00a0 }\n}).sum\n```", "```scala\nval hlc = new HighLowCalc\nspark.udf.register(\"hlc\", hlc)\n\nval highLowDF = windowDF.agg(expr(\"hlc(DATE,PRICE) as highLow\"))\nhighLowDF.show(20, false)\n```", "```scala\n+-----------------------------+----------------------+\n|window\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0    |highLow\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0|\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\n|\u00a0 \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0                |\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0       |\n+-----------------------------+----------------------+\n|[2011-11-07 00:00:00.0,\u2026 ]   |[2011-11-08,115.61,\u2026 ]|\n|[2011-11-14 00:00:00.0,\u2026 ]   |[2011-11-14,112.57,\u2026 ]|\n|[2011-11-21 00:00:00.0,\u2026 ]   |[2011-11-22,107.77,\u2026 ]|\n```", "```scala\n// ensure our data is in correct date order by sorting\n// on each first date in the window column window\n// Struct contains the values start and end\nval sortedWindow = Window.orderBy(\"window.start\")\n\n// define the lag of just one row\nval lagCol = lag(col(\"highLow\"), 1).over(sortedWindow)\n\n// create a new DataFrame with the additional column \"highLowPrev\"\n// where the previous row does not exist, null will be entered\nval highLowPrevDF = highLowDF.withColumn(\"highLowPrev\", lagCol)\n```", "```scala\nval simpleTrendFunc = udf {\n\u00a0 (currentHigh : Double, currentLow : Double,\n\u00a0\u00a0 prevHigh : Double, prevLow : Double) => {\n\u00a0\u00a0 \u00a0\u00a0(((currentHigh - prevHigh) compare 0).signum +\n\u00a0\u00a0\u00a0\u00a0 ((currentLow - prevLow) compare 0).signum compare 0).signum\u00a0}\n}\n```", "```scala\nval simpleTrendDF = highLowPrevDF.withColumn(\"sign\",\u00a0\u00a0\u00a0\n\u00a0\u00a0\u00a0 simpleTrendFunc(highLowPrevDF(\"highLow.HighestHighPrice\"),\n\u00a0\u00a0\u00a0 \u00a0highLowPrevDF(\"highLow.LowestLowPrice\"),\n\u00a0\u00a0\u00a0 \u00a0highLowPrevDF(\"highLowPrev.HighestHighPrice\"),\n\u00a0\u00a0\u00a0 \u00a0highLowPrevDF(\"highLowPrev.LowestLowPrice\")\n\u00a0\u00a0\u00a0 )\n)\n\n// view the DataFrame\nsimpleTrendDF.show(20, false)\n\n+----------------------+----------------------+-----+\n|highLow \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0  |highLowPrev\u00a0\u00a0 \u00a0\u00a0\u00a0     |sign |\n+----------------------+----------------------+-----+\n|[2011-11-08,115.61,...|null\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0  |null |\n|[2011-11-14,112.57,...|2011-11-08,115.61,... |-1\u00a0\u00a0 |\n|[2011-11-22,107.77,...|[2011-11-14,112.57,...|1\u00a0\u00a0\u00a0 |\n```", "```scala\n// define the lag of just one row\nval lagSignCol = lag(col(\"sign\"), 1).over(sortedWindow)\n\n// create a new DataFrame with the additional column signPrev\nval lagSignColDF = simpleTrendDF.withColumn(\"signPrev\", lagSignCol)\n\n// define a UDF that calculates the reversals\nval reversalFunc = udf {\n\u00a0 (currentSign : Int, prevSign : Int,\n\u00a0\u00a0\u00a0 prevHighPrice : Double, prevHighDate : String,\n\u00a0\u00a0\u00a0 prevLowPrice : Double, prevLowDate : String) => {\n\u00a0\u00a0 \u00a0\u00a0\u00a0(currentSign compare prevSign).signum match {\n\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0case 0 => null\n\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0// if the current SimpleTrend is less than the\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 // previous, the previous high is a reversal\n\u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0\u00a0case -1 => (prevHighDate, prevHighPrice)\n\u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0\u00a0// if the current SimpleTrend is more than the\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 // previous, the previous low is a reversal\n\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0case 1 => (prevLowDate, prevLowPrice)\n\u00a0\u00a0 \u00a0\u00a0\u00a0}\n\u00a0\u00a0\u00a0 }\n}\n\n// use the UDF to create a new DataFrame with the\n// additional column reversals\nval reversalsDF = lagSignColDF.withColumn(\"reversals\",\n\u00a0 reversalFunc(lagSignColDF(\"sign\"),\n\u00a0\u00a0\u00a0 lagSignColDF(\"signPrev\"),\n\u00a0\u00a0\u00a0 lagSignColDF(\"highLowPrev.HighestHighPrice\"),\n\u00a0\u00a0\u00a0 lagSignColDF(\"highLowPrev.HighestHighDate\"),\n\u00a0\u00a0\u00a0 lagSignColDF(\"highLowPrev.LowestLowPrice\"),\n\u00a0\u00a0\u00a0 lagSignColDF(\"highLowPrev.LowestLowDate\")\n\u00a0 )\n)\n\nreversalsDF.show(20, false)\n\n+----------------------+------+--------+--------------------+\n|highLowPrev\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |sign\u00a0 |signPrev|reversals\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |\n+----------------------+------+-----------------------------+\n|null\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |null\u00a0 |null\u00a0\u00a0\u00a0 |null\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |\n|[2011-11-08,115.61,\u2026 ]|-1\u00a0\u00a0\u00a0 |null\u00a0\u00a0\u00a0 |null\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |\n|[2011-11-14,112.57,\u2026 ]|-1\u00a0\u00a0\u00a0 |-1\u00a0\u00a0\u00a0\u00a0\u00a0 |null\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |\n|[2011-11-22,107.77,\u2026 ]|1\u00a0\u00a0\u00a0\u00a0 |-1\u00a0\u00a0\u00a0\u00a0\u00a0 |[2011-11-24,105.3]\u00a0 |\n|[2011-11-29,111.25,\u2026 ]|-1\u00a0\u00a0\u00a0 |1\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 |[2011-11-29,111.25] |\n```", "```scala\ndef evaluate(buffer: Row): Any = {\n\u00a0 // compare the highest and lowest dates\n\u00a0\u00a0(parseDate(buffer.getString(0)), parseDate(buffer.getString(2))) match {\n\u00a0\u00a0 \u00a0\u00a0case (Some(a), Some(b)) => {\n\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0// if the highest date is the earlier\n\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0if(a.before(b)){\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0// highest date, highest price, lowest date,\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 // lowest price, first(highest price), second\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0(buffer(0), buffer(1), buffer(2), buffer(3), buffer(1), buffer(3))\n\u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0}\n\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0else {\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0// the lowest date is earlier or they are\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 // both the same (shouldn\u2019t be possible)\n\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0// highest date, highest price, lowest date,\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 // lowest price, first(lowest price), second\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0(buffer(0), buffer(1), buffer(2), buffer(3), buffer(3), buffer(1))\n\u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0}\n\u00a0 \u00a0\u00a0\u00a0}\n\u00a0\u00a0 \u00a0\u00a0// we couldn\u2019t parse one or both of the dates -shouldn\u2019t reach here\n\u00a0\u00a0 \u00a0\u00a0case _ =>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 (buffer(0), buffer(1), buffer(2), buffer(3), buffer(1), buffer(3))\n\u00a0\u00a0}\n}\n```", "```scala\nval fhlsSelectDF = reversalsDF.select(\n\u00a0\"window.start\",\n\u00a0\"highLow.firstPrice\",\n\u00a0\"highLow.HighestHighPrice\",\n\u00a0\"highLow.LowestLowPrice\",\n\u00a0\"highLow.secondPrice\",\n\u00a0\"highLow.HighestHighDate\",\n\u00a0\"highLow.LowestLowDate\",\n\u00a0\"window.end\",\n\u00a0\"reversals._1\",\n\u00a0\"reversals._2\")\n```", "```scala\nval lookup = Map(\"_1\" -> \"reversalDate\", \"_2\" -> \"reversalPrice\")\nval fhlsDF = fhlsSelectDF.select { fhlsSelectDF.columns.map(c =>\n\u00a0\u00a0 col(c).as(lookup.getOrElse(c, c))):_*\n}\nfhlsDF.orderBy(asc(\"start\")).show(20, false)\n```", "```scala\n\u00a0\u00a0 fhlsDF.write\n\u00a0\u00a0\u00a0\u00a0 .format(\"com.databricks.spark.csv\")\n\u00a0\u00a0\u00a0\u00a0 .option(\"header\", \"true\")\n\u00a0\u00a0\u00a0\u00a0 .save(\"fhls\");\n```", "```scala\n.option(\"codec\", \"org.apache.hadoop.io.compress.CryptoCodec\")\n```", "```scala\ndata = data.slice(0, 200).map(function(d) {\n\u00a0 return {\n\u00a0\u00a0 \u00a0date: parseDate(d.start),\n\u00a0\u00a0\u00a0 open: +d.firstPrice,\n\u00a0\u00a0\u00a0 high: +d.HighestHighPrice,\n\u00a0\u00a0\u00a0 low: +d.LowestLowPrice,\n\u00a0\u00a0\u00a0 close: +d.SecondPrice\n\u00a0 };\n});\n```", "```scala\ndata = data.slice(0, 200).map(function(d) {\n\u00a0 return {\n\u00a0\u00a0\u00a0 date: parseDate(d.start),\n\u00a0\u00a0\u00a0 open: +d.firstPrice,\n\u00a0\u00a0\u00a0 high: +d.HighestHighPrice,\n\u00a0\u00a0\u00a0 low: +d.LowestLowPrice,\n\u00a0\u00a0\u00a0 close: +d.secondPrice,\n\u00a0\u00a0\u00a0 price: +d.reversalPrice\n\u00a0 };\n}).sort(function(a, b) {\n\u00a0 return d3.ascending(accessor.d(a), accessor.d(b));\n});\n```", "```scala\nsvg.selectAll(\".dot\")\n\u00a0 .data(data)\n\u00a0 .enter().append(\"circle\")\n\u00a0 .attr(\"class\", \"dot\")\n\u00a0\u00a0.attr(\"r\", 1)\n\u00a0 .attr(\"cx\", function(d) { return x(d.date); })\n\u00a0 .attr(\"cy\", function(d) { return y(d.price); })\n\u00a0 .style(\"fill\",\"black\");\u00a0\n```", "```scala\n        val tempHighLowDF =\n        spark.createDataFrame(highLowDF.rdd.map(x => {\n        \u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0RowFactory.create(x.getAs(\"window\")., x.getAs(\"highLow\"),\n        \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 x.getAs(\"highLowPrev\"))\n\n        \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 }), highLowDF.schema)\n        ```", "```scala\nval newColumnNames = Seq(\"DATE\", \"PRICE\")\n\nval highLowHighestDF = simpleTrendDF.select(\"highLow.HighestHighDate\", \"highLow.HighestHighPrice\").toDF(newColumnNames:_*)\n\nval highLowLowestDF = simpleTrendDF.select(\"highLow.LowestLowDate\", \"highLow.LowestLowPrice\").toDF(newColumnNames:_*)\n\nval stackedDF = highLowHighestDF.union(highLowLowestDF)\n\nstackedDF.write\n\u00a0\u00a0\u00a0\u00a0 .option(\"header\", \"true\")\n\u00a0\u00a0\u00a0\u00a0 .csv(\"stackData.csv\")\n```"]