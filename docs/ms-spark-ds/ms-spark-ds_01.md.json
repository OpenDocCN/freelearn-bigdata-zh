["```scala\nspark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem \nspark.hadoop.fs.s3a.access.key=MyAccessKeyID \nspark.hadoop.fs.s3a.secret.key=MySecretKey\n\n```", "```scala\nspark.driver.extraClassPath=${HADOOP_HOME}/extlib/hadoop-aws-currentversion.jar:${HADOOP_HOME}/ext/aws-java-sdk-1.7.4.jar\n\n```", "```scala\nval rdd = spark.sparkContext.textFile(\"s3a://user/dir/text.txt\") \n\n```", "```scala\nspark.sparkContext.textFile(\"s3a://AccessID:SecretKey@user/dir/file\") \n\n```", "```scala\nval ds = Seq(1, 2, 3, 4, 5).toDS \nds.write.parquet(\"/data/numbers.parquet\") \nval fromParquet = spark.read.parquet(\"/data/numbers.parquet\")\n```", "```scala\n<dependency>   \n   <groupId>org.apache.avro</groupId>   \n   <artifactId>avro</artifactId>   \n   <version>1.7.7</version> \n</dependency> \n\n```", "```scala\nspark-submit --class package.Class /  \n             --master yarn / \n             --deploy-mode client [options] <app jar> [app options] \n\n```", "```scala\n<dependency> \n    <groupId>org.apache.lucene</groupId> \n    <artifactId>lucene-core</artifactId> \n    <version>6.1.0</version> \n</dependency> \n\n```", "```scala\n<dependency> \n    <groupId>org.elasticsearch</groupId> \n    <artifactId>elasticsearch-spark_2.10</artifactId> \n    <version>2.2.0-m1</version> \n</dependency> \n\n```"]