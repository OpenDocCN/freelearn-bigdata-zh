["```scala\nbin/pyspark --packages com.databricks:spark-csv_2.10:1.0.3\nbin/spark-shell --packages com.databricks:spark-csv_2.10:1.0.3\n\n```", "```scala\nwget http://search.maven.org/remotecontent?filepath=org/apache/commons/commons-csv/1.1/commons-csv-1.1.jar\nwget http://search.maven.org/remotecontent?filepath=com/databricks/spark-csv_2.10/1.0.0/spark-csv_2.10-1.0.0.jar\n\n```", "```scala\nstatic SparkSession spark = SparkSession \n        .builder() \n        .appName(\"JavaLDAExample\") \n          .master(\"local[*]\") \n          .config(\"spark.sql.warehouse.dir\", \"C:/Exp/\")               \n          .getOrCreate(); \n\n```", "```scala\nString input = \"input/letterdata.data\"; \nDataset<Row> df = spark.read().format(\"com.databricks.spark.csv\").option(\"header\", \"true\").load(input);  \ndf.show();   \n\n```", "```scala\n<repositories> \n    <repository> \n      <id>cloudera-repos</id> \n      <name>Cloudera Repos</name> \n      <url>https://repository.cloudera.com/artifactory/cloudera-repos/</url> \n    </repository> \n</repositories> \n And including the following dependency in the pom.xml:  \n<dependency> \n      <groupId>com.cloudera.sparkts</groupId> \n      <artifactId>sparkts</artifactId> \n      <version>0.1.0</version> \n</dependency> \n\n```", "```scala\nspark-shell \\\n --jars sparkts-0.1.0-jar-with-dependencies.jar \\\n --driver-class-path sparkts-0.1.0-jar-with-dependencies.jar\n\n```", "```scala\n          SPARK_HOME = \"/home/spark-2.0.0-bin-hadoop2.7/R/lib\" \n          Sys.setenv(SPARK_MEM=\"8g\") \n          Sys.setenv(SPARK_HOME = \"/home/spark-2.0.0-bin-hadoop2.7\") \n          .libPaths(c(file.path(Sys.getenv(\"SPARK_HOME\"), \"R\",\n          \"lib\"),.libPaths())) \n\n    ```", "```scala\n          library(SparkR, lib.loc = SPARK_HOME)\n          ibrary(SparkR) \n\n    ```", "```scala\n          sc <- sparkR.init(appName = \"SparkR-DataFrame-example\", master =\n          \"local\")\n          sqlContext <- sparkRSQL.init(sc) \n\n    ```", "```scala\n          df <- createDataFrame(sqlContext, faithful) \n          head(df) \n\n    ```", "```scala\n          install.packages(\"xml2\", dependencies = TRUE) \n          install.packages(\"Rcpp\", dependencies = TRUE) \n          install.packages(\"plyr\", dependencies = TRUE) \n          install.packages(\"devtools\", dependencies = TRUE) \n          install.packages(\"MatrixModels\", dependencies = TRUE) \n          install.packages(\"quantreg\", dependencies = TRUE)  \n          install.packages(\"moments\", dependencies = TRUE) \n          install.packages(\"xml2\") \n          install.packages(c(\"digest\", \"gtable\", \"scales\", \"rversions\",\n          \"lintr\")) \n\n    ```", "```scala\n     sudo apt-get -y build-dep libcurl4-gnutls-dev \n          sudo apt-get install libcurl4-gnutls-dev \n          sudo apt-get install r-cran-plyr \n          sudo apt-get install r-cran-reshape2\n\n    ```", "```scala\n          library(devtools) \n          devtools::install_github(\"SKKU-SKT/ggplot2.SparkR\") \n\n    ```", "```scala\n          library(moments) \n          library(ggplot2) \n\n    ```", "```scala\n          time_taken <- c (15, 16, 18, 17.16, 16.5, 18.6, 19.0, 20.4, 20.6, \n          25.15, 27.27, 25.24, 21.05, 21.65, 20.92, 22.61, 23.71, 35, 39, 50) \n          df_new <- data.frame(time_taken)  \n          head(df_new)  \n          df<- createDataFrame(sqlContext, data = df_new)  \n          head(df) \n\n    ```", "```scala\n          skewness(df) \n          kurtosis(df_new) \n\n    ```", "```scala\n          ggplot(df, aes(x = time_taken)) + stat_density(geom=\"line\",\n          col= \"green\", size = 1, bw = 4) + theme_bw() \n\n    ```", "```scala\n16/10/04 11:59:52 ERROR Shell: Failed to locate the winutils binary in the hadoop binary path\njava.io.IOException: Could not locate executable null\\bin\\winutils.exe in the Hadoop binaries.\n```"]