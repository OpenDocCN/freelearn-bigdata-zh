["```py\ndirty_data = spark.createDataFrame([\n          (1,'Porsche','Boxster S','Turbo',2.5,4,22,None)\n        , (2,'Aston Martin','Vanquish','Aspirated',6.0,12,16,None)\n        , (3,'Porsche','911 Carrera 4S Cabriolet','Turbo',3.0,6,24,None)\n        , (3,'General Motors','SPARK ACTIV','Aspirated',1.4,None,32,None)\n        , (5,'BMW','COOPER S HARDTOP 2 DOOR','Turbo',2.0,4,26,None)\n        , (6,'BMW','330i','Turbo',2.0,None,27,None)\n        , (7,'BMW','440i Coupe','Turbo',3.0,6,23,None)\n        , (8,'BMW','440i Coupe','Turbo',3.0,6,23,None)\n        , (9,'Mercedes-Benz',None,None,None,None,27,None)\n        , (10,'Mercedes-Benz','CLS 550','Turbo',4.7,8,21,79231)\n        , (11,'Volkswagen','GTI','Turbo',2.0,4,None,None)\n        , (12,'Ford Motor Company','FUSION AWD','Turbo',2.7,6,20,None)\n        , (13,'Nissan','Q50 AWD RED SPORT','Turbo',3.0,6,22,None)\n        , (14,'Nissan','Q70 AWD','Aspirated',5.6,8,18,None)\n        , (15,'Kia','Stinger RWD','Turbo',2.0,4,25,None)\n        , (16,'Toyota','CAMRY HYBRID LE','Aspirated',2.5,4,46,None)\n        , (16,'Toyota','CAMRY HYBRID LE','Aspirated',2.5,4,46,None)\n        , (18,'FCA US LLC','300','Aspirated',3.6,6,23,None)\n        , (19,'Hyundai','G80 AWD','Turbo',3.3,6,20,None)\n        , (20,'Hyundai','G80 AWD','Turbo',3.3,6,20,None)\n        , (21,'BMW','X5 M','Turbo',4.4,8,18,121231)\n        , (22,'GE','K1500 SUBURBAN 4WD','Aspirated',5.3,8,18,None)\n    ], ['Id','Manufacturer','Model','EngineType','Displacement',\n        'Cylinders','FuelEconomy','MSRP'])\n```", "```py\ndirty_data.count(), dirty_data.distinct().count()\n```", "```py\nfull_removed = dirty_data.dropDuplicates()\n```", "```py\n(\n    dirty_data\n    .groupby(dirty_data.columns)\n    .count()\n    .filter('count > 1')\n    .show()\n)\n```", "```py\n(\n    full_removed\n    .groupby([col for col in full_removed.columns if col != 'Id'])\n    .count()\n    .filter('count > 1')\n    .show()\n)\n```", "```py\nno_ids = (\n    full_removed\n    .select([col for col in full_removed.columns if col != 'Id'])\n)\n\nno_ids.count(), no_ids.distinct().count()\n(21, 19), indicating that we have four records that are duplicated, just like we saw earlier.\n```", "```py\nid_removed = full_removed.dropDuplicates(\n    subset = [col for col in full_removed.columns if col != 'Id']\n)\n```", "```py\nimport pyspark.sql.functions as fn\n\nid_removed.agg(\n      fn.count('Id').alias('CountOfIDs')\n    , fn.countDistinct('Id').alias('CountOfDistinctIDs')\n).show()\n```", "```py\n(\n    id_removed\n    .groupby('Id')\n    .count()\n    .filter('count > 1')\n    .show()\n)\n```", "```py\nnew_id = (\n    id_removed\n    .select(\n        [fn.monotonically_increasing_id().alias('Id')] + \n        [col for col in id_removed.columns if col != 'Id'])\n)\n\nnew_id.show()\n```", "```py\n(\n    spark.createDataFrame(\n        new_id\n        .rdd\n        .map(\n           lambda row: (\n                 row['Id']\n               , sum([c == None for c in row])\n           )\n        )\n        .collect()\n        .filter(lambda el: el[1] > 1)\n        ,['Id', 'CountMissing']\n    )\n    .orderBy('CountMissing', ascending=False)\n    .show()\n)\n```", "```py\nfor k, v in sorted(\n    merc_out\n        .agg(*[\n               (1 - (fn.count(c) / fn.count('*')))\n                    .alias(c + '_miss')\n               for c in merc_out.columns\n           ])\n        .collect()[0]\n        .asDict()\n        .items()\n    , key=lambda el: el[1]\n    , reverse=True\n):\n    print(k, v)\n```", "```py\n(\n    new_id\n    .where('Id == 197568495616')\n    .show()\n)\n```", "```py\n(\n    merc_out\n    .where('Id == 197568495616')\n    .show()\n)\nId equal to\u00a0197568495616, as shown in the following screenshot:\n```", "```py\n[\n    (1 - (fn.count(c) / fn.count('*')))\n        .alias(c + '_miss')\n    for c in merc_out.columns\n]\n```", "```py\nno_MSRP = merc_out.select([col for col in new_id.columns if col != 'MSRP'])\n```", "```py\nmultipliers = (\n    no_MSRP\n    .agg(\n          fn.mean(\n              fn.col('FuelEconomy') / \n              (\n                  fn.col('Displacement') * fn.col('Cylinders')\n              )\n          ).alias('FuelEconomy')\n        , fn.mean(\n            fn.col('Cylinders') / \n            fn.col('Displacement')\n        ).alias('Cylinders')\n    )\n).toPandas().to_dict('records')[0]\n```", "```py\nimputed = (\n    no_MSRP\n    .withColumn('FuelEconomy', fn.col('FuelEconomy') / fn.col('Displacement') / fn.col('Cylinders'))\n    .withColumn('Cylinders', fn.col('Cylinders') / fn.col('Displacement'))\n    .fillna(multipliers)\n    .withColumn('Cylinders', (fn.col('Cylinders') * fn.col('Displacement')).cast('integer'))\n    .withColumn('FuelEconomy', fn.col('FuelEconomy') * fn.col('Displacement') * fn.col('Cylinders'))\n)\n```", "```py\nfeatures = ['Displacement', 'Cylinders', 'FuelEconomy']\nquantiles = [0.25, 0.75]\n\ncut_off_points = []\n\nfor feature in features:\n    quants = imputed.approxQuantile(feature, quantiles, 0.05)\n\n    IQR = quants[1] - quants[0]\n    cut_off_points.append((feature, [\n        quants[0] - 1.5 * IQR,\n        quants[1] + 1.5 * IQR,\n    ]))\n\ncut_off_points = dict(cut_off_points)\n```", "```py\noutliers = imputed.select(*['id'] + [\n       (\n           (imputed[f] < cut_off_points[f][0]) |\n           (imputed[f] > cut_off_points[f][1])\n       ).alias(f + '_o') for f in features\n  ])\n```", "```py\nwith_outliers_flag = imputed.join(outliers, on='Id')\n\n(\n    with_outliers_flag\n    .filter('FuelEconomy_o')\n    .select('Id', 'Manufacturer', 'Model', 'FuelEconomy')\n    .show()\n)\n```", "```py\nno_outliers = (\n    with_outliers_flag\n    .filter('!FuelEconomy_o')\n    .select(imputed.columns)\n)\nFuelEconomy_o column. That's it!\n```", "```py\ndescriptive_stats = no_outliers.describe(features)\n```", "```py\ndescriptive_stats_all = no_outliers.describe()\ndescriptive_stats_all.show()\n```", "```py\n(\n    no_outliers\n    .select(features)\n    .groupBy('Cylinders')\n    .agg(*[\n          fn.count('*').alias('Count')\n        , fn.mean('FuelEconomy').alias('MPG_avg')\n        , fn.mean('Displacement').alias('Disp_avg')\n        , fn.stddev('FuelEconomy').alias('MPG_stdev')\n```", "```py\n\n        , fn.stddev('Displacement').alias('Disp_stdev')\n    ])\n    .orderBy('Cylinders')\n).show()\n```", "```py\n(\n    no_outliers\n    .corr('Cylinders', 'Displacement')\n)\n```", "```py\nn_features = len(features)\n\ncorr = []\n\nfor i in range(0, n_features):\n    temp = [None] * i\n\n    for j in range(i, n_features):\n        temp.append(no_outliers.corr(features[i], features[j]))\n    corr.append([features[i]] + temp)\n\ncorrelations = spark.createDataFrame(corr, ['Column'] + features)\n```", "```py\nhistogram_MPG = (\n    no_outliers\n    .select('FuelEconomy')\n    .rdd\n    .flatMap(lambda record: record)\n    .histogram(5)\n)\n```", "```py\n(\n    spark\n    .createDataFrame(\n        [(bins, counts) \n         for bins, counts \n         in zip(\n             histogram_MPG[0], \n             histogram_MPG[1]\n         )]\n        , ['bins', 'counts']\n    )\n    .registerTempTable('histogram_MPG')\n)\n```", "```py\n%%sql -o hist_MPG -q\nSELECT * FROM histogram_MPG\n```", "```py\n%%local\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('ggplot')\n\nfig = plt.figure(figsize=(12,9))\nax = fig.add_subplot(1, 1, 1)\nax.bar(hist_MPG['bins'], hist_MPG['counts'], width=3)\nax.set_title('Histogram of fuel economy')\n```", "```py\n%%local\nfrom bokeh.io import show\nfrom bokeh.plotting import figure\nfrom bokeh.io import output_notebook\noutput_notebook()\n\nlabels = [str(round(e, 2)) for e in hist_MPG['bins']]\n\np = figure(\n    x_range=labels, \n    plot_height=350, \n    title='Histogram of fuel economy'\n)\n\np.vbar(x=labels, top=hist_MPG['counts'], width=0.9)\n\nshow(p)\n```", "```py\nscatter = (\n    no_outliers\n    .select('Displacement', 'Cylinders')\n)\n\nscatter.registerTempTable('scatter')\n\n%%sql -o scatter_source -q\nSELECT * FROM scatter\n```", "```py\n%%local\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('ggplot')\n\nfig = plt.figure(figsize=(12,9))\nax = fig.add_subplot(1, 1, 1)\nax.scatter(\n      list(scatter_source['Cylinders'])\n    , list(scatter_source['Displacement'])\n    , s = 200\n    , alpha = 0.5\n)\n\nax.set_xlabel('Cylinders')\nax.set_ylabel('Displacement')\n\nax.set_title('Relationship between cylinders and displacement')\n```", "```py\n%%local \nfrom bokeh.io import show\nfrom bokeh.plotting import figure\nfrom bokeh.io import output_notebook\noutput_notebook()\n\np = figure(title = 'Relationship between cylinders and displacement')\np.xaxis.axis_label = 'Cylinders'\np.yaxis.axis_label = 'Displacement'\n\np.circle( list(scatter_source['Cylinders'])\n         , list(scatter_source['Displacement'])\n         , fill_alpha=0.2, size=10)\n\nshow(p)\n```"]