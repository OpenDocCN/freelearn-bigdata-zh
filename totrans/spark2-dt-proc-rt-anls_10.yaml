- en: Practical Machine Learning with Spark Using Scala
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover:'
  prefs: []
  type: TYPE_NORMAL
- en: Configuring IntelliJ to work with Spark and run Spark ML sample codes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running a sample ML code from Spark
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identifying data sources for practical machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running your first program using Apache Spark 2.0 with the IntelliJ IDE
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to add graphics to your Spark program
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With the recent advancements in cluster computing coupled with the rise of big
    data, the field of machine learning has been pushed to the forefront of computing.
    The need for an interactive platform that enables data science at scale has long been
    a dream that is now a reality.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following three areas together have enabled and accelerated interactive
    data science at scale:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Apache Spark**: A unified technology platform for data science that combines
    a fast compute engine and fault-tolerant data structures into a well-designed
    and integrated offering'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Machine learning**: A field of artificial intelligence that enables machines
    to mimic some of the tasks originally reserved exclusively for the human brain'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scala**: A modern JVM-based language that builds on traditional languages,
    but unites functional and object-oriented concepts without the verboseness of
    other languages'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'First, we need to set up the development environment, which will consist of
    the following components:'
  prefs: []
  type: TYPE_NORMAL
- en: Spark
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: IntelliJ community edition IDE
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scala
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The recipes in this chapter will give you detailed instructions for installing
    and configuring the IntelliJ IDE, Scala plugin, and Spark. After the development
    environment is set up, we'll proceed to run one of the Spark ML sample codes to
    test the setup.
  prefs: []
  type: TYPE_NORMAL
- en: Apache Spark
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Apache Spark is emerging as the de facto platform and trade language for big
    data analytics and as a complement to the **Hadoop** paradigm. Spark enables a
    data scientist to work in the manner that is most conducive to their workflow
    right out of the box. Spark's approach is to process the workload in a completely
    distributed manner without the need for **MapReduce** (**MR**) or repeated writing
    of the intermediate results to a disk.
  prefs: []
  type: TYPE_NORMAL
- en: Spark provides an easy-to-use distributed framework in a unified technology
    stack, which has made it the platform of choice for data science projects, which
    more often than not require an iterative algorithm that eventually merges toward
    a solution. These algorithms, due to their inner workings, generate a large ...
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The aim of machine learning is to produce machines and devices that can mimic
    human intelligence and automate some of the tasks that have been traditionally
    reserved for a human brain. Machine learning algorithms are designed to go through
    very large data sets in a relatively short time and approximate answers that would
    have taken a human much longer to process.
  prefs: []
  type: TYPE_NORMAL
- en: The field of machine learning can be classified into many forms and at a high
    level, it can be classified as supervised and unsupervised learning. Supervised
    learning algorithms are a class of ML algorithms that use a training set (that
    is, labeled data) to compute a probabilistic distribution or graphical model that
    in turn allows them to classify the new data points without further human intervention.
    Unsupervised learning is a type of machine learning algorithm used to draw inferences
    from datasets consisting of input data without labeled responses.
  prefs: []
  type: TYPE_NORMAL
- en: 'Out of the box, Spark offers a rich set of ML algorithms that can be deployed
    on large datasets without any further coding. The following figure depicts Spark''s
    MLlib algorithms as a mind map. Spark''s MLlib is designed to take advantage of
    parallelism while having fault-tolerant distributed data structures. Spark refers
    to such data structures as **Resilient Distributed Datasets** or **RDDs**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2651bc34-49cd-4574-a38e-de98c563668e.png)'
  prefs: []
  type: TYPE_IMG
- en: Scala
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Scala** is a modern programming language that is emerging as an alternative
    to traditional programming languages such as **Java** and **C++**. Scala is a
    JVM-based language that not only offers a concise syntax without the traditional
    boilerplate code, but also incorporates both object-oriented and functional programming
    into an extremely crisp and extraordinarily powerful type-safe language.'
  prefs: []
  type: TYPE_NORMAL
- en: Scala takes a flexible and expressive approach, which makes it perfect for interacting
    with Spark's MLlib. The fact that Spark itself is written in Scala provides a
    strong evidence that the Scala language is a full-service programming language
    that can be used to create sophisticated system code with heavy performance needs.
  prefs: []
  type: TYPE_NORMAL
- en: Scala builds on Java's tradition ...
  prefs: []
  type: TYPE_NORMAL
- en: Software versions and libraries used in this book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following table provides a detailed list of software versions and libraries
    used in this book. If you follow the installation instructions covered in this
    chapter, it will include most of the items listed here. Any other JAR or library
    files that may be required for specific recipes are covered via additional installation
    instructions in the respective recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Core systems** | **Version** |'
  prefs: []
  type: TYPE_TB
- en: '| Spark | 2.0.0 |'
  prefs: []
  type: TYPE_TB
- en: '| Java | 1.8 |'
  prefs: []
  type: TYPE_TB
- en: '| IntelliJ IDEA | 2016.2.4 |'
  prefs: []
  type: TYPE_TB
- en: '| Scala-sdk | 2.11.8 |'
  prefs: []
  type: TYPE_TB
- en: 'Miscellaneous JARs that will be required are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Miscellaneous JARs** | **Version** |'
  prefs: []
  type: TYPE_TB
- en: '| `bliki-core` | 3.0.19 |'
  prefs: []
  type: TYPE_TB
- en: '| `breeze-viz` | 0.12 |'
  prefs: []
  type: TYPE_TB
- en: '| `Cloud9` | 1.5.0 |'
  prefs: []
  type: TYPE_TB
- en: '| `Hadoop-streaming` | 2.2.0 |'
  prefs: []
  type: TYPE_TB
- en: '| `JCommon` | 1.0.23 |'
  prefs: []
  type: TYPE_TB
- en: '| `JFreeChart` | 1.0.19 |'
  prefs: []
  type: TYPE_TB
- en: '| `lucene-analyzers-common` | 6.0.0 |'
  prefs: []
  type: TYPE_TB
- en: '| `Lucene-Core` | 6.0.0 |'
  prefs: []
  type: TYPE_TB
- en: '| `scopt` | 3.3.0 |'
  prefs: []
  type: TYPE_TB
- en: '| `spark-streaming-flume-assembly` | 2.0.0 |'
  prefs: []
  type: TYPE_TB
- en: '| `spark-streaming-kafka-0-8-assembly` | 2.0.0 |'
  prefs: []
  type: TYPE_TB
- en: We have additionally tested all the recipes in this book on Spark 2.1.1 and
    found that the programs executed as expected. It is recommended for learning purposes
    you use the software versions and libraries listed in these tables.
  prefs: []
  type: TYPE_NORMAL
- en: To stay current with the rapidly changing Spark landscape and documentation,
    the API links to the Spark documentation mentioned throughout this book point
    to the latest version of Spark 2.x.x, but the API references in the recipes are
    explicitly for Spark 2.0.0.
  prefs: []
  type: TYPE_NORMAL
- en: 'All the Spark documentation links provided in this book will point to the latest
    documentation on Spark''s website. If you prefer to look for documentation for
    a specific version of Spark (for example, Spark 2.0.0), look for relevant documentation
    on the Spark website using the following URL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://spark.apache.org/documentation.html](https://spark.apache.org/documentation.html)'
  prefs: []
  type: TYPE_NORMAL
- en: We've made the code as simple as possible for clarity purposes rather than demonstrating
    the advanced features of Scala.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring IntelliJ to work with Spark and run Spark ML sample codes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We need to run some configurations to ensure that the project settings are correct
    before being able to run the samples that are provided by Spark or any of the
    programs listed this book.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We need to be particularly careful when configuring the project structure and
    global libraries. After we set everything up, we proceed to run the sample ML
    code provided by the Spark team to verify the setup. Sample code can be found
    under the Spark directory or can be obtained by downloading the Spark source code
    with samples.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are the steps for configuring IntelliJ to work with Spark MLlib
    and for running the sample ML code provided by Spark in the examples directory.
    The examples directory can be found in your home directory for Spark. Use the
    Scala samples to proceed:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the Project Structure... option, as shown in the following screenshot,
    to configure project settings:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/0d1ca754-2685-4f65-8e23-80edaf3a3992.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Verify the settings:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/c7b7d942-4e71-4afe-bc92-afee16c93ecb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Configure Global Libraries. Select Scala SDK as your global library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the JARs for the new Scala SDK and let the download ...
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Prior to Spark 2.0, we needed another library from Google called **Guava**
    for facilitating I/O and for providing a set of rich methods of defining tables
    and then letting Spark broadcast them across the cluster. Due to dependency issues
    that were hard to work around, Spark 2.0 no longer uses the Guava library. Make
    sure you use the Guava library if you are using Spark versions prior to 2.0 (required
    in version 1.5.2). The Guava library can be accessed at the following URL:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/google/guava/wiki](https://github.com/google/guava/wiki)'
  prefs: []
  type: TYPE_NORMAL
- en: 'You may want to use Guava version 15.0, which can be found here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://mvnrepository.com/artifact/com.google.guava/guava/15.0](https://mvnrepository.com/artifact/com.google.guava/guava/15.0)'
  prefs: []
  type: TYPE_NORMAL
- en: If you are using installation instructions from previous blogs, make sure to
    exclude the Guava library from the installation set.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If there are other third-party libraries or JARs required for the completion
    of the Spark installation, you can find those in the following Maven repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://repo1.maven.org/maven2/org/apache/spark/](https://repo1.maven.org/maven2/org/apache/spark/)'
  prefs: []
  type: TYPE_NORMAL
- en: Running a sample ML code from Spark
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We can verify the setup by simply downloading the sample code from the Spark
    source tree and importing it into IntelliJ to make sure it runs.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will first run the logistic regression code from the samples to verify installation.
    In the next section, we proceed to write our own version of the same program and
    examine the output in order to understand how it works.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Go to the source directory and pick one of the ML sample code files to run.
    We've selected the logistic regression example.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If you cannot find the source code in your directory, you can always download
    the Spark source, unzip, and then extract the examples directory accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: 'After selecting the example, select Edit Configurations..., as shown in the
    following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/b0826b04-9920-401b-a74e-23c650d70b49.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In the Configurations tab, define the following options:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'VM options: The choice shown allows you to run a standalone Spark cluster'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Program arguments: What we are supposed to pass into the program'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/a74269e6-9e2a-49d7-8971-26c941a19264.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Run the logistic regression by going to Run ''LogisticRegressionExample'',
    as shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/fcb89557-0451-4306-b937-972e2c1864bf.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Verify the exit code and make sure it is as shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/64a1a0db-aae3-4870-bbfd-96ba850d663f.png)'
  prefs: []
  type: TYPE_IMG
- en: Identifying data sources for practical machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Getting data for machine learning projects was a challenge in the past. However,
    now there is a rich set of public data sources specifically suitable for machine
    learning.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In addition to the university and government sources, there are many other open
    sources of data that can be used to learn and code your own examples and projects.
    We will list the data sources and show you how to best obtain and download data
    for each chapter.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following is a list of open source data worth exploring if you would like
    to develop applications in this field:'
  prefs: []
  type: TYPE_NORMAL
- en: '*UCI machine learning repository*: This is an extensive library with search
    functionality. At the time of writing, there were more than 350 datasets. You
    can click on the [https://archive.ics.uci.edu/ml/index.html](https://archive.ics.uci.edu/ml/index.html)
    link to see all the datasets or look for a specific set using a simple search
    (*Ctrl* + *F*).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Kaggle datasets*: You need to create an account, but you can download any
    sets for learning as well as for competing in machine learning competitions. The
    [https://www.kaggle.com/competitions](https://www.kaggle.com/competitions) link
    provides details for exploring and learning more about Kaggle, and the inner workings
    of machine learning competitions. ...'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Other sources for machine learning data:'
  prefs: []
  type: TYPE_NORMAL
- en: 'SMS spam data: [http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Financial dataset from Lending Club [https://www.lendingclub.com/info/download-data.action](https://www.lendingclub.com/info/download-data.action)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Research data from Yahoo [http://webscope.sandbox.yahoo.com/index.php](http://webscope.sandbox.yahoo.com/index.php)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon AWS public dataset [http://aws.amazon.com/public-data-sets/](http://aws.amazon.com/public-data-sets/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Labeled visual data from Image Net [http://www.image-net.org](http://www.image-net.org)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Census datasets [http://www.census.gov](http://www.census.gov)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compiled YouTube dataset [http://netsg.cs.sfu.ca/youtubedata/](http://netsg.cs.sfu.ca/youtubedata/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Collected rating data from the MovieLens site [http://grouplens.org/datasets/movielens/](http://grouplens.org/datasets/movielens/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enron dataset available to the public [http://www.cs.cmu.edu/~enron/](http://www.cs.cmu.edu/~enron/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dataset for the classic book elements of statistical learning [http://statweb.stanford.edu/~tibs/ElemStatLearn/data.htmlIMDB](http://statweb.stanford.edu/~tibs/ElemStatLearn/data.htmlIMDB)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Movie dataset [http://www.imdb.com/interfaces](http://www.imdb.com/interfaces)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Million Song dataset [http://labrosa.ee.columbia.edu/millionsong/](http://labrosa.ee.columbia.edu/millionsong/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dataset for speech and audio [http://labrosa.ee.columbia.edu/projects/](http://labrosa.ee.columbia.edu/projects/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Face recognition data [http://www.face-rec.org/databases/](http://www.face-rec.org/databases/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Social science data [http://www.icpsr.umich.edu/icpsrweb/ICPSR/studies](http://www.icpsr.umich.edu/icpsrweb/ICPSR/studies)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bulk datasets from Cornell University [http://arxiv.org/help/bulk_data_s3](http://arxiv.org/help/bulk_data_s3)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Project Guttenberg datasets [http://www.gutenberg.org/wiki/Gutenberg:Offline_Catalogs](http://www.gutenberg.org/wiki/Gutenberg:Offline_Catalogs)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Datasets from World Bank [http://data.worldbank.org](http://data.worldbank.org)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lexical database from World Net [http://wordnet.princeton.edu](http://wordnet.princeton.edu)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Collision data from NYPD [http://nypd.openscrape.com/#/](http://nypd.openscrape.com/#/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dataset for congressional row calls and others [http://voteview.com/dwnl.htm](http://voteview.com/dwnl.htm)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Large graph datasets from Stanford [http://snap.stanford.edu/data/index.html](http://snap.stanford.edu/data/index.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rich set of data from datahub [https://datahub.io/dataset](https://datahub.io/dataset)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yelp's academic dataset [https://www.yelp.com/academic_dataset](https://www.yelp.com/academic_dataset)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Source of data from GitHub [https://github.com/caesar0301/awesome-public-datasets](https://github.com/caesar0301/awesome-public-datasets)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dataset archives from Reddit [https://www.reddit.com/r/datasets/](https://www.reddit.com/r/datasets/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are some specialized datasets (for example, text analytics in Spanish,
    and gene and IMF data) that might be of some interest to you:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Datasets from Colombia (in Spanish): [http://www.datos.gov.co/frm/buscador/frmBuscador.aspx](http://www.datos.gov.co/frm/buscador/frmBuscador.aspx)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dataset from cancer studies [http://www.broadinstitute.org/cgi-bin/cancer/datasets.cgi](http://www.broadinstitute.org/cgi-bin/cancer/datasets.cgi)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Research data from Pew [http://www.pewinternet.org/datasets/](http://www.pewinternet.org/datasets/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data from the state of Illinois/USA [https://data.illinois.gov](https://data.illinois.gov)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data from freebase.com [http://www.freebase.com](http://www.freebase.com)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Datasets from the UN and its associated agencies [http://data.un.org](http://data.un.org)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: International Monetary Fund datasets [http://www.imf.org/external/data.htm](http://www.imf.org/external/data.htm)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: UK government data [https://data.gov.uk](https://data.gov.uk)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Open data from Estonia [http://pub.stat.ee/px-web.2001/Dialog/statfile1.asp](http://pub.stat.ee/px-web.2001/Dialog/statfile1.asp)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Many ML libraries in R containing data that can be exported as CSV [https://www.r-project.org](https://www.r-project.org)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gene expression datasets [http://www.ncbi.nlm.nih.gov/geo/](http://www.ncbi.nlm.nih.gov/geo/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running your first program using Apache Spark 2.0 with the IntelliJ IDE
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The purpose of this program is to get you comfortable with compiling and running
    a recipe using the Spark 2.0 development environment you just set up. We will
    explore the components and steps in later chapters.
  prefs: []
  type: TYPE_NORMAL
- en: We are going to write our own version of the Spark 2.0.0 program and examine
    the output so we can understand how it works. To emphasize, this short recipe
    is only a simple RDD program with Scala sugar syntax to make sure you have set
    up your environment correctly before starting to work with more complicated recipes.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Start a new project in IntelliJ or in an IDE of your choice. Make sure that
    the necessary JAR files are included.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Download the sample code for the book, find the `myFirstSpark20.scala` file,
    and place the code in the following directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We installed Spark 2.0 in the `C:\spark-2.0.0-bin-hadoop2.7\` directory on a
    Windows machine.
  prefs: []
  type: TYPE_NORMAL
- en: 'Place the `myFirstSpark20.scala` file in the `C:\spark-2.0.0-bin-hadoop2.7\examples\src\main\scala\spark\ml\cookbook\chapter1` directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/c91a16fa-6bd9-4971-b0db-e96b39641279.png)'
  prefs: []
  type: TYPE_IMG
- en: Mac users note that we installed Spark 2.0 in the `/Users/USERNAME/spark/spark-2.0.0-bin-hadoop2.7/`
    directory on a Mac machine.
  prefs: []
  type: TYPE_NORMAL
- en: Place the `myFirstSpark20.scala` file in the `/Users/USERNAME/spark/spark-2.0.0-bin-hadoop2.7/examples/src/main/scala/spark/ml/cookbook/chapter1`
    directory.
  prefs: []
  type: TYPE_NORMAL
- en: 'Set up the package location where the program will reside:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Import the necessary packages for the Spark session to gain access to the cluster
    and `log4j.Logger` to reduce the amount of output produced by Spark:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Set output level to `ERROR` to reduce Spark''s logging output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Initialize a Spark session by specifying configurations with the builder pattern,
    thus making an entry point available for the Spark cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The `myFirstSpark20` object will run in local mode. The previous code block
    is a typical way to start creating a `SparkSession` object.
  prefs: []
  type: TYPE_NORMAL
- en: 'We then create two array variables:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We then let Spark create two RDDs based on the array created before:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we let Spark operate on the `RDD`; the `zip()` function will create a
    new `RDD` from the two RDDs mentioned before:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'In the console output at runtime (more details on how to run the program in
    the IntelliJ IDE in the following steps), you will see this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9282b5ba-0927-4911-94c5-1cc2ee084d2f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, we sum up the value for `xRDD` and `yRDD` and calculate the new `zipedRDD`
    sum value. We also calculate the item count for `zipedRDD`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We print out the value calculated previously in the console:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s the console output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8584177e-8723-4303-af1d-472174b89309.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We close the program by stopping the Spark session:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the program is complete, the layout of `myFirstSpark20.scala` in the IntelliJ
    project explorer will look like the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/499b8f6b-90d1-4b13-a84b-5b2fed8873a7.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Make sure there is no compiling error. You can test this by rebuilding the
    project:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/65f74350-8ff4-4239-a524-0c9575256308.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Once the rebuild is complete, there should be a build completed message on
    the console:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: You can run the previous program by right-clicking on `the myFirstSpark20` object
    in the project explorer and selecting the context menu option (shown in the next
    screenshot) called `Run myFirstSpark20`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can also use the Run menu from the menu bar to perform the same action.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8b54aab8-e7da-496d-9c2e-73458fc9d172.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Once the program is successfully executed, you will see the following message:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'This is also shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f541842c-fa04-4078-a14d-23fc23f0b625.png)'
  prefs: []
  type: TYPE_IMG
- en: Mac users with IntelliJ will be able to perform this action using the same context
    menu.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Place the code in the correct path.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this example, we wrote our first Scala program, `myFirstSpark20.scala`, and
    displayed the steps to execute the program in IntelliJ. We placed the code in
    the path described in the steps for both Windows and Mac.
  prefs: []
  type: TYPE_NORMAL
- en: In the `myFirstSpark20` code, we saw a typical way to create a `SparkSession`
    object and how to configure it to run in local mode using the `master()` function.
    We created two RDDs out of the array objects and used a simple `zip()` function
    to create a new RDD.
  prefs: []
  type: TYPE_NORMAL
- en: We also did a simple sum calculation on the RDDs that were created and then
    displayed the result in the console. Finally, we exited and released the resource
    by calling `spark.stop()`.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Spark can be downloaded from [http://spark.apache.org/downloads.html](http://spark.apache.org/downloads.html).
  prefs: []
  type: TYPE_NORMAL
- en: Documentation for Spark 2.0 related to RDD can be found at [http://spark.apache.org/docs/latest/programming-guide.html#rdd-operations](http://spark.apache.org/docs/latest/programming-guide.html#rdd-operations).
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: More information about JetBrain IntelliJ can be found at [https://www.jetbrains.com/idea/](https://www.jetbrains.com/idea/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to add graphics to your Spark program
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we discuss how to use JFreeChart to add a graphic chart to your
    Spark 2.0.0 program.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Set up the JFreeChart library. JFreeChart JARs can be downloaded from the [https://sourceforge.net/projects/jfreechart/files/](https://sourceforge.net/projects/jfreechart/files/)
    site.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The JFreeChart version we have covered in this book is JFreeChart 1.0.19, as
    can be seen in the following screenshot. It can be downloaded from the [https://sourceforge.net/projects/jfreechart/files/1.%20JFreeChart/1.0.19/jfreechart-1.0.19.zip/download](https://sourceforge.net/projects/jfreechart/files/1.%20JFreeChart/1.0.19/jfreechart-1.0.19.zip/download) site:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/39158216-47c5-4394-bf11-f9e4d0883505.png)'
  prefs: []
  type: TYPE_IMG
- en: Once the ZIP file is downloaded, extract it. We extracted the ZIP file under
    `C:\` for a Windows machine, then proceed to find the `lib` directory under the
    extracted destination directory.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We then find the two libraries we need (JFreeChart ...
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this example, we wrote `MyChart.scala` and saw the steps for executing the
    program in IntelliJ. We placed code in the path described in the steps for both
    Windows and Mac.
  prefs: []
  type: TYPE_NORMAL
- en: In the code, we saw a typical way to create the `SparkSession` object and how
    to use the `master()` function. We created an RDD out of an array of random integers
    in the range of 1 to 15 and zipped it with the Index.
  prefs: []
  type: TYPE_NORMAL
- en: We then used JFreeChart to compose a basic chart that contains a simple *x*
    and *y* axis, and supplied the chart with the dataset we generated from the original
    RDD in the previous steps.
  prefs: []
  type: TYPE_NORMAL
- en: We set up the schema for the chart and called the `show()` function in JFreeChart
    to show a Frame with the *x* and *y* axes displayed as a linear graphical chart.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we exited and released the resource by calling `spark.stop()`.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'More about JFreeChart can be found here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://www.jfree.org/jfreechart/](http://www.jfree.org/jfreechart/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[http://www.jfree.org/jfreechart/api/javadoc/index.html](http://www.jfree.org/jfreechart/api/javadoc/index.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Additional examples about the features and capabilities of JFreeChart can be
    found at the following website:'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://www.jfree.org/jfreechart/samples.html](http://www.jfree.org/jfreechart/samples.html)'
  prefs: []
  type: TYPE_NORMAL
